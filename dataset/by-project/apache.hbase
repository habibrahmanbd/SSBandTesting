[{"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fa77c758483c1f10c3a60fd76076e9d49fe89133", "fixCommitParentSHA1": "3708198817e34bf67997c812b7f1fcef8119005a", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java\nindex 3823103..36d31b4 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java\n@@ -1155,14 +1155,14 @@\n     }\n   }\n \n-  @Test(expected = IOException.class)\n+  @Test(expected = NullPointerException.class)\n   public void testNullTableName() throws IOException {\n     // Null table name (should NOT work)\n     TEST_UTIL.createTable((TableName)null, FAMILY);\n     fail(\"Creating a table with null name passed, should have failed\");\n   }\n \n-  @Test(expected = IOException.class)\n+  @Test(expected = IllegalArgumentException.class)\n   public void testNullFamilyName() throws IOException {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n \n", "projectName": "apache.hbase", "bugLineNum": 1158, "bugNodeStartChar": 45276, "bugNodeLength": 17, "fixLineNum": 1158, "fixNodeStartChar": 45276, "fixNodeLength": 26, "sourceBeforeFix": "IOException.class", "sourceAfterFix": "NullPointerException.class"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fa77c758483c1f10c3a60fd76076e9d49fe89133", "fixCommitParentSHA1": "3708198817e34bf67997c812b7f1fcef8119005a", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java\nindex 3823103..36d31b4 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java\n@@ -1155,14 +1155,14 @@\n     }\n   }\n \n-  @Test(expected = IOException.class)\n+  @Test(expected = NullPointerException.class)\n   public void testNullTableName() throws IOException {\n     // Null table name (should NOT work)\n     TEST_UTIL.createTable((TableName)null, FAMILY);\n     fail(\"Creating a table with null name passed, should have failed\");\n   }\n \n-  @Test(expected = IOException.class)\n+  @Test(expected = IllegalArgumentException.class)\n   public void testNullFamilyName() throws IOException {\n     final TableName tableName = TableName.valueOf(name.getMethodName());\n \n", "projectName": "apache.hbase", "bugLineNum": 1165, "bugNodeStartChar": 45539, "bugNodeLength": 17, "fixLineNum": 1165, "fixNodeStartChar": 45539, "fixNodeLength": 30, "sourceBeforeFix": "IOException.class", "sourceAfterFix": "IllegalArgumentException.class"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "127bef4d101ac677d2b4875305d402528d4b81a6", "fixCommitParentSHA1": "47cb6295fae119e16c8625b5260dd33e9127b4ff", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/TestClientOperationTimeout.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestClientOperationTimeout.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestClientOperationTimeout.java\nindex 2ce34a9..52f0c7d 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestClientOperationTimeout.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestClientOperationTimeout.java\n@@ -120,7 +120,7 @@\n    * Tests that a get on a table throws {@link SocketTimeoutException} when the operation takes\n    * longer than 'hbase.client.operation.timeout'.\n    */\n-  @Test(expected = SocketTimeoutException.class)\n+  @Test(expected = RetriesExhaustedException.class)\n   public void testGetTimeout() throws Exception {\n     DELAY_GET = 600;\n     TABLE.get(new Get(ROW));\n@@ -130,7 +130,7 @@\n    * Tests that a put on a table throws {@link SocketTimeoutException} when the operation takes\n    * longer than 'hbase.client.operation.timeout'.\n    */\n-  @Test(expected = SocketTimeoutException.class)\n+  @Test(expected = RetriesExhaustedException.class)\n   public void testPutTimeout() throws Exception {\n     DELAY_MUTATE = 600;\n \n", "projectName": "apache.hbase", "bugLineNum": 123, "bugNodeStartChar": 5186, "bugNodeLength": 28, "fixLineNum": 123, "fixNodeStartChar": 5186, "fixNodeLength": 31, "sourceBeforeFix": "SocketTimeoutException.class", "sourceAfterFix": "RetriesExhaustedException.class"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "127bef4d101ac677d2b4875305d402528d4b81a6", "fixCommitParentSHA1": "47cb6295fae119e16c8625b5260dd33e9127b4ff", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/TestClientOperationTimeout.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestClientOperationTimeout.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestClientOperationTimeout.java\nindex 2ce34a9..52f0c7d 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestClientOperationTimeout.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestClientOperationTimeout.java\n@@ -120,7 +120,7 @@\n    * Tests that a get on a table throws {@link SocketTimeoutException} when the operation takes\n    * longer than 'hbase.client.operation.timeout'.\n    */\n-  @Test(expected = SocketTimeoutException.class)\n+  @Test(expected = RetriesExhaustedException.class)\n   public void testGetTimeout() throws Exception {\n     DELAY_GET = 600;\n     TABLE.get(new Get(ROW));\n@@ -130,7 +130,7 @@\n    * Tests that a put on a table throws {@link SocketTimeoutException} when the operation takes\n    * longer than 'hbase.client.operation.timeout'.\n    */\n-  @Test(expected = SocketTimeoutException.class)\n+  @Test(expected = RetriesExhaustedException.class)\n   public void testPutTimeout() throws Exception {\n     DELAY_MUTATE = 600;\n \n", "projectName": "apache.hbase", "bugLineNum": 133, "bugNodeStartChar": 5499, "bugNodeLength": 28, "fixLineNum": 133, "fixNodeStartChar": 5499, "fixNodeLength": 31, "sourceBeforeFix": "SocketTimeoutException.class", "sourceAfterFix": "RetriesExhaustedException.class"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "8af2dd3da2bacbd93965edb9de9d5ba3a8bf9ca4", "fixCommitParentSHA1": "bf140acd20fd3671919673e74da212a0faf43485", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\nindex ff56a26..d291b39 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n@@ -4736,7 +4736,7 @@\n                   HConstants.HREGION_EDITS_REPLAY_SKIP_ERRORS + \" instead.\");\n         }\n         if (skipErrors) {\n-          Path p = WALSplitter.moveAsideBadEditsFile(walFS, edits);\n+          Path p = WALSplitter.moveAsideBadEditsFile(fs, edits);\n           LOG.error(HConstants.HREGION_EDITS_REPLAY_SKIP_ERRORS\n               + \"=true so continuing. Renamed \" + edits +\n               \" as \" + p, e);\n", "projectName": "apache.hbase", "bugLineNum": 4739, "bugNodeStartChar": 191534, "bugNodeLength": 47, "fixLineNum": 4739, "fixNodeStartChar": 191534, "fixNodeLength": 44, "sourceBeforeFix": "WALSplitter.moveAsideBadEditsFile(walFS,edits)", "sourceAfterFix": "WALSplitter.moveAsideBadEditsFile(fs,edits)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "cb84b2788aeed6aad2bc4b1acb98290e060861e2", "fixCommitParentSHA1": "01c26c5311d462a0d78fbf88dfd79dbcceeb3a21", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\nindex 8ee00b8..d9a7ca9 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\n@@ -253,7 +253,7 @@\n       Assert.assertEquals(1, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n@@ -290,7 +290,7 @@\n       Assert.assertEquals(2, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n@@ -310,7 +310,7 @@\n       Assert.assertEquals(2, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n", "projectName": "apache.hbase", "bugLineNum": 256, "bugNodeStartChar": 10812, "bugNodeLength": 83, "fixLineNum": 256, "fixNodeStartChar": 10812, "fixNodeLength": 78, "sourceBeforeFix": "ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor())", "sourceAfterFix": "ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor())"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "cb84b2788aeed6aad2bc4b1acb98290e060861e2", "fixCommitParentSHA1": "01c26c5311d462a0d78fbf88dfd79dbcceeb3a21", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\nindex 8ee00b8..d9a7ca9 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\n@@ -253,7 +253,7 @@\n       Assert.assertEquals(1, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n@@ -290,7 +290,7 @@\n       Assert.assertEquals(2, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n@@ -310,7 +310,7 @@\n       Assert.assertEquals(2, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n", "projectName": "apache.hbase", "bugLineNum": 256, "bugNodeStartChar": 10812, "bugNodeLength": 83, "fixLineNum": 256, "fixNodeStartChar": 10812, "fixNodeLength": 78, "sourceBeforeFix": "ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor())", "sourceAfterFix": "ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor())"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "cb84b2788aeed6aad2bc4b1acb98290e060861e2", "fixCommitParentSHA1": "01c26c5311d462a0d78fbf88dfd79dbcceeb3a21", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\nindex 8ee00b8..d9a7ca9 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\n@@ -253,7 +253,7 @@\n       Assert.assertEquals(1, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n@@ -290,7 +290,7 @@\n       Assert.assertEquals(2, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n@@ -310,7 +310,7 @@\n       Assert.assertEquals(2, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n", "projectName": "apache.hbase", "bugLineNum": 293, "bugNodeStartChar": 12906, "bugNodeLength": 83, "fixLineNum": 293, "fixNodeStartChar": 12906, "fixNodeLength": 78, "sourceBeforeFix": "ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor())", "sourceAfterFix": "ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor())"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "cb84b2788aeed6aad2bc4b1acb98290e060861e2", "fixCommitParentSHA1": "01c26c5311d462a0d78fbf88dfd79dbcceeb3a21", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\nindex 8ee00b8..d9a7ca9 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\n@@ -253,7 +253,7 @@\n       Assert.assertEquals(1, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n@@ -290,7 +290,7 @@\n       Assert.assertEquals(2, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n@@ -310,7 +310,7 @@\n       Assert.assertEquals(2, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n", "projectName": "apache.hbase", "bugLineNum": 293, "bugNodeStartChar": 12906, "bugNodeLength": 83, "fixLineNum": 293, "fixNodeStartChar": 12906, "fixNodeLength": 78, "sourceBeforeFix": "ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor())", "sourceAfterFix": "ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor())"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "cb84b2788aeed6aad2bc4b1acb98290e060861e2", "fixCommitParentSHA1": "01c26c5311d462a0d78fbf88dfd79dbcceeb3a21", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\nindex 8ee00b8..d9a7ca9 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\n@@ -253,7 +253,7 @@\n       Assert.assertEquals(1, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n@@ -290,7 +290,7 @@\n       Assert.assertEquals(2, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n@@ -310,7 +310,7 @@\n       Assert.assertEquals(2, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n", "projectName": "apache.hbase", "bugLineNum": 313, "bugNodeStartChar": 14031, "bugNodeLength": 83, "fixLineNum": 313, "fixNodeStartChar": 14031, "fixNodeLength": 78, "sourceBeforeFix": "ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor())", "sourceAfterFix": "ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor())"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "cb84b2788aeed6aad2bc4b1acb98290e060861e2", "fixCommitParentSHA1": "01c26c5311d462a0d78fbf88dfd79dbcceeb3a21", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\nindex 8ee00b8..d9a7ca9 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestHbck.java\n@@ -253,7 +253,7 @@\n       Assert.assertEquals(1, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n@@ -290,7 +290,7 @@\n       Assert.assertEquals(2, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n@@ -310,7 +310,7 @@\n       Assert.assertEquals(2, result.size());\n       hbck.assigns(Arrays.asList(result.keySet().toArray(new String[0])).stream()\n           .map(regionName -> regionName.split(\"\\\\.\")[1]).collect(Collectors.toList()));\n-      ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor());\n+      ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor());\n       // now the state should be fixed\n       result = hbck.getFailedSplitMergeLegacyRegions(Arrays.asList(TableName.valueOf(testTable)));\n       Assert.assertEquals(0, result.size());\n", "projectName": "apache.hbase", "bugLineNum": 313, "bugNodeStartChar": 14031, "bugNodeLength": 83, "fixLineNum": 313, "fixNodeStartChar": 14031, "fixNodeLength": 78, "sourceBeforeFix": "ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor())", "sourceAfterFix": "ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor())"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "baf3ae80f5588ee848176adefc9f56818458a387", "fixCommitParentSHA1": "a93febecc473952fd5b6112a844bae3c11156b24", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\nindex cbc1a37..7a93c6e 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\n@@ -389,7 +389,7 @@\n             + \"maxSteps:{}. Hence load balancing may not work well. Setting parameter \"\n             + \"\\\"hbase.master.balancer.stochastic.runMaxSteps\\\" to true can overcome this issue.\"\n             + \"(This config change does not require service restart)\", calculatedMaxSteps,\n-            maxRunningTime);\n+            maxSteps);\n       }\n     }\n     LOG.info(\"start StochasticLoadBalancer.balancer, initCost=\" + currentCost + \", functionCost=\"\n", "projectName": "apache.hbase", "bugLineNum": 388, "bugNodeStartChar": 15600, "bugNodeLength": 388, "fixLineNum": 388, "fixNodeStartChar": 15600, "fixNodeLength": 382, "sourceBeforeFix": "LOG.warn(\"calculatedMaxSteps:{} for loadbalancer's stochastic walk is larger than \" + \"maxSteps:{}. Hence load balancing may not work well. Setting parameter \" + \"\\\"hbase.master.balancer.stochastic.runMaxSteps\\\" to true can overcome this issue.\"+ \"(This config change does not require service restart)\",calculatedMaxSteps,maxRunningTime)", "sourceAfterFix": "LOG.warn(\"calculatedMaxSteps:{} for loadbalancer's stochastic walk is larger than \" + \"maxSteps:{}. Hence load balancing may not work well. Setting parameter \" + \"\\\"hbase.master.balancer.stochastic.runMaxSteps\\\" to true can overcome this issue.\"+ \"(This config change does not require service restart)\",calculatedMaxSteps,maxSteps)"}, {"bugType": "CHANGE_CALLER_IN_FUNCTION_CALL", "fixCommitSHA1": "8fffaa7778e75625710adc9e458e7a549c525ce9", "fixCommitParentSHA1": "908dea8e416f383b40e4fb21d6867fd43e8a47ac", "bugFilePath": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableRangeHistogram.java", "fixPatch": "diff --git a/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableRangeHistogram.java b/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableRangeHistogram.java\nindex 4c800c4..4b73087 100644\n--- a/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableRangeHistogram.java\n+++ b/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableRangeHistogram.java\n@@ -81,7 +81,7 @@\n       priorRange = ranges[i];\n       cumNum = val;\n     }\n-    long val = histogram.getCount();\n+    long val = snapshot.getCount();\n     if (val - cumNum > 0) {\n       metricsRecordBuilder.addCounter(\n           Interns.info(name + \"_\" + rangeType + \"_\" + ranges[ranges.length - 1] + \"-inf\", desc),\n", "projectName": "apache.hbase", "bugLineNum": 84, "bugNodeStartChar": 2950, "bugNodeLength": 20, "fixLineNum": 84, "fixNodeStartChar": 2950, "fixNodeLength": 19, "sourceBeforeFix": "histogram.getCount()", "sourceAfterFix": "snapshot.getCount()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "8fffaa7778e75625710adc9e458e7a549c525ce9", "fixCommitParentSHA1": "908dea8e416f383b40e4fb21d6867fd43e8a47ac", "bugFilePath": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableRangeHistogram.java", "fixPatch": "diff --git a/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableRangeHistogram.java b/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableRangeHistogram.java\nindex 4c800c4..4b73087 100644\n--- a/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableRangeHistogram.java\n+++ b/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/metrics2/lib/MutableRangeHistogram.java\n@@ -81,7 +81,7 @@\n       priorRange = ranges[i];\n       cumNum = val;\n     }\n-    long val = histogram.getCount();\n+    long val = snapshot.getCount();\n     if (val - cumNum > 0) {\n       metricsRecordBuilder.addCounter(\n           Interns.info(name + \"_\" + rangeType + \"_\" + ranges[ranges.length - 1] + \"-inf\", desc),\n", "projectName": "apache.hbase", "bugLineNum": 84, "bugNodeStartChar": 2950, "bugNodeLength": 20, "fixLineNum": 84, "fixNodeStartChar": 2950, "fixNodeLength": 19, "sourceBeforeFix": "histogram.getCount()", "sourceAfterFix": "snapshot.getCount()"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "7142cea121b49677c748ae565dba89d2cc8971ab", "fixCommitParentSHA1": "1e12e884925f09abbc8c1231c7e000e875e961c6", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/AbstractTestAsyncTableRegionReplicasRead.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/AbstractTestAsyncTableRegionReplicasRead.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/AbstractTestAsyncTableRegionReplicasRead.java\nindex c70af51..1a5dc2b 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/AbstractTestAsyncTableRegionReplicasRead.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/AbstractTestAsyncTableRegionReplicasRead.java\n@@ -107,7 +107,7 @@\n       }\n       REPLICA_ID_TO_COUNT.computeIfAbsent(region.getReplicaId(), k -> new AtomicInteger())\n         .incrementAndGet();\n-      if (region.getRegionId() == RegionReplicaUtil.DEFAULT_REPLICA_ID && FAIL_PRIMARY_GET) {\n+      if (region.getReplicaId() == RegionReplicaUtil.DEFAULT_REPLICA_ID && FAIL_PRIMARY_GET) {\n         throw new IOException(\"Inject error\");\n       }\n     }\n", "projectName": "apache.hbase", "bugLineNum": 110, "bugNodeStartChar": 3974, "bugNodeLength": 20, "fixLineNum": 110, "fixNodeStartChar": 3974, "fixNodeLength": 21, "sourceBeforeFix": "region.getRegionId()", "sourceAfterFix": "region.getReplicaId()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "7142cea121b49677c748ae565dba89d2cc8971ab", "fixCommitParentSHA1": "1e12e884925f09abbc8c1231c7e000e875e961c6", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/AbstractTestAsyncTableRegionReplicasRead.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/AbstractTestAsyncTableRegionReplicasRead.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/AbstractTestAsyncTableRegionReplicasRead.java\nindex c70af51..1a5dc2b 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/AbstractTestAsyncTableRegionReplicasRead.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/AbstractTestAsyncTableRegionReplicasRead.java\n@@ -107,7 +107,7 @@\n       }\n       REPLICA_ID_TO_COUNT.computeIfAbsent(region.getReplicaId(), k -> new AtomicInteger())\n         .incrementAndGet();\n-      if (region.getRegionId() == RegionReplicaUtil.DEFAULT_REPLICA_ID && FAIL_PRIMARY_GET) {\n+      if (region.getReplicaId() == RegionReplicaUtil.DEFAULT_REPLICA_ID && FAIL_PRIMARY_GET) {\n         throw new IOException(\"Inject error\");\n       }\n     }\n", "projectName": "apache.hbase", "bugLineNum": 110, "bugNodeStartChar": 3974, "bugNodeLength": 20, "fixLineNum": 110, "fixNodeStartChar": 3974, "fixNodeLength": 21, "sourceBeforeFix": "region.getRegionId()", "sourceAfterFix": "region.getReplicaId()"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "40e1d9174e1dd15ed95b03a4cf8944384b1aaa2c", "fixCommitParentSHA1": "dedab71381e14d96da61485f859e0792d8ebc3f9", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ReopenTableRegionsProcedure.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ReopenTableRegionsProcedure.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ReopenTableRegionsProcedure.java\nindex 0634815..34ce962 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ReopenTableRegionsProcedure.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/procedure/ReopenTableRegionsProcedure.java\n@@ -88,7 +88,7 @@\n     switch (state) {\n       case REOPEN_TABLE_REGIONS_GET_REGIONS:\n         if (!env.getAssignmentManager().isTableEnabled(tableName)) {\n-          LOG.info(\"Table {} is disabled, give up reopening its regions\");\n+          LOG.info(\"Table {} is disabled, give up reopening its regions\", tableName);\n           return Flow.NO_MORE_STATE;\n         }\n         regions =\n", "projectName": "apache.hbase", "bugLineNum": 91, "bugNodeStartChar": 3579, "bugNodeLength": 63, "fixLineNum": 91, "fixNodeStartChar": 3579, "fixNodeLength": 74, "sourceBeforeFix": "LOG.info(\"Table {} is disabled, give up reopening its regions\")", "sourceAfterFix": "LOG.info(\"Table {} is disabled, give up reopening its regions\",tableName)"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "40e1d9174e1dd15ed95b03a4cf8944384b1aaa2c", "fixCommitParentSHA1": "dedab71381e14d96da61485f859e0792d8ebc3f9", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/SerialReplicationChecker.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/SerialReplicationChecker.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/SerialReplicationChecker.java\nindex b775d25..4b88050 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/SerialReplicationChecker.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/replication/regionserver/SerialReplicationChecker.java\n@@ -255,7 +255,7 @@\n     // has been moved to another RS and then back, so we need to check the barrier.\n     MutableLong previousPushedSeqId = pushed.getUnchecked(encodedNameAsString);\n     if (seqId == previousPushedSeqId.longValue() + 1) {\n-      LOG.trace(\"The sequence id for {} is continuous, pass\");\n+      LOG.trace(\"The sequence id for {} is continuous, pass\", entry);\n       previousPushedSeqId.increment();\n       return true;\n     }\n", "projectName": "apache.hbase", "bugLineNum": 258, "bugNodeStartChar": 12387, "bugNodeLength": 55, "fixLineNum": 258, "fixNodeStartChar": 12387, "fixNodeLength": 62, "sourceBeforeFix": "LOG.trace(\"The sequence id for {} is continuous, pass\")", "sourceAfterFix": "LOG.trace(\"The sequence id for {} is continuous, pass\",entry)"}, {"bugType": "CHANGE_OPERAND", "fixCommitSHA1": "fd3e0ff191f3e26b09f52f538748133b65f40740", "fixCommitParentSHA1": "ce29e9ea5c048a57e877d53e9c3e6081ff91dd78", "bugFilePath": "hbase-backup/src/main/java/org/apache/hadoop/hbase/backup/util/BackupUtils.java", "fixPatch": "diff --git a/hbase-backup/src/main/java/org/apache/hadoop/hbase/backup/util/BackupUtils.java b/hbase-backup/src/main/java/org/apache/hadoop/hbase/backup/util/BackupUtils.java\nindex 12f2f2f..da11756 100644\n--- a/hbase-backup/src/main/java/org/apache/hadoop/hbase/backup/util/BackupUtils.java\n+++ b/hbase-backup/src/main/java/org/apache/hadoop/hbase/backup/util/BackupUtils.java\n@@ -327,7 +327,7 @@\n       if (expMsg.contains(\"No FileSystem for scheme\")) {\n         newMsg =\n             \"Unsupported filesystem scheme found in the backup target url. Error Message: \"\n-                + newMsg;\n+                + expMsg;\n         LOG.error(newMsg);\n         throw new IOException(newMsg);\n       } else {\n", "projectName": "apache.hbase", "bugLineNum": 329, "bugNodeStartChar": 12190, "bugNodeLength": 104, "fixLineNum": 329, "fixNodeStartChar": 12190, "fixNodeLength": 104, "sourceBeforeFix": "\"Unsupported filesystem scheme found in the backup target url. Error Message: \" + newMsg", "sourceAfterFix": "\"Unsupported filesystem scheme found in the backup target url. Error Message: \" + expMsg"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fd3e0ff191f3e26b09f52f538748133b65f40740", "fixCommitParentSHA1": "ce29e9ea5c048a57e877d53e9c3e6081ff91dd78", "bugFilePath": "hbase-backup/src/main/java/org/apache/hadoop/hbase/backup/util/BackupUtils.java", "fixPatch": "diff --git a/hbase-backup/src/main/java/org/apache/hadoop/hbase/backup/util/BackupUtils.java b/hbase-backup/src/main/java/org/apache/hadoop/hbase/backup/util/BackupUtils.java\nindex 12f2f2f..da11756 100644\n--- a/hbase-backup/src/main/java/org/apache/hadoop/hbase/backup/util/BackupUtils.java\n+++ b/hbase-backup/src/main/java/org/apache/hadoop/hbase/backup/util/BackupUtils.java\n@@ -327,7 +327,7 @@\n       if (expMsg.contains(\"No FileSystem for scheme\")) {\n         newMsg =\n             \"Unsupported filesystem scheme found in the backup target url. Error Message: \"\n-                + newMsg;\n+                + expMsg;\n         LOG.error(newMsg);\n         throw new IOException(newMsg);\n       } else {\n", "projectName": "apache.hbase", "bugLineNum": 329, "bugNodeStartChar": 12190, "bugNodeLength": 104, "fixLineNum": 329, "fixNodeStartChar": 12190, "fixNodeLength": 104, "sourceBeforeFix": "\"Unsupported filesystem scheme found in the backup target url. Error Message: \" + newMsg", "sourceAfterFix": "\"Unsupported filesystem scheme found in the backup target url. Error Message: \" + expMsg"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "112d050609184375d8cc6b15ddb80bc7c6b9a19c", "fixCommitParentSHA1": "34e23fe425e62f240a65c435d41adfbbe211522d", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestSyncReplicationStandbyKillRS.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestSyncReplicationStandbyKillRS.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestSyncReplicationStandbyKillRS.java\nindex 3c9724f..d659688 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestSyncReplicationStandbyKillRS.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestSyncReplicationStandbyKillRS.java\n@@ -90,7 +90,7 @@\n       UTIL2.getAdmin().transitReplicationPeerSyncReplicationState(PEER_ID,\n           SyncReplicationState.DOWNGRADE_ACTIVE);\n     } catch (Exception e) {\n-      LOG.error(\"Failed to transit standby cluster to \" + SyncReplicationState.DOWNGRADE_ACTIVE);\n+      LOG.error(\"Failed to transit standby cluster to \" + SyncReplicationState.DOWNGRADE_ACTIVE, e);\n     }\n \n     while (UTIL2.getAdmin().getReplicationPeerSyncReplicationState(PEER_ID)\n", "projectName": "apache.hbase", "bugLineNum": 93, "bugNodeStartChar": 3782, "bugNodeLength": 90, "fixLineNum": 93, "fixNodeStartChar": 3782, "fixNodeLength": 93, "sourceBeforeFix": "LOG.error(\"Failed to transit standby cluster to \" + SyncReplicationState.DOWNGRADE_ACTIVE)", "sourceAfterFix": "LOG.error(\"Failed to transit standby cluster to \" + SyncReplicationState.DOWNGRADE_ACTIVE,e)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "34e23fe425e62f240a65c435d41adfbbe211522d", "fixCommitParentSHA1": "632aaef88b16cedaf30c213e4a5d3fd8bd58c3ce", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java\nindex 1abd605..bc472d3 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java\n@@ -697,7 +697,7 @@\n     TableDescriptor htd = TableDescriptorBuilder.copy(tableName, snapshotTableDesc);\n     org.apache.hadoop.hbase.client.SnapshotDescription snapshotPOJO = null;\n     if (cpHost != null) {\n-      snapshotPOJO = ProtobufUtil.createSnapshotDesc(reqSnapshot);\n+      snapshotPOJO = ProtobufUtil.createSnapshotDesc(snapshot);\n       cpHost.preCloneSnapshot(snapshotPOJO, htd);\n     }\n     long procId;\n@@ -827,7 +827,7 @@\n     // call Coprocessor pre hook\n     org.apache.hadoop.hbase.client.SnapshotDescription snapshotPOJO = null;\n     if (cpHost != null) {\n-      snapshotPOJO = ProtobufUtil.createSnapshotDesc(reqSnapshot);\n+      snapshotPOJO = ProtobufUtil.createSnapshotDesc(snapshot);\n       cpHost.preRestoreSnapshot(snapshotPOJO, snapshotTableDesc);\n     }\n \n", "projectName": "apache.hbase", "bugLineNum": 700, "bugNodeStartChar": 30102, "bugNodeLength": 44, "fixLineNum": 700, "fixNodeStartChar": 30102, "fixNodeLength": 41, "sourceBeforeFix": "ProtobufUtil.createSnapshotDesc(reqSnapshot)", "sourceAfterFix": "ProtobufUtil.createSnapshotDesc(snapshot)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "34e23fe425e62f240a65c435d41adfbbe211522d", "fixCommitParentSHA1": "632aaef88b16cedaf30c213e4a5d3fd8bd58c3ce", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java\nindex 1abd605..bc472d3 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/snapshot/SnapshotManager.java\n@@ -697,7 +697,7 @@\n     TableDescriptor htd = TableDescriptorBuilder.copy(tableName, snapshotTableDesc);\n     org.apache.hadoop.hbase.client.SnapshotDescription snapshotPOJO = null;\n     if (cpHost != null) {\n-      snapshotPOJO = ProtobufUtil.createSnapshotDesc(reqSnapshot);\n+      snapshotPOJO = ProtobufUtil.createSnapshotDesc(snapshot);\n       cpHost.preCloneSnapshot(snapshotPOJO, htd);\n     }\n     long procId;\n@@ -827,7 +827,7 @@\n     // call Coprocessor pre hook\n     org.apache.hadoop.hbase.client.SnapshotDescription snapshotPOJO = null;\n     if (cpHost != null) {\n-      snapshotPOJO = ProtobufUtil.createSnapshotDesc(reqSnapshot);\n+      snapshotPOJO = ProtobufUtil.createSnapshotDesc(snapshot);\n       cpHost.preRestoreSnapshot(snapshotPOJO, snapshotTableDesc);\n     }\n \n", "projectName": "apache.hbase", "bugLineNum": 830, "bugNodeStartChar": 35576, "bugNodeLength": 44, "fixLineNum": 830, "fixNodeStartChar": 35576, "fixNodeLength": 41, "sourceBeforeFix": "ProtobufUtil.createSnapshotDesc(reqSnapshot)", "sourceAfterFix": "ProtobufUtil.createSnapshotDesc(snapshot)"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "42be553433775c5985f6c68f8178e51afb0a402e", "fixCommitParentSHA1": "05f57f4c03c68e3184d6fcfaaa4353a0981125fa", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java\nindex 9e130eb..6856aad 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java\n@@ -244,7 +244,7 @@\n     dir = TEST_UTIL.getDataTestDir(\"TestHRegion\").toString();\n     method = name.getMethodName();\n     tableName = TableName.valueOf(method);\n-    CONF.set(CompactingMemStore.IN_MEMORY_FLUSH_THRESHOLD_FACTOR_KEY, String.valueOf(0.02));\n+    CONF.set(CompactingMemStore.IN_MEMORY_FLUSH_THRESHOLD_FACTOR_KEY, String.valueOf(0.09));\n   }\n \n   @After\n", "projectName": "apache.hbase", "bugLineNum": 247, "bugNodeStartChar": 11439, "bugNodeLength": 20, "fixLineNum": 247, "fixNodeStartChar": 11439, "fixNodeLength": 20, "sourceBeforeFix": "String.valueOf(0.02)", "sourceAfterFix": "String.valueOf(0.09)"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "f346a144b970bc51d28ada5eb6fb4568b0151529", "fixCommitParentSHA1": "e2fc21e4a1b0b854a49b94ff2c1627da3be4fbc4", "bugFilePath": "hbase-replication/src/main/java/org/apache/hadoop/hbase/replication/ZKReplicationQueueStorage.java", "fixPatch": "diff --git a/hbase-replication/src/main/java/org/apache/hadoop/hbase/replication/ZKReplicationQueueStorage.java b/hbase-replication/src/main/java/org/apache/hadoop/hbase/replication/ZKReplicationQueueStorage.java\nindex 499ee0a..d4363db 100644\n--- a/hbase-replication/src/main/java/org/apache/hadoop/hbase/replication/ZKReplicationQueueStorage.java\n+++ b/hbase-replication/src/main/java/org/apache/hadoop/hbase/replication/ZKReplicationQueueStorage.java\n@@ -134,26 +134,30 @@\n   }\n \n   /**\n+   * <p>\n    * Put all regions under /hbase/replication/regions znode will lead to too many children because\n-   * of the huge number of regions in real production environment. So here we use hash of encoded\n-   * region name to distribute the znode into multiple znodes. <br>\n+   * of the huge number of regions in real production environment. So here we will distribute the\n+   * znodes to multiple directories.\n+   * </p>\n+   * <p>\n    * So the final znode path will be format like this:\n    *\n    * <pre>\n-   * /hbase/replication/regions/e1/ff/dd04e76a6966d4ffa908ed0586764767-100\n+   * /hbase/replication/regions/dd/04/e76a6966d4ffa908ed0586764767-100\n    * </pre>\n    *\n-   * The e1 indicate the first level hash of encoded region name, and the ff indicate the second\n-   * level hash of encoded region name, the 100 indicate the peer id. <br>\n-   * Note that here we use two-level hash because if only one-level hash (such as mod 65535), it\n-   * will still lead to too many children under the /hbase/replication/regions znode.\n+   * Here the full encoded region name is dd04e76a6966d4ffa908ed0586764767, and we use the first two\n+   * characters 'dd' as the first level directory name, and use the next two characters '04' as the\n+   * second level directory name, and the rest part as the prefix of the znode, and the suffix '100'\n+   * is the peer id.\n+   * </p>\n    * @param encodedRegionName the encoded region name.\n    * @param peerId peer id for replication.\n    * @return ZNode path to persist the max sequence id that we've pushed for the given region and\n    *         peer.\n    */\n   @VisibleForTesting\n-  public String getSerialReplicationRegionPeerNode(String encodedRegionName, String peerId) {\n+  String getSerialReplicationRegionPeerNode(String encodedRegionName, String peerId) {\n     if (encodedRegionName == null || encodedRegionName.length() != RegionInfo.MD5_HEX_LENGTH) {\n       throw new IllegalArgumentException(\n           \"Invalid encoded region name: \" + encodedRegionName + \", length should be 32.\");\n@@ -161,7 +165,7 @@\n     return new StringBuilder(regionsZNode).append(ZNodePaths.ZNODE_PATH_SEPARATOR)\n         .append(encodedRegionName.substring(0, 2)).append(ZNodePaths.ZNODE_PATH_SEPARATOR)\n         .append(encodedRegionName.substring(2, 4)).append(ZNodePaths.ZNODE_PATH_SEPARATOR)\n-        .append(encodedRegionName).append(\"-\").append(peerId).toString();\n+        .append(encodedRegionName.substring(4)).append(\"-\").append(peerId).toString();\n   }\n \n   @Override\n", "projectName": "apache.hbase", "bugLineNum": 136, "bugNodeStartChar": 5426, "bugNodeLength": 1701, "fixLineNum": 136, "fixNodeStartChar": 5426, "fixNodeLength": 1694, "sourceBeforeFix": "1", "sourceAfterFix": "0"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "0a5f26324cfe4eb39eb48947f11364ec39221fa6", "fixCommitParentSHA1": "f1a81618fdd6318df5edded64fbb07e085e10853", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java\nindex 3fab7fb..a0b3b54 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java\n@@ -104,7 +104,7 @@\n     CallRunner task = createMockTask();\n     task.setStatus(new MonitoredRPCHandlerImpl());\n     scheduler.dispatch(task);\n-    verify(task, timeout(1000)).run();\n+    verify(task, timeout(10000)).run();\n     scheduler.stop();\n   }\n \n@@ -218,7 +218,7 @@\n       scheduler.dispatch(task);\n     }\n     for (CallRunner task : tasks) {\n-      verify(task, timeout(1000)).run();\n+      verify(task, timeout(10000)).run();\n     }\n     scheduler.stop();\n \n", "projectName": "apache.hbase", "bugLineNum": 107, "bugNodeStartChar": 4235, "bugNodeLength": 13, "fixLineNum": 107, "fixNodeStartChar": 4235, "fixNodeLength": 14, "sourceBeforeFix": "timeout(1000)", "sourceAfterFix": "timeout(10000)"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "0a5f26324cfe4eb39eb48947f11364ec39221fa6", "fixCommitParentSHA1": "f1a81618fdd6318df5edded64fbb07e085e10853", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java\nindex 3fab7fb..a0b3b54 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/ipc/TestSimpleRpcScheduler.java\n@@ -104,7 +104,7 @@\n     CallRunner task = createMockTask();\n     task.setStatus(new MonitoredRPCHandlerImpl());\n     scheduler.dispatch(task);\n-    verify(task, timeout(1000)).run();\n+    verify(task, timeout(10000)).run();\n     scheduler.stop();\n   }\n \n@@ -218,7 +218,7 @@\n       scheduler.dispatch(task);\n     }\n     for (CallRunner task : tasks) {\n-      verify(task, timeout(1000)).run();\n+      verify(task, timeout(10000)).run();\n     }\n     scheduler.stop();\n \n", "projectName": "apache.hbase", "bugLineNum": 221, "bugNodeStartChar": 8107, "bugNodeLength": 13, "fixLineNum": 221, "fixNodeStartChar": 8107, "fixNodeLength": 14, "sourceBeforeFix": "timeout(1000)", "sourceAfterFix": "timeout(10000)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "6d04aa179485f331deff328f511f9b494bdb4d43", "fixCommitParentSHA1": "8de820786ce8d708a6d2fd32b36ab9128bc6fc0f", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/MetaTableAccessor.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/MetaTableAccessor.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/MetaTableAccessor.java\nindex 5dc0565..dad9aef 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/MetaTableAccessor.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/MetaTableAccessor.java\n@@ -1759,7 +1759,7 @@\n       // master tries to assign these offline regions. This is followed by re-assignments of the\n       // daughter regions from resumed {@link SplitTableRegionProcedure}\n       addRegionStateToPut(putA, RegionState.State.CLOSED);\n-      addRegionStateToPut(putA, RegionState.State.CLOSED);\n+      addRegionStateToPut(putB, RegionState.State.CLOSED);\n \n       addSequenceNum(putA, 1, -1, splitA.getReplicaId()); //new regions, openSeqNum = 1 is fine.\n       addSequenceNum(putB, 1, -1, splitB.getReplicaId());\n", "projectName": "apache.hbase", "bugLineNum": 1762, "bugNodeStartChar": 67674, "bugNodeLength": 51, "fixLineNum": 1762, "fixNodeStartChar": 67674, "fixNodeLength": 51, "sourceBeforeFix": "addRegionStateToPut(putA,RegionState.State.CLOSED)", "sourceAfterFix": "addRegionStateToPut(putB,RegionState.State.CLOSED)"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "f0d0501d556efb8796138d4aa92ce4f276c93c3b", "fixCommitParentSHA1": "67a2c62a6aa3aadeb5e7ba68fd28aed2d33cd9d7", "bugFilePath": "hbase-rsgroup/src/test/java/org/apache/hadoop/hbase/rsgroup/TestRSGroupsWithACL.java", "fixPatch": "diff --git a/hbase-rsgroup/src/test/java/org/apache/hadoop/hbase/rsgroup/TestRSGroupsWithACL.java b/hbase-rsgroup/src/test/java/org/apache/hadoop/hbase/rsgroup/TestRSGroupsWithACL.java\nindex a428cfc..c5e4619 100644\n--- a/hbase-rsgroup/src/test/java/org/apache/hadoop/hbase/rsgroup/TestRSGroupsWithACL.java\n+++ b/hbase-rsgroup/src/test/java/org/apache/hadoop/hbase/rsgroup/TestRSGroupsWithACL.java\n@@ -166,9 +166,9 @@\n     grantGlobal(TEST_UTIL, toGroupEntry(GROUP_READ), Permission.Action.READ);\n     grantGlobal(TEST_UTIL, toGroupEntry(GROUP_WRITE), Permission.Action.WRITE);\n \n-    assertEquals(5, AccessControlLists.getTablePermissions(conf, TEST_TABLE).size());\n+    assertEquals(4, AccessControlLists.getTablePermissions(conf, TEST_TABLE).size());\n     try {\n-      assertEquals(5, AccessControlClient.getUserPermissions(systemUserConnection,\n+      assertEquals(4, AccessControlClient.getUserPermissions(systemUserConnection,\n           TEST_TABLE.toString()).size());\n     } catch (Throwable e) {\n       LOG.error(\"error during call of AccessControlClient.getUserPermissions. \", e);\n", "projectName": "apache.hbase", "bugLineNum": 169, "bugNodeStartChar": 7233, "bugNodeLength": 80, "fixLineNum": 169, "fixNodeStartChar": 7233, "fixNodeLength": 80, "sourceBeforeFix": "assertEquals(5,AccessControlLists.getTablePermissions(conf,TEST_TABLE).size())", "sourceAfterFix": "assertEquals(4,AccessControlLists.getTablePermissions(conf,TEST_TABLE).size())"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "f0d0501d556efb8796138d4aa92ce4f276c93c3b", "fixCommitParentSHA1": "67a2c62a6aa3aadeb5e7ba68fd28aed2d33cd9d7", "bugFilePath": "hbase-rsgroup/src/test/java/org/apache/hadoop/hbase/rsgroup/TestRSGroupsWithACL.java", "fixPatch": "diff --git a/hbase-rsgroup/src/test/java/org/apache/hadoop/hbase/rsgroup/TestRSGroupsWithACL.java b/hbase-rsgroup/src/test/java/org/apache/hadoop/hbase/rsgroup/TestRSGroupsWithACL.java\nindex a428cfc..c5e4619 100644\n--- a/hbase-rsgroup/src/test/java/org/apache/hadoop/hbase/rsgroup/TestRSGroupsWithACL.java\n+++ b/hbase-rsgroup/src/test/java/org/apache/hadoop/hbase/rsgroup/TestRSGroupsWithACL.java\n@@ -166,9 +166,9 @@\n     grantGlobal(TEST_UTIL, toGroupEntry(GROUP_READ), Permission.Action.READ);\n     grantGlobal(TEST_UTIL, toGroupEntry(GROUP_WRITE), Permission.Action.WRITE);\n \n-    assertEquals(5, AccessControlLists.getTablePermissions(conf, TEST_TABLE).size());\n+    assertEquals(4, AccessControlLists.getTablePermissions(conf, TEST_TABLE).size());\n     try {\n-      assertEquals(5, AccessControlClient.getUserPermissions(systemUserConnection,\n+      assertEquals(4, AccessControlClient.getUserPermissions(systemUserConnection,\n           TEST_TABLE.toString()).size());\n     } catch (Throwable e) {\n       LOG.error(\"error during call of AccessControlClient.getUserPermissions. \", e);\n", "projectName": "apache.hbase", "bugLineNum": 171, "bugNodeStartChar": 7331, "bugNodeLength": 117, "fixLineNum": 171, "fixNodeStartChar": 7331, "fixNodeLength": 117, "sourceBeforeFix": "assertEquals(5,AccessControlClient.getUserPermissions(systemUserConnection,TEST_TABLE.toString()).size())", "sourceAfterFix": "assertEquals(4,AccessControlClient.getUserPermissions(systemUserConnection,TEST_TABLE.toString()).size())"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "c98bab51de22a20990ff8805825e8638e0686464", "fixCommitParentSHA1": "e880946f53a9217f322c75dda8b9285e566c7406", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java\nindex 731e02f..d54cb53 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java\n@@ -49,7 +49,7 @@\n   @Test\n   public void testOnlineConfigChange() throws IOException {\n     LOG.debug(\"Starting the test\");\n-    Admin admin = TEST_UTIL.getHBaseAdmin();\n+    Admin admin = TEST_UTIL.getAdmin();\n     ServerName server = TEST_UTIL.getHBaseCluster().getRegionServer(0).getServerName();\n     admin.updateConfiguration(server);\n   }\n@@ -65,7 +65,7 @@\n     // update hbase-site.xml by overwriting it\n     Files.copy(cnf2Path, cnfPath, StandardCopyOption.REPLACE_EXISTING);\n \n-    Admin admin = TEST_UTIL.getHBaseAdmin();\n+    Admin admin = TEST_UTIL.getAdmin();\n     ServerName server = TEST_UTIL.getHBaseCluster().getMaster().getServerName();\n     admin.updateConfiguration(server);\n     Configuration conf = TEST_UTIL.getMiniHBaseCluster().getMaster().getConfiguration();\n", "projectName": "apache.hbase", "bugLineNum": 52, "bugNodeStartChar": 1915, "bugNodeLength": 25, "fixLineNum": 52, "fixNodeStartChar": 1915, "fixNodeLength": 20, "sourceBeforeFix": "TEST_UTIL.getHBaseAdmin()", "sourceAfterFix": "TEST_UTIL.getAdmin()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "c98bab51de22a20990ff8805825e8638e0686464", "fixCommitParentSHA1": "e880946f53a9217f322c75dda8b9285e566c7406", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java\nindex 731e02f..d54cb53 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java\n@@ -49,7 +49,7 @@\n   @Test\n   public void testOnlineConfigChange() throws IOException {\n     LOG.debug(\"Starting the test\");\n-    Admin admin = TEST_UTIL.getHBaseAdmin();\n+    Admin admin = TEST_UTIL.getAdmin();\n     ServerName server = TEST_UTIL.getHBaseCluster().getRegionServer(0).getServerName();\n     admin.updateConfiguration(server);\n   }\n@@ -65,7 +65,7 @@\n     // update hbase-site.xml by overwriting it\n     Files.copy(cnf2Path, cnfPath, StandardCopyOption.REPLACE_EXISTING);\n \n-    Admin admin = TEST_UTIL.getHBaseAdmin();\n+    Admin admin = TEST_UTIL.getAdmin();\n     ServerName server = TEST_UTIL.getHBaseCluster().getMaster().getServerName();\n     admin.updateConfiguration(server);\n     Configuration conf = TEST_UTIL.getMiniHBaseCluster().getMaster().getConfiguration();\n", "projectName": "apache.hbase", "bugLineNum": 52, "bugNodeStartChar": 1915, "bugNodeLength": 25, "fixLineNum": 52, "fixNodeStartChar": 1915, "fixNodeLength": 20, "sourceBeforeFix": "TEST_UTIL.getHBaseAdmin()", "sourceAfterFix": "TEST_UTIL.getAdmin()"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "c98bab51de22a20990ff8805825e8638e0686464", "fixCommitParentSHA1": "e880946f53a9217f322c75dda8b9285e566c7406", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java\nindex 731e02f..d54cb53 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java\n@@ -49,7 +49,7 @@\n   @Test\n   public void testOnlineConfigChange() throws IOException {\n     LOG.debug(\"Starting the test\");\n-    Admin admin = TEST_UTIL.getHBaseAdmin();\n+    Admin admin = TEST_UTIL.getAdmin();\n     ServerName server = TEST_UTIL.getHBaseCluster().getRegionServer(0).getServerName();\n     admin.updateConfiguration(server);\n   }\n@@ -65,7 +65,7 @@\n     // update hbase-site.xml by overwriting it\n     Files.copy(cnf2Path, cnfPath, StandardCopyOption.REPLACE_EXISTING);\n \n-    Admin admin = TEST_UTIL.getHBaseAdmin();\n+    Admin admin = TEST_UTIL.getAdmin();\n     ServerName server = TEST_UTIL.getHBaseCluster().getMaster().getServerName();\n     admin.updateConfiguration(server);\n     Configuration conf = TEST_UTIL.getMiniHBaseCluster().getMaster().getConfiguration();\n", "projectName": "apache.hbase", "bugLineNum": 68, "bugNodeStartChar": 2710, "bugNodeLength": 25, "fixLineNum": 68, "fixNodeStartChar": 2710, "fixNodeLength": 20, "sourceBeforeFix": "TEST_UTIL.getHBaseAdmin()", "sourceAfterFix": "TEST_UTIL.getAdmin()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "c98bab51de22a20990ff8805825e8638e0686464", "fixCommitParentSHA1": "e880946f53a9217f322c75dda8b9285e566c7406", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java\nindex 731e02f..d54cb53 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/client/TestUpdateConfiguration.java\n@@ -49,7 +49,7 @@\n   @Test\n   public void testOnlineConfigChange() throws IOException {\n     LOG.debug(\"Starting the test\");\n-    Admin admin = TEST_UTIL.getHBaseAdmin();\n+    Admin admin = TEST_UTIL.getAdmin();\n     ServerName server = TEST_UTIL.getHBaseCluster().getRegionServer(0).getServerName();\n     admin.updateConfiguration(server);\n   }\n@@ -65,7 +65,7 @@\n     // update hbase-site.xml by overwriting it\n     Files.copy(cnf2Path, cnfPath, StandardCopyOption.REPLACE_EXISTING);\n \n-    Admin admin = TEST_UTIL.getHBaseAdmin();\n+    Admin admin = TEST_UTIL.getAdmin();\n     ServerName server = TEST_UTIL.getHBaseCluster().getMaster().getServerName();\n     admin.updateConfiguration(server);\n     Configuration conf = TEST_UTIL.getMiniHBaseCluster().getMaster().getConfiguration();\n", "projectName": "apache.hbase", "bugLineNum": 68, "bugNodeStartChar": 2710, "bugNodeLength": 25, "fixLineNum": 68, "fixNodeStartChar": 2710, "fixNodeLength": 20, "sourceBeforeFix": "TEST_UTIL.getHBaseAdmin()", "sourceAfterFix": "TEST_UTIL.getAdmin()"}, {"bugType": "LESS_SPECIFIC_IF", "fixCommitSHA1": "ddbff4fd8700b17229d0192353c109b3ef1c5858", "fixCommitParentSHA1": "9434d52c190386f15188e0473ce005e96bf78413", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/util/UnsafeAvailChecker.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/util/UnsafeAvailChecker.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/util/UnsafeAvailChecker.java\nindex f6744d7..8fe7044 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/util/UnsafeAvailChecker.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/util/UnsafeAvailChecker.java\n@@ -52,7 +52,7 @@\n     // When Unsafe itself is not available/accessible consider unaligned as false.\n     if (avail) {\n       String arch = System.getProperty(\"os.arch\");\n-      if (\"ppc64\".equals(arch) || \"ppc64le\".equals(arch)) {\n+      if (\"ppc64\".equals(arch) || \"ppc64le\".equals(arch) || \"aarch64\".equals(arch)) {\n         // java.nio.Bits.unaligned() wrongly returns false on ppc (JDK-8165231),\n         unaligned = true;\n       } else {\n", "projectName": "apache.hbase", "bugLineNum": 55, "bugNodeStartChar": 2054, "bugNodeLength": 46, "fixLineNum": 55, "fixNodeStartChar": 2054, "fixNodeLength": 72, "sourceBeforeFix": "\"ppc64\".equals(arch) || \"ppc64le\".equals(arch)", "sourceAfterFix": "\"ppc64\".equals(arch) || \"ppc64le\".equals(arch) || \"aarch64\".equals(arch)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fc13cf7d7843029d807878869e3c64cace5640dd", "fixCommitParentSHA1": "efb95a17945cc91aa639396f6f6c528b52c71fcb", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/ByteBufferKeyValue.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/ByteBufferKeyValue.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/ByteBufferKeyValue.java\nindex f906681..c59b947 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/ByteBufferKeyValue.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/ByteBufferKeyValue.java\n@@ -302,7 +302,7 @@\n   }\n \n   @Override\n-  public Cell deepClone() {\n+  public ExtendedCell deepClone() {\n     byte[] copy = new byte[this.length];\n     ByteBufferUtils.copyFromBufferToArray(copy, this.buf, this.offset, 0, this.length);\n     KeyValue kv = new KeyValue(copy, 0, copy.length);\n", "projectName": "apache.hbase", "bugLineNum": 304, "bugNodeStartChar": 7425, "bugNodeLength": 283, "fixLineNum": 304, "fixNodeStartChar": 7425, "fixNodeLength": 291, "sourceBeforeFix": "@Override public Cell deepClone(){   byte[] copy=new byte[this.length];   ByteBufferUtils.copyFromBufferToArray(copy,this.buf,this.offset,0,this.length);   KeyValue kv=new KeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } ", "sourceAfterFix": "@Override public ExtendedCell deepClone(){   byte[] copy=new byte[this.length];   ByteBufferUtils.copyFromBufferToArray(copy,this.buf,this.offset,0,this.length);   KeyValue kv=new KeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } "}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fc13cf7d7843029d807878869e3c64cace5640dd", "fixCommitParentSHA1": "efb95a17945cc91aa639396f6f6c528b52c71fcb", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\nindex 825d9b1..a3029f8 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\n@@ -657,7 +657,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       return new TagRewriteCell(clonedBaseCell, this.tags);\n     }\n@@ -838,7 +838,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       if (clonedBaseCell instanceof ByteBufferCell) {\n         return new TagRewriteByteBufferCell((ByteBufferCell) clonedBaseCell, this.tags);\n@@ -981,7 +981,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       return new ValueAndTagRewriteCell(clonedBaseCell, this.value, this.tags);\n     }\n@@ -1047,7 +1047,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       if (clonedBaseCell instanceof ByteBufferCell) {\n         return new ValueAndTagRewriteByteBufferCell((ByteBufferCell) clonedBaseCell, this.value,\n", "projectName": "apache.hbase", "bugLineNum": 659, "bugNodeStartChar": 23428, "bugNodeLength": 173, "fixLineNum": 659, "fixNodeStartChar": 23428, "fixNodeLength": 181, "sourceBeforeFix": "@Override public Cell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   return new TagRewriteCell(clonedBaseCell,this.tags); } ", "sourceAfterFix": "@Override public ExtendedCell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   return new TagRewriteCell(clonedBaseCell,this.tags); } "}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fc13cf7d7843029d807878869e3c64cace5640dd", "fixCommitParentSHA1": "efb95a17945cc91aa639396f6f6c528b52c71fcb", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\nindex 825d9b1..a3029f8 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\n@@ -657,7 +657,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       return new TagRewriteCell(clonedBaseCell, this.tags);\n     }\n@@ -838,7 +838,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       if (clonedBaseCell instanceof ByteBufferCell) {\n         return new TagRewriteByteBufferCell((ByteBufferCell) clonedBaseCell, this.tags);\n@@ -981,7 +981,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       return new ValueAndTagRewriteCell(clonedBaseCell, this.value, this.tags);\n     }\n@@ -1047,7 +1047,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       if (clonedBaseCell instanceof ByteBufferCell) {\n         return new ValueAndTagRewriteByteBufferCell((ByteBufferCell) clonedBaseCell, this.value,\n", "projectName": "apache.hbase", "bugLineNum": 840, "bugNodeStartChar": 28126, "bugNodeLength": 324, "fixLineNum": 840, "fixNodeStartChar": 28126, "fixNodeLength": 332, "sourceBeforeFix": "@Override public Cell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   if (clonedBaseCell instanceof ByteBufferCell) {     return new TagRewriteByteBufferCell((ByteBufferCell)clonedBaseCell,this.tags);   }   return new TagRewriteCell(clonedBaseCell,this.tags); } ", "sourceAfterFix": "@Override public ExtendedCell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   if (clonedBaseCell instanceof ByteBufferCell) {     return new TagRewriteByteBufferCell((ByteBufferCell)clonedBaseCell,this.tags);   }   return new TagRewriteCell(clonedBaseCell,this.tags); } "}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fc13cf7d7843029d807878869e3c64cace5640dd", "fixCommitParentSHA1": "efb95a17945cc91aa639396f6f6c528b52c71fcb", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\nindex 825d9b1..a3029f8 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\n@@ -657,7 +657,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       return new TagRewriteCell(clonedBaseCell, this.tags);\n     }\n@@ -838,7 +838,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       if (clonedBaseCell instanceof ByteBufferCell) {\n         return new TagRewriteByteBufferCell((ByteBufferCell) clonedBaseCell, this.tags);\n@@ -981,7 +981,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       return new ValueAndTagRewriteCell(clonedBaseCell, this.value, this.tags);\n     }\n@@ -1047,7 +1047,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       if (clonedBaseCell instanceof ByteBufferCell) {\n         return new ValueAndTagRewriteByteBufferCell((ByteBufferCell) clonedBaseCell, this.value,\n", "projectName": "apache.hbase", "bugLineNum": 983, "bugNodeStartChar": 32393, "bugNodeLength": 193, "fixLineNum": 983, "fixNodeStartChar": 32393, "fixNodeLength": 201, "sourceBeforeFix": "@Override public Cell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   return new ValueAndTagRewriteCell(clonedBaseCell,this.value,this.tags); } ", "sourceAfterFix": "@Override public ExtendedCell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   return new ValueAndTagRewriteCell(clonedBaseCell,this.value,this.tags); } "}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fc13cf7d7843029d807878869e3c64cace5640dd", "fixCommitParentSHA1": "efb95a17945cc91aa639396f6f6c528b52c71fcb", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\nindex 825d9b1..a3029f8 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\n@@ -657,7 +657,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       return new TagRewriteCell(clonedBaseCell, this.tags);\n     }\n@@ -838,7 +838,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       if (clonedBaseCell instanceof ByteBufferCell) {\n         return new TagRewriteByteBufferCell((ByteBufferCell) clonedBaseCell, this.tags);\n@@ -981,7 +981,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       return new ValueAndTagRewriteCell(clonedBaseCell, this.value, this.tags);\n     }\n@@ -1047,7 +1047,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       Cell clonedBaseCell = ((ExtendedCell) this.cell).deepClone();\n       if (clonedBaseCell instanceof ByteBufferCell) {\n         return new ValueAndTagRewriteByteBufferCell((ByteBufferCell) clonedBaseCell, this.value,\n", "projectName": "apache.hbase", "bugLineNum": 1049, "bugNodeStartChar": 34072, "bugNodeLength": 376, "fixLineNum": 1049, "fixNodeStartChar": 34072, "fixNodeLength": 384, "sourceBeforeFix": "@Override public Cell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   if (clonedBaseCell instanceof ByteBufferCell) {     return new ValueAndTagRewriteByteBufferCell((ByteBufferCell)clonedBaseCell,this.value,this.tags);   }   return new ValueAndTagRewriteCell(clonedBaseCell,this.value,this.tags); } ", "sourceAfterFix": "@Override public ExtendedCell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   if (clonedBaseCell instanceof ByteBufferCell) {     return new ValueAndTagRewriteByteBufferCell((ByteBufferCell)clonedBaseCell,this.value,this.tags);   }   return new ValueAndTagRewriteCell(clonedBaseCell,this.value,this.tags); } "}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fc13cf7d7843029d807878869e3c64cace5640dd", "fixCommitParentSHA1": "efb95a17945cc91aa639396f6f6c528b52c71fcb", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/ExtendedCell.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/ExtendedCell.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/ExtendedCell.java\nindex 7ed4dc0..4d16fca 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/ExtendedCell.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/ExtendedCell.java\n@@ -73,7 +73,7 @@\n    * Does a deep copy of the contents to a new memory area and returns it as a new cell.\n    * @return The deep cloned cell\n    */\n-  Cell deepClone();\n+  ExtendedCell deepClone();\n \n   /**\n    * Extracts the id of the backing bytebuffer of this cell if it was obtained from fixed sized\n", "projectName": "apache.hbase", "bugLineNum": 72, "bugNodeStartChar": 2986, "bugNodeLength": 152, "fixLineNum": 72, "fixNodeStartChar": 2986, "fixNodeLength": 160, "sourceBeforeFix": "/**   * Does a deep copy of the contents to a new memory area and returns it as a new cell.  * @return The deep cloned cell  */ Cell deepClone(); ", "sourceAfterFix": "/**   * Does a deep copy of the contents to a new memory area and returns it as a new cell.  * @return The deep cloned cell  */ ExtendedCell deepClone(); "}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fc13cf7d7843029d807878869e3c64cace5640dd", "fixCommitParentSHA1": "efb95a17945cc91aa639396f6f6c528b52c71fcb", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/IndividualBytesFieldCell.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/IndividualBytesFieldCell.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/IndividualBytesFieldCell.java\nindex 0597c5e..14e35df 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/IndividualBytesFieldCell.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/IndividualBytesFieldCell.java\n@@ -183,7 +183,7 @@\n   }\n \n   @Override\n-  public Cell deepClone() {\n+  public ExtendedCell deepClone() {\n     // When being added to the memstore, deepClone() is called and KeyValue has less heap overhead.\n     return new KeyValue(this);\n   }\n", "projectName": "apache.hbase", "bugLineNum": 185, "bugNodeStartChar": 7151, "bugNodeLength": 172, "fixLineNum": 185, "fixNodeStartChar": 7151, "fixNodeLength": 180, "sourceBeforeFix": "@Override public Cell deepClone(){   return new KeyValue(this); } ", "sourceAfterFix": "@Override public ExtendedCell deepClone(){   return new KeyValue(this); } "}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fc13cf7d7843029d807878869e3c64cace5640dd", "fixCommitParentSHA1": "efb95a17945cc91aa639396f6f6c528b52c71fcb", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java\nindex 0ee8b80..ae95738 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/KeyValue.java\n@@ -2808,7 +2808,7 @@\n   }\n \n   @Override\n-  public Cell deepClone() {\n+  public ExtendedCell deepClone() {\n     byte[] copy = Bytes.copy(this.bytes, this.offset, this.length);\n     KeyValue kv = new KeyValue(copy, 0, copy.length);\n     kv.setSequenceId(this.getSequenceId());\n", "projectName": "apache.hbase", "bugLineNum": 2810, "bugNodeStartChar": 96751, "bugNodeLength": 222, "fixLineNum": 2810, "fixNodeStartChar": 96751, "fixNodeLength": 230, "sourceBeforeFix": "@Override public Cell deepClone(){   byte[] copy=Bytes.copy(this.bytes,this.offset,this.length);   KeyValue kv=new KeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } ", "sourceAfterFix": "@Override public ExtendedCell deepClone(){   byte[] copy=Bytes.copy(this.bytes,this.offset,this.length);   KeyValue kv=new KeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } "}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fc13cf7d7843029d807878869e3c64cace5640dd", "fixCommitParentSHA1": "efb95a17945cc91aa639396f6f6c528b52c71fcb", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/NoTagsByteBufferKeyValue.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/NoTagsByteBufferKeyValue.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/NoTagsByteBufferKeyValue.java\nindex 1822563..82b243b 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/NoTagsByteBufferKeyValue.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/NoTagsByteBufferKeyValue.java\n@@ -52,7 +52,7 @@\n   }\n \n   @Override\n-  public Cell deepClone() {\n+  public ExtendedCell deepClone() {\n     byte[] copy = new byte[this.length];\n     ByteBufferUtils.copyFromBufferToArray(copy, this.buf, this.offset, 0, this.length);\n     KeyValue kv = new NoTagsKeyValue(copy, 0, copy.length);\n", "projectName": "apache.hbase", "bugLineNum": 54, "bugNodeStartChar": 1646, "bugNodeLength": 289, "fixLineNum": 54, "fixNodeStartChar": 1646, "fixNodeLength": 297, "sourceBeforeFix": "@Override public Cell deepClone(){   byte[] copy=new byte[this.length];   ByteBufferUtils.copyFromBufferToArray(copy,this.buf,this.offset,0,this.length);   KeyValue kv=new NoTagsKeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } ", "sourceAfterFix": "@Override public ExtendedCell deepClone(){   byte[] copy=new byte[this.length];   ByteBufferUtils.copyFromBufferToArray(copy,this.buf,this.offset,0,this.length);   KeyValue kv=new NoTagsKeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } "}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fc13cf7d7843029d807878869e3c64cace5640dd", "fixCommitParentSHA1": "efb95a17945cc91aa639396f6f6c528b52c71fcb", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/NoTagsKeyValue.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/NoTagsKeyValue.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/NoTagsKeyValue.java\nindex 8a57a01..088aff5 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/NoTagsKeyValue.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/NoTagsKeyValue.java\n@@ -51,7 +51,7 @@\n   }\n \n   @Override\n-  public Cell deepClone() {\n+  public ExtendedCell deepClone() {\n     byte[] copy = Bytes.copy(this.bytes, this.offset, this.length);\n     KeyValue kv = new NoTagsKeyValue(copy, 0, copy.length);\n     kv.setSequenceId(this.getSequenceId());\n", "projectName": "apache.hbase", "bugLineNum": 53, "bugNodeStartChar": 1620, "bugNodeLength": 228, "fixLineNum": 53, "fixNodeStartChar": 1620, "fixNodeLength": 236, "sourceBeforeFix": "@Override public Cell deepClone(){   byte[] copy=Bytes.copy(this.bytes,this.offset,this.length);   KeyValue kv=new NoTagsKeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } ", "sourceAfterFix": "@Override public ExtendedCell deepClone(){   byte[] copy=Bytes.copy(this.bytes,this.offset,this.length);   KeyValue kv=new NoTagsKeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } "}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fc13cf7d7843029d807878869e3c64cace5640dd", "fixCommitParentSHA1": "efb95a17945cc91aa639396f6f6c528b52c71fcb", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\nindex 00ec0fc..bc905e5 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\n@@ -470,7 +470,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       // This is not used in actual flow. Throwing UnsupportedOperationException\n       throw new UnsupportedOperationException();\n     }\n@@ -715,7 +715,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       // This is not used in actual flow. Throwing UnsupportedOperationException\n       throw new UnsupportedOperationException();\n     }\n", "projectName": "apache.hbase", "bugLineNum": 472, "bugNodeStartChar": 17488, "bugNodeLength": 175, "fixLineNum": 472, "fixNodeStartChar": 17488, "fixNodeLength": 183, "sourceBeforeFix": "@Override public Cell deepClone(){   throw new UnsupportedOperationException(); } ", "sourceAfterFix": "@Override public ExtendedCell deepClone(){   throw new UnsupportedOperationException(); } "}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "fc13cf7d7843029d807878869e3c64cace5640dd", "fixCommitParentSHA1": "efb95a17945cc91aa639396f6f6c528b52c71fcb", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\nindex 00ec0fc..bc905e5 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/io/encoding/BufferedDataBlockEncoder.java\n@@ -470,7 +470,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       // This is not used in actual flow. Throwing UnsupportedOperationException\n       throw new UnsupportedOperationException();\n     }\n@@ -715,7 +715,7 @@\n     }\n \n     @Override\n-    public Cell deepClone() {\n+    public ExtendedCell deepClone() {\n       // This is not used in actual flow. Throwing UnsupportedOperationException\n       throw new UnsupportedOperationException();\n     }\n", "projectName": "apache.hbase", "bugLineNum": 717, "bugNodeStartChar": 23910, "bugNodeLength": 175, "fixLineNum": 717, "fixNodeStartChar": 23910, "fixNodeLength": 183, "sourceBeforeFix": "@Override public Cell deepClone(){   throw new UnsupportedOperationException(); } ", "sourceAfterFix": "@Override public ExtendedCell deepClone(){   throw new UnsupportedOperationException(); } "}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "c2eebfdb613427fa3314b7ee13c3b9f34ce4c120", "fixCommitParentSHA1": "f64512bee11112454fc3728fe5d344a838781e26", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/SplitTableRegionProcedure.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/SplitTableRegionProcedure.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/SplitTableRegionProcedure.java\nindex ff7e60f..219b67b 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/SplitTableRegionProcedure.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/assignment/SplitTableRegionProcedure.java\n@@ -536,13 +536,13 @@\n     final TableDescriptor htd = env.getMasterServices().getTableDescriptors().get(getTableName());\n     for (Map.Entry<String, Collection<StoreFileInfo>>e: files.entrySet()) {\n       byte [] familyName = Bytes.toBytes(e.getKey());\n-      final HColumnDescriptor hcd = htd.getFamily(familyName);\n+      final ColumnFamilyDescriptor hcd = htd.getColumnFamily(familyName);\n       final Collection<StoreFileInfo> storeFiles = e.getValue();\n       if (storeFiles != null && storeFiles.size() > 0) {\n         final CacheConfig cacheConf = new CacheConfig(conf, hcd);\n         for (StoreFileInfo storeFileInfo: storeFiles) {\n           StoreFileSplitter sfs =\n-              new StoreFileSplitter(regionFs, family.getBytes(), new HStoreFile(mfs.getFileSystem(),\n+              new StoreFileSplitter(regionFs, familyName, new HStoreFile(mfs.getFileSystem(),\n                   storeFileInfo, conf, cacheConf, hcd.getBloomFilterType(), true));\n           futures.add(threadPool.submit(sfs));\n         }\n", "projectName": "apache.hbase", "bugLineNum": 539, "bugNodeStartChar": 22250, "bugNodeLength": 56, "fixLineNum": 539, "fixNodeStartChar": 22250, "fixNodeLength": 67, "sourceBeforeFix": "final HColumnDescriptor hcd=htd.getFamily(familyName); ", "sourceAfterFix": "final ColumnFamilyDescriptor hcd=htd.getColumnFamily(familyName); "}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "8b75e9ed91c0a6c100917d24cdb29e8a4b14390e", "fixCommitParentSHA1": "837bb9ece796aee9bc1f82ec45414ea52ac33f80", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java\nindex ad91617..d0e3f90 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java\n@@ -190,11 +190,11 @@\n       // Prefetch online tables/namespaces\n       for (TableName table: QuotaCache.this.rsServices.getOnlineTables()) {\n         if (table.isSystemTable()) continue;\n-        if (!QuotaCache.this.tableQuotaCache.contains(table)) {\n+        if (!QuotaCache.this.tableQuotaCache.containsKey(table)) {\n           QuotaCache.this.tableQuotaCache.putIfAbsent(table, new QuotaState());\n         }\n         String ns = table.getNamespaceAsString();\n-        if (!QuotaCache.this.namespaceQuotaCache.contains(ns)) {\n+        if (!QuotaCache.this.namespaceQuotaCache.containsKey(ns)) {\n           QuotaCache.this.namespaceQuotaCache.putIfAbsent(ns, new QuotaState());\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 193, "bugNodeStartChar": 6900, "bugNodeLength": 47, "fixLineNum": 193, "fixNodeStartChar": 6900, "fixNodeLength": 50, "sourceBeforeFix": "QuotaCache.this.tableQuotaCache.contains(table)", "sourceAfterFix": "QuotaCache.this.tableQuotaCache.containsKey(table)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "8b75e9ed91c0a6c100917d24cdb29e8a4b14390e", "fixCommitParentSHA1": "837bb9ece796aee9bc1f82ec45414ea52ac33f80", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java\nindex ad91617..d0e3f90 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java\n@@ -190,11 +190,11 @@\n       // Prefetch online tables/namespaces\n       for (TableName table: QuotaCache.this.rsServices.getOnlineTables()) {\n         if (table.isSystemTable()) continue;\n-        if (!QuotaCache.this.tableQuotaCache.contains(table)) {\n+        if (!QuotaCache.this.tableQuotaCache.containsKey(table)) {\n           QuotaCache.this.tableQuotaCache.putIfAbsent(table, new QuotaState());\n         }\n         String ns = table.getNamespaceAsString();\n-        if (!QuotaCache.this.namespaceQuotaCache.contains(ns)) {\n+        if (!QuotaCache.this.namespaceQuotaCache.containsKey(ns)) {\n           QuotaCache.this.namespaceQuotaCache.putIfAbsent(ns, new QuotaState());\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 193, "bugNodeStartChar": 6900, "bugNodeLength": 47, "fixLineNum": 193, "fixNodeStartChar": 6900, "fixNodeLength": 50, "sourceBeforeFix": "QuotaCache.this.tableQuotaCache.contains(table)", "sourceAfterFix": "QuotaCache.this.tableQuotaCache.containsKey(table)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "8b75e9ed91c0a6c100917d24cdb29e8a4b14390e", "fixCommitParentSHA1": "837bb9ece796aee9bc1f82ec45414ea52ac33f80", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java\nindex ad91617..d0e3f90 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java\n@@ -190,11 +190,11 @@\n       // Prefetch online tables/namespaces\n       for (TableName table: QuotaCache.this.rsServices.getOnlineTables()) {\n         if (table.isSystemTable()) continue;\n-        if (!QuotaCache.this.tableQuotaCache.contains(table)) {\n+        if (!QuotaCache.this.tableQuotaCache.containsKey(table)) {\n           QuotaCache.this.tableQuotaCache.putIfAbsent(table, new QuotaState());\n         }\n         String ns = table.getNamespaceAsString();\n-        if (!QuotaCache.this.namespaceQuotaCache.contains(ns)) {\n+        if (!QuotaCache.this.namespaceQuotaCache.containsKey(ns)) {\n           QuotaCache.this.namespaceQuotaCache.putIfAbsent(ns, new QuotaState());\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 197, "bugNodeStartChar": 7104, "bugNodeLength": 48, "fixLineNum": 197, "fixNodeStartChar": 7104, "fixNodeLength": 51, "sourceBeforeFix": "QuotaCache.this.namespaceQuotaCache.contains(ns)", "sourceAfterFix": "QuotaCache.this.namespaceQuotaCache.containsKey(ns)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "8b75e9ed91c0a6c100917d24cdb29e8a4b14390e", "fixCommitParentSHA1": "837bb9ece796aee9bc1f82ec45414ea52ac33f80", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java\nindex ad91617..d0e3f90 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/quotas/QuotaCache.java\n@@ -190,11 +190,11 @@\n       // Prefetch online tables/namespaces\n       for (TableName table: QuotaCache.this.rsServices.getOnlineTables()) {\n         if (table.isSystemTable()) continue;\n-        if (!QuotaCache.this.tableQuotaCache.contains(table)) {\n+        if (!QuotaCache.this.tableQuotaCache.containsKey(table)) {\n           QuotaCache.this.tableQuotaCache.putIfAbsent(table, new QuotaState());\n         }\n         String ns = table.getNamespaceAsString();\n-        if (!QuotaCache.this.namespaceQuotaCache.contains(ns)) {\n+        if (!QuotaCache.this.namespaceQuotaCache.containsKey(ns)) {\n           QuotaCache.this.namespaceQuotaCache.putIfAbsent(ns, new QuotaState());\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 197, "bugNodeStartChar": 7104, "bugNodeLength": 48, "fixLineNum": 197, "fixNodeStartChar": 7104, "fixNodeLength": 51, "sourceBeforeFix": "QuotaCache.this.namespaceQuotaCache.contains(ns)", "sourceAfterFix": "QuotaCache.this.namespaceQuotaCache.containsKey(ns)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "c0f265384f09d5b36e2065083922ba428edef798", "fixCommitParentSHA1": "17007685c1ad2c4b7e672afaaf43b50f6c3a7c5c", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPaginationFilter.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPaginationFilter.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPaginationFilter.java\nindex 696f868..2ce9746 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPaginationFilter.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/filter/ColumnPaginationFilter.java\n@@ -207,7 +207,7 @@\n \n     ColumnPaginationFilter other = (ColumnPaginationFilter)o;\n     if (this.columnOffset != null) {\n-      return this.getLimit() == this.getLimit() &&\n+      return this.getLimit() == other.getLimit() &&\n           Bytes.equals(this.getColumnOffset(), other.getColumnOffset());\n     }\n     return this.getLimit() == other.getLimit() && this.getOffset() == other.getOffset();\n", "projectName": "apache.hbase", "bugLineNum": 210, "bugNodeStartChar": 7365, "bugNodeLength": 4, "fixLineNum": 210, "fixNodeStartChar": 7365, "fixNodeLength": 5, "sourceBeforeFix": "this.getLimit()", "sourceAfterFix": "other.getLimit()"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "e39e0e634a2252a352ad799bc2957c72e8d2d2e9", "fixCommitParentSHA1": "55d6dcaf877cc5223e679736eb613173229c18be", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java\nindex ca7dfd4..ab6b0ef 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreFileScanner.java\n@@ -129,7 +129,7 @@\n     List<StoreFile> sorted_files = new ArrayList<>(files);\n     Collections.sort(sorted_files, StoreFile.Comparators.SEQ_ID);\n     for (int i = 0; i < sorted_files.size(); i++) {\n-      StoreFileReader r = sorted_files.get(i).createReader();\n+      StoreFileReader r = sorted_files.get(i).createReader(canUseDrop);\n       r.setReplicaStoreFile(isPrimaryReplica);\n       StoreFileScanner scanner = r.getStoreFileScanner(cacheBlocks, usePread, isCompaction, readPt,\n         i, matcher != null ? !matcher.hasNullColumnInQuery() : false);\n", "projectName": "apache.hbase", "bugLineNum": 132, "bugNodeStartChar": 5405, "bugNodeLength": 34, "fixLineNum": 132, "fixNodeStartChar": 5405, "fixNodeLength": 44, "sourceBeforeFix": "sorted_files.get(i).createReader()", "sourceAfterFix": "sorted_files.get(i).createReader(canUseDrop)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "d08bafad1a5a9bd52e494a00fe7434a90a906b33", "fixCommitParentSHA1": "350904e90f33dc31f40ab9560848e37745b9c2c5", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/SimpleRpcScheduler.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/SimpleRpcScheduler.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/SimpleRpcScheduler.java\nindex 1f7e8ba..616f741 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/SimpleRpcScheduler.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/ipc/SimpleRpcScheduler.java\n@@ -87,7 +87,7 @@\n     } else {\n       if (RpcExecutor.isFifoQueueType(callQueueType)) {\n         callExecutor = new FastPathBalancedQueueRpcExecutor(\"deafult.FPBQ\", handlerCount,\n-            maxPriorityQueueLength, priority, conf, server);\n+            maxQueueLength, priority, conf, server);\n       } else {\n         callExecutor = new BalancedQueueRpcExecutor(\"deafult.BQ\", handlerCount, maxQueueLength,\n             priority, conf, server);\n", "projectName": "apache.hbase", "bugLineNum": 89, "bugNodeStartChar": 3969, "bugNodeLength": 126, "fixLineNum": 89, "fixNodeStartChar": 3969, "fixNodeLength": 118, "sourceBeforeFix": "new FastPathBalancedQueueRpcExecutor(\"deafult.FPBQ\",handlerCount,maxPriorityQueueLength,priority,conf,server)", "sourceAfterFix": "new FastPathBalancedQueueRpcExecutor(\"deafult.FPBQ\",handlerCount,maxQueueLength,priority,conf,server)"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "06a260f107ba5ab489e7d28256ee6bc9530d3416", "fixCommitParentSHA1": "489c8872c14fc8c4c9cd5d36b1953bf5afcf08ec", "bugFilePath": "hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java", "fixPatch": "diff --git a/hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java b/hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java\nindex 16f1e71..d35ef84 100644\n--- a/hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java\n+++ b/hbase-it/src/test/java/org/apache/hadoop/hbase/DistributedHBaseCluster.java\n@@ -269,7 +269,7 @@\n   public ServerName getServerHoldingRegion(TableName tn, byte[] regionName) throws IOException {\n     HRegionLocation regionLoc = null;\n     try (RegionLocator locator = connection.getRegionLocator(tn)) {\n-      regionLoc = locator.getRegionLocation(regionName);\n+      regionLoc = locator.getRegionLocation(regionName, true);\n     }\n     if (regionLoc == null) {\n       LOG.warn(\"Cannot find region server holding region \" + Bytes.toString(regionName) +\n", "projectName": "apache.hbase", "bugLineNum": 272, "bugNodeStartChar": 9935, "bugNodeLength": 37, "fixLineNum": 272, "fixNodeStartChar": 9935, "fixNodeLength": 43, "sourceBeforeFix": "locator.getRegionLocation(regionName)", "sourceAfterFix": "locator.getRegionLocation(regionName,true)"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "5c77a7dcd455f7a6e0ba3f289266032be687dc4f", "fixCommitParentSHA1": "9a78d008841726ec2029215cddf0c0b2141771ae", "bugFilePath": "hbase-endpoint/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java", "fixPatch": "diff --git a/hbase-endpoint/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java b/hbase-endpoint/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java\nindex 3fdd8cb..14a2bf9 100644\n--- a/hbase-endpoint/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java\n+++ b/hbase-endpoint/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java\n@@ -170,7 +170,7 @@\n     ResultScanner scan = table.getScanner(fam1);\n     scan.next();\n     scan.close();\n-    counter = verifyCount(counter + 2);\n+    counter = verifyCount(counter + 1);\n \n     Get g2 = new Get(row);\n     table.get(Lists.newArrayList(g, g2));\n@@ -189,7 +189,7 @@\n \n     // reversed, regular\n     scanInfo.setSmall(false);\n-    counter = doScan(table, scanInfo, counter + 2);\n+    counter = doScan(table, scanInfo, counter + 1);\n \n     table.close();\n     connection.close();\n", "projectName": "apache.hbase", "bugLineNum": 173, "bugNodeStartChar": 6176, "bugNodeLength": 11, "fixLineNum": 173, "fixNodeStartChar": 6176, "fixNodeLength": 11, "sourceBeforeFix": "counter + 2", "sourceAfterFix": "counter + 1"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "5c77a7dcd455f7a6e0ba3f289266032be687dc4f", "fixCommitParentSHA1": "9a78d008841726ec2029215cddf0c0b2141771ae", "bugFilePath": "hbase-endpoint/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java", "fixPatch": "diff --git a/hbase-endpoint/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java b/hbase-endpoint/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java\nindex 3fdd8cb..14a2bf9 100644\n--- a/hbase-endpoint/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java\n+++ b/hbase-endpoint/src/test/java/org/apache/hadoop/hbase/client/TestRpcControllerFactory.java\n@@ -170,7 +170,7 @@\n     ResultScanner scan = table.getScanner(fam1);\n     scan.next();\n     scan.close();\n-    counter = verifyCount(counter + 2);\n+    counter = verifyCount(counter + 1);\n \n     Get g2 = new Get(row);\n     table.get(Lists.newArrayList(g, g2));\n@@ -189,7 +189,7 @@\n \n     // reversed, regular\n     scanInfo.setSmall(false);\n-    counter = doScan(table, scanInfo, counter + 2);\n+    counter = doScan(table, scanInfo, counter + 1);\n \n     table.close();\n     connection.close();\n", "projectName": "apache.hbase", "bugLineNum": 192, "bugNodeStartChar": 6739, "bugNodeLength": 11, "fixLineNum": 192, "fixNodeStartChar": 6739, "fixNodeLength": 11, "sourceBeforeFix": "counter + 2", "sourceAfterFix": "counter + 1"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "79073cd40c3b9a32d4509381c9d2763be42045ba", "fixCommitParentSHA1": "6ce05d44e5f6c78df1eae79d682b49ae7d410a89", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java\nindex 5856b19..eeb4ebf 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestIOFencing.java\n@@ -241,7 +241,7 @@\n     // Insert our custom region\n     c.setClass(HConstants.REGION_IMPL, regionClass, HRegion.class);\n     // Encourage plenty of flushes\n-    c.setLong(\"hbase.hregion.memstore.flush.size\", 100000);\n+    c.setLong(\"hbase.hregion.memstore.flush.size\", 25000);\n     c.set(HConstants.HBASE_REGION_SPLIT_POLICY_KEY, ConstantSizeRegionSplitPolicy.class.getName());\n     // Only run compaction when we tell it to\n     c.setInt(\"hbase.hstore.compaction.min\",1);\n", "projectName": "apache.hbase", "bugLineNum": 244, "bugNodeStartChar": 10331, "bugNodeLength": 54, "fixLineNum": 244, "fixNodeStartChar": 10331, "fixNodeLength": 53, "sourceBeforeFix": "c.setLong(\"hbase.hregion.memstore.flush.size\",100000)", "sourceAfterFix": "c.setLong(\"hbase.hregion.memstore.flush.size\",25000)"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "a9526f6fdb12efc7d6195185cfc2c8e6aa927af1", "fixCommitParentSHA1": "d35b65883c07a4d8d378ce633bb1cc5185ad43c5", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionUtils.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionUtils.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionUtils.java\nindex e0030e8..42d5ce8 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionUtils.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/ConnectionUtils.java\n@@ -230,7 +230,7 @@\n \n   // A byte array in which all elements are the max byte, and it is used to\n   // construct closest front row\n-  static byte[] MAX_BYTE_ARRAY = Bytes.createMaxByteArray(9);\n+  public static byte[] MAX_BYTE_ARRAY = Bytes.createMaxByteArray(9);\n \n   /**\n    * Create the closest row after the specified row\n", "projectName": "apache.hbase", "bugLineNum": 233, "bugNodeStartChar": 8865, "bugNodeLength": 59, "fixLineNum": 233, "fixNodeStartChar": 8865, "fixNodeLength": 66, "sourceBeforeFix": "8", "sourceAfterFix": "9"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "5a7c8dcb683515f0fe6b3de6c18e78c749f3729a", "fixCommitParentSHA1": "0bb18de91c69ec43dc5118e59035686c586f3372", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\nindex d01f510..ab075db 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\n@@ -996,7 +996,7 @@\n     private static final String MOVE_COST_KEY = \"hbase.master.balancer.stochastic.moveCost\";\n     private static final String MAX_MOVES_PERCENT_KEY =\n         \"hbase.master.balancer.stochastic.maxMovePercent\";\n-    private static final float DEFAULT_MOVE_COST = 100;\n+    private static final float DEFAULT_MOVE_COST = 7;\n     private static final int DEFAULT_MAX_MOVES = 600;\n     private static final float DEFAULT_MAX_MOVE_PERCENT = 0.25f;\n \n", "projectName": "apache.hbase", "bugLineNum": 999, "bugNodeStartChar": 35861, "bugNodeLength": 23, "fixLineNum": 999, "fixNodeStartChar": 35861, "fixNodeLength": 21, "sourceBeforeFix": "DEFAULT_MOVE_COST=100", "sourceAfterFix": "DEFAULT_MOVE_COST=7"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "a975408b7c90e2d545a7a490687cddb717d43807", "fixCommitParentSHA1": "29a192ef3cbe3b9cc12a6ee38f39e1199ac9790f", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\nindex 7242791..85b3913 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\n@@ -460,7 +460,7 @@\n \n   public static boolean matchingRow(final Cell left, final byte[] buf) {\n     if (buf == null) {\n-      return left.getQualifierLength() == 0;\n+      return left.getRowLength() == 0;\n     }\n     return matchingRow(left, buf, 0, buf.length);\n   }\n", "projectName": "apache.hbase", "bugLineNum": 463, "bugNodeStartChar": 16750, "bugNodeLength": 25, "fixLineNum": 463, "fixNodeStartChar": 16750, "fixNodeLength": 19, "sourceBeforeFix": "left.getQualifierLength()", "sourceAfterFix": "left.getRowLength()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "a975408b7c90e2d545a7a490687cddb717d43807", "fixCommitParentSHA1": "29a192ef3cbe3b9cc12a6ee38f39e1199ac9790f", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\nindex 7242791..85b3913 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellUtil.java\n@@ -460,7 +460,7 @@\n \n   public static boolean matchingRow(final Cell left, final byte[] buf) {\n     if (buf == null) {\n-      return left.getQualifierLength() == 0;\n+      return left.getRowLength() == 0;\n     }\n     return matchingRow(left, buf, 0, buf.length);\n   }\n", "projectName": "apache.hbase", "bugLineNum": 463, "bugNodeStartChar": 16750, "bugNodeLength": 25, "fixLineNum": 463, "fixNodeStartChar": 16750, "fixNodeLength": 19, "sourceBeforeFix": "left.getQualifierLength()", "sourceAfterFix": "left.getRowLength()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "2439f7a68843ddff5b468a203e5856705e574599", "fixCommitParentSHA1": "95a13b51ee052eb73882682e8f009bfa1e914866", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/wal/RegionGroupingProvider.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/wal/RegionGroupingProvider.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/wal/RegionGroupingProvider.java\nindex 2885428..0aeaccf 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/wal/RegionGroupingProvider.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/wal/RegionGroupingProvider.java\n@@ -185,7 +185,7 @@\n   }\n \n   private WAL getWAL(final String group) throws IOException {\n-    WAL log = cached.get(walCacheLock);\n+    WAL log = cached.get(group);\n     if (null == log) {\n       // only lock when need to create wal, and need to lock since\n       // creating hlog on fs is time consuming\n", "projectName": "apache.hbase", "bugLineNum": 188, "bugNodeStartChar": 7725, "bugNodeLength": 24, "fixLineNum": 188, "fixNodeStartChar": 7725, "fixNodeLength": 17, "sourceBeforeFix": "cached.get(walCacheLock)", "sourceAfterFix": "cached.get(group)"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "95a13b51ee052eb73882682e8f009bfa1e914866", "fixCommitParentSHA1": "6e2c5d216eb1f4cacad7c5d7ed43b67785cabb67", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\nindex 538b390..dd98d26 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\n@@ -228,7 +228,7 @@\n         && getTimeBetweenRuns() > getMaximumAllowedTimeBetweenRuns();\n   }\n \n-  private synchronized double getMaximumAllowedTimeBetweenRuns() {\n+  private double getMaximumAllowedTimeBetweenRuns() {\n     // Threshold used to determine if the Chore's current run started too late\n     return 1.5 * period;\n   }\n@@ -268,23 +268,23 @@\n     choreServicer = null;\n   }\n \n-  public synchronized String getName() {\n+  public String getName() {\n     return name;\n   }\n \n-  public synchronized Stoppable getStopper() {\n+  public Stoppable getStopper() {\n     return stopper;\n   }\n \n-  public synchronized int getPeriod() {\n+  public int getPeriod() {\n     return period;\n   }\n \n-  public synchronized long getInitialDelay() {\n+  public long getInitialDelay() {\n     return initialDelay;\n   }\n \n-  public final synchronized TimeUnit getTimeUnit() {\n+  public TimeUnit getTimeUnit() {\n     return timeUnit;\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 231, "bugNodeStartChar": 9393, "bugNodeLength": 172, "fixLineNum": 231, "fixNodeStartChar": 9393, "fixNodeLength": 159, "sourceBeforeFix": "34", "sourceAfterFix": "2"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "95a13b51ee052eb73882682e8f009bfa1e914866", "fixCommitParentSHA1": "6e2c5d216eb1f4cacad7c5d7ed43b67785cabb67", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\nindex 538b390..dd98d26 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\n@@ -228,7 +228,7 @@\n         && getTimeBetweenRuns() > getMaximumAllowedTimeBetweenRuns();\n   }\n \n-  private synchronized double getMaximumAllowedTimeBetweenRuns() {\n+  private double getMaximumAllowedTimeBetweenRuns() {\n     // Threshold used to determine if the Chore's current run started too late\n     return 1.5 * period;\n   }\n@@ -268,23 +268,23 @@\n     choreServicer = null;\n   }\n \n-  public synchronized String getName() {\n+  public String getName() {\n     return name;\n   }\n \n-  public synchronized Stoppable getStopper() {\n+  public Stoppable getStopper() {\n     return stopper;\n   }\n \n-  public synchronized int getPeriod() {\n+  public int getPeriod() {\n     return period;\n   }\n \n-  public synchronized long getInitialDelay() {\n+  public long getInitialDelay() {\n     return initialDelay;\n   }\n \n-  public final synchronized TimeUnit getTimeUnit() {\n+  public TimeUnit getTimeUnit() {\n     return timeUnit;\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 271, "bugNodeStartChar": 10609, "bugNodeLength": 59, "fixLineNum": 271, "fixNodeStartChar": 10609, "fixNodeLength": 46, "sourceBeforeFix": "33", "sourceAfterFix": "1"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "95a13b51ee052eb73882682e8f009bfa1e914866", "fixCommitParentSHA1": "6e2c5d216eb1f4cacad7c5d7ed43b67785cabb67", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\nindex 538b390..dd98d26 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\n@@ -228,7 +228,7 @@\n         && getTimeBetweenRuns() > getMaximumAllowedTimeBetweenRuns();\n   }\n \n-  private synchronized double getMaximumAllowedTimeBetweenRuns() {\n+  private double getMaximumAllowedTimeBetweenRuns() {\n     // Threshold used to determine if the Chore's current run started too late\n     return 1.5 * period;\n   }\n@@ -268,23 +268,23 @@\n     choreServicer = null;\n   }\n \n-  public synchronized String getName() {\n+  public String getName() {\n     return name;\n   }\n \n-  public synchronized Stoppable getStopper() {\n+  public Stoppable getStopper() {\n     return stopper;\n   }\n \n-  public synchronized int getPeriod() {\n+  public int getPeriod() {\n     return period;\n   }\n \n-  public synchronized long getInitialDelay() {\n+  public long getInitialDelay() {\n     return initialDelay;\n   }\n \n-  public final synchronized TimeUnit getTimeUnit() {\n+  public TimeUnit getTimeUnit() {\n     return timeUnit;\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 275, "bugNodeStartChar": 10672, "bugNodeLength": 68, "fixLineNum": 275, "fixNodeStartChar": 10672, "fixNodeLength": 55, "sourceBeforeFix": "33", "sourceAfterFix": "1"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "95a13b51ee052eb73882682e8f009bfa1e914866", "fixCommitParentSHA1": "6e2c5d216eb1f4cacad7c5d7ed43b67785cabb67", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\nindex 538b390..dd98d26 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\n@@ -228,7 +228,7 @@\n         && getTimeBetweenRuns() > getMaximumAllowedTimeBetweenRuns();\n   }\n \n-  private synchronized double getMaximumAllowedTimeBetweenRuns() {\n+  private double getMaximumAllowedTimeBetweenRuns() {\n     // Threshold used to determine if the Chore's current run started too late\n     return 1.5 * period;\n   }\n@@ -268,23 +268,23 @@\n     choreServicer = null;\n   }\n \n-  public synchronized String getName() {\n+  public String getName() {\n     return name;\n   }\n \n-  public synchronized Stoppable getStopper() {\n+  public Stoppable getStopper() {\n     return stopper;\n   }\n \n-  public synchronized int getPeriod() {\n+  public int getPeriod() {\n     return period;\n   }\n \n-  public synchronized long getInitialDelay() {\n+  public long getInitialDelay() {\n     return initialDelay;\n   }\n \n-  public final synchronized TimeUnit getTimeUnit() {\n+  public TimeUnit getTimeUnit() {\n     return timeUnit;\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 279, "bugNodeStartChar": 10744, "bugNodeLength": 60, "fixLineNum": 279, "fixNodeStartChar": 10744, "fixNodeLength": 47, "sourceBeforeFix": "33", "sourceAfterFix": "1"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "95a13b51ee052eb73882682e8f009bfa1e914866", "fixCommitParentSHA1": "6e2c5d216eb1f4cacad7c5d7ed43b67785cabb67", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\nindex 538b390..dd98d26 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\n@@ -228,7 +228,7 @@\n         && getTimeBetweenRuns() > getMaximumAllowedTimeBetweenRuns();\n   }\n \n-  private synchronized double getMaximumAllowedTimeBetweenRuns() {\n+  private double getMaximumAllowedTimeBetweenRuns() {\n     // Threshold used to determine if the Chore's current run started too late\n     return 1.5 * period;\n   }\n@@ -268,23 +268,23 @@\n     choreServicer = null;\n   }\n \n-  public synchronized String getName() {\n+  public String getName() {\n     return name;\n   }\n \n-  public synchronized Stoppable getStopper() {\n+  public Stoppable getStopper() {\n     return stopper;\n   }\n \n-  public synchronized int getPeriod() {\n+  public int getPeriod() {\n     return period;\n   }\n \n-  public synchronized long getInitialDelay() {\n+  public long getInitialDelay() {\n     return initialDelay;\n   }\n \n-  public final synchronized TimeUnit getTimeUnit() {\n+  public TimeUnit getTimeUnit() {\n     return timeUnit;\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 283, "bugNodeStartChar": 10808, "bugNodeLength": 73, "fixLineNum": 283, "fixNodeStartChar": 10808, "fixNodeLength": 60, "sourceBeforeFix": "33", "sourceAfterFix": "1"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "95a13b51ee052eb73882682e8f009bfa1e914866", "fixCommitParentSHA1": "6e2c5d216eb1f4cacad7c5d7ed43b67785cabb67", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\nindex 538b390..dd98d26 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/ScheduledChore.java\n@@ -228,7 +228,7 @@\n         && getTimeBetweenRuns() > getMaximumAllowedTimeBetweenRuns();\n   }\n \n-  private synchronized double getMaximumAllowedTimeBetweenRuns() {\n+  private double getMaximumAllowedTimeBetweenRuns() {\n     // Threshold used to determine if the Chore's current run started too late\n     return 1.5 * period;\n   }\n@@ -268,23 +268,23 @@\n     choreServicer = null;\n   }\n \n-  public synchronized String getName() {\n+  public String getName() {\n     return name;\n   }\n \n-  public synchronized Stoppable getStopper() {\n+  public Stoppable getStopper() {\n     return stopper;\n   }\n \n-  public synchronized int getPeriod() {\n+  public int getPeriod() {\n     return period;\n   }\n \n-  public synchronized long getInitialDelay() {\n+  public long getInitialDelay() {\n     return initialDelay;\n   }\n \n-  public final synchronized TimeUnit getTimeUnit() {\n+  public TimeUnit getTimeUnit() {\n     return timeUnit;\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 287, "bugNodeStartChar": 10885, "bugNodeLength": 75, "fixLineNum": 287, "fixNodeStartChar": 10885, "fixNodeLength": 56, "sourceBeforeFix": "49", "sourceAfterFix": "1"}, {"bugType": "CHANGE_OPERAND", "fixCommitSHA1": "a0d72051dbace9dc4ec6ab288f2f6553e2ee7307", "fixCommitParentSHA1": "1b0b67fb7c84f65aa35c4a840e8af3fd930916b8", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\nindex 644e89b..40c5046 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\n@@ -197,12 +197,12 @@\n            ServerRegionReplicaUtil.isRegionReplicaStoreFileRefreshEnabled(conf) &&\n            (bestRegionReplica.getMemstoreSize()\n                > secondaryMultiplier * regionToFlush.getMemstoreSize()))) {\n-        LOG.info(\"Refreshing storefiles of region \" + regionToFlush +\n+        LOG.info(\"Refreshing storefiles of region \" + bestRegionReplica +\n           \" due to global heap pressure. memstore size=\" + StringUtils.humanReadableInt(\n             server.getRegionServerAccounting().getGlobalMemstoreSize()));\n         flushedOne = refreshStoreFilesAndReclaimMemory(bestRegionReplica);\n         if (!flushedOne) {\n-          LOG.info(\"Excluding secondary region \" + regionToFlush +\n+          LOG.info(\"Excluding secondary region \" + bestRegionReplica +\n               \" - trying to find a different region to refresh files.\");\n           excludedRegions.add(bestRegionReplica);\n         }\n", "projectName": "apache.hbase", "bugLineNum": 200, "bugNodeStartChar": 8452, "bugNodeLength": 213, "fixLineNum": 200, "fixNodeStartChar": 8452, "fixNodeLength": 217, "sourceBeforeFix": "\"Refreshing storefiles of region \" + regionToFlush + \" due to global heap pressure. memstore size=\"+ StringUtils.humanReadableInt(server.getRegionServerAccounting().getGlobalMemstoreSize())", "sourceAfterFix": "\"Refreshing storefiles of region \" + bestRegionReplica + \" due to global heap pressure. memstore size=\"+ StringUtils.humanReadableInt(server.getRegionServerAccounting().getGlobalMemstoreSize())"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "a0d72051dbace9dc4ec6ab288f2f6553e2ee7307", "fixCommitParentSHA1": "1b0b67fb7c84f65aa35c4a840e8af3fd930916b8", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\nindex 644e89b..40c5046 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\n@@ -197,12 +197,12 @@\n            ServerRegionReplicaUtil.isRegionReplicaStoreFileRefreshEnabled(conf) &&\n            (bestRegionReplica.getMemstoreSize()\n                > secondaryMultiplier * regionToFlush.getMemstoreSize()))) {\n-        LOG.info(\"Refreshing storefiles of region \" + regionToFlush +\n+        LOG.info(\"Refreshing storefiles of region \" + bestRegionReplica +\n           \" due to global heap pressure. memstore size=\" + StringUtils.humanReadableInt(\n             server.getRegionServerAccounting().getGlobalMemstoreSize()));\n         flushedOne = refreshStoreFilesAndReclaimMemory(bestRegionReplica);\n         if (!flushedOne) {\n-          LOG.info(\"Excluding secondary region \" + regionToFlush +\n+          LOG.info(\"Excluding secondary region \" + bestRegionReplica +\n               \" - trying to find a different region to refresh files.\");\n           excludedRegions.add(bestRegionReplica);\n         }\n", "projectName": "apache.hbase", "bugLineNum": 200, "bugNodeStartChar": 8452, "bugNodeLength": 213, "fixLineNum": 200, "fixNodeStartChar": 8452, "fixNodeLength": 217, "sourceBeforeFix": "\"Refreshing storefiles of region \" + regionToFlush + \" due to global heap pressure. memstore size=\"+ StringUtils.humanReadableInt(server.getRegionServerAccounting().getGlobalMemstoreSize())", "sourceAfterFix": "\"Refreshing storefiles of region \" + bestRegionReplica + \" due to global heap pressure. memstore size=\"+ StringUtils.humanReadableInt(server.getRegionServerAccounting().getGlobalMemstoreSize())"}, {"bugType": "CHANGE_OPERAND", "fixCommitSHA1": "a0d72051dbace9dc4ec6ab288f2f6553e2ee7307", "fixCommitParentSHA1": "1b0b67fb7c84f65aa35c4a840e8af3fd930916b8", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\nindex 644e89b..40c5046 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\n@@ -197,12 +197,12 @@\n            ServerRegionReplicaUtil.isRegionReplicaStoreFileRefreshEnabled(conf) &&\n            (bestRegionReplica.getMemstoreSize()\n                > secondaryMultiplier * regionToFlush.getMemstoreSize()))) {\n-        LOG.info(\"Refreshing storefiles of region \" + regionToFlush +\n+        LOG.info(\"Refreshing storefiles of region \" + bestRegionReplica +\n           \" due to global heap pressure. memstore size=\" + StringUtils.humanReadableInt(\n             server.getRegionServerAccounting().getGlobalMemstoreSize()));\n         flushedOne = refreshStoreFilesAndReclaimMemory(bestRegionReplica);\n         if (!flushedOne) {\n-          LOG.info(\"Excluding secondary region \" + regionToFlush +\n+          LOG.info(\"Excluding secondary region \" + bestRegionReplica +\n               \" - trying to find a different region to refresh files.\");\n           excludedRegions.add(bestRegionReplica);\n         }\n", "projectName": "apache.hbase", "bugLineNum": 205, "bugNodeStartChar": 8789, "bugNodeLength": 118, "fixLineNum": 205, "fixNodeStartChar": 8789, "fixNodeLength": 122, "sourceBeforeFix": "\"Excluding secondary region \" + regionToFlush + \" - trying to find a different region to refresh files.\"", "sourceAfterFix": "\"Excluding secondary region \" + bestRegionReplica + \" - trying to find a different region to refresh files.\""}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "a0d72051dbace9dc4ec6ab288f2f6553e2ee7307", "fixCommitParentSHA1": "1b0b67fb7c84f65aa35c4a840e8af3fd930916b8", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\nindex 644e89b..40c5046 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\n@@ -197,12 +197,12 @@\n            ServerRegionReplicaUtil.isRegionReplicaStoreFileRefreshEnabled(conf) &&\n            (bestRegionReplica.getMemstoreSize()\n                > secondaryMultiplier * regionToFlush.getMemstoreSize()))) {\n-        LOG.info(\"Refreshing storefiles of region \" + regionToFlush +\n+        LOG.info(\"Refreshing storefiles of region \" + bestRegionReplica +\n           \" due to global heap pressure. memstore size=\" + StringUtils.humanReadableInt(\n             server.getRegionServerAccounting().getGlobalMemstoreSize()));\n         flushedOne = refreshStoreFilesAndReclaimMemory(bestRegionReplica);\n         if (!flushedOne) {\n-          LOG.info(\"Excluding secondary region \" + regionToFlush +\n+          LOG.info(\"Excluding secondary region \" + bestRegionReplica +\n               \" - trying to find a different region to refresh files.\");\n           excludedRegions.add(bestRegionReplica);\n         }\n", "projectName": "apache.hbase", "bugLineNum": 205, "bugNodeStartChar": 8789, "bugNodeLength": 118, "fixLineNum": 205, "fixNodeStartChar": 8789, "fixNodeLength": 122, "sourceBeforeFix": "\"Excluding secondary region \" + regionToFlush + \" - trying to find a different region to refresh files.\"", "sourceAfterFix": "\"Excluding secondary region \" + bestRegionReplica + \" - trying to find a different region to refresh files.\""}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "41c8ec7aeae859808a217bd7a561e81be7e3c7ac", "fixCommitParentSHA1": "f5ad736282c8c9c27b14131919d60b72834ec9e4", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\nindex b118ecd..fa69d63 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\n@@ -1844,7 +1844,7 @@\n         // Update metrics.\n         postAppend(entry, EnvironmentEdgeManager.currentTime() - start);\n       } catch (Exception e) {\n-        LOG.fatal(\"Could not append. Requesting close of wal\", e);\n+        LOG.warn(\"Could not append. Requesting close of wal\", e);\n         requestLogRoll();\n         throw e;\n       }\n", "projectName": "apache.hbase", "bugLineNum": 1847, "bugNodeStartChar": 78024, "bugNodeLength": 57, "fixLineNum": 1847, "fixNodeStartChar": 78024, "fixNodeLength": 56, "sourceBeforeFix": "LOG.fatal(\"Could not append. Requesting close of wal\",e)", "sourceAfterFix": "LOG.warn(\"Could not append. Requesting close of wal\",e)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "41c8ec7aeae859808a217bd7a561e81be7e3c7ac", "fixCommitParentSHA1": "f5ad736282c8c9c27b14131919d60b72834ec9e4", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\nindex b118ecd..fa69d63 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\n@@ -1844,7 +1844,7 @@\n         // Update metrics.\n         postAppend(entry, EnvironmentEdgeManager.currentTime() - start);\n       } catch (Exception e) {\n-        LOG.fatal(\"Could not append. Requesting close of wal\", e);\n+        LOG.warn(\"Could not append. Requesting close of wal\", e);\n         requestLogRoll();\n         throw e;\n       }\n", "projectName": "apache.hbase", "bugLineNum": 1847, "bugNodeStartChar": 78024, "bugNodeLength": 57, "fixLineNum": 1847, "fixNodeStartChar": 78024, "fixNodeLength": 56, "sourceBeforeFix": "LOG.fatal(\"Could not append. Requesting close of wal\",e)", "sourceAfterFix": "LOG.warn(\"Could not append. Requesting close of wal\",e)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "5038fc76c950029c78681dff816d7465f6acbb91", "fixCommitParentSHA1": "0a500e5d305b0c75a6a357a5ff7a9210a615a007", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\nindex e390d6b..bd25a824 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n@@ -5663,7 +5663,7 @@\n \n       long size = 0;\n       for (Cell c : results) {\n-        size += CellUtil.estimatedHeapSizeOf(c);\n+        size += CellUtil.estimatedHeapSizeOfWithoutTags(c);\n       }\n \n       return size;\n", "projectName": "apache.hbase", "bugLineNum": 5666, "bugNodeStartChar": 226924, "bugNodeLength": 31, "fixLineNum": 5666, "fixNodeStartChar": 226924, "fixNodeLength": 42, "sourceBeforeFix": "CellUtil.estimatedHeapSizeOf(c)", "sourceAfterFix": "CellUtil.estimatedHeapSizeOfWithoutTags(c)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "5038fc76c950029c78681dff816d7465f6acbb91", "fixCommitParentSHA1": "0a500e5d305b0c75a6a357a5ff7a9210a615a007", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\nindex e390d6b..bd25a824 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n@@ -5663,7 +5663,7 @@\n \n       long size = 0;\n       for (Cell c : results) {\n-        size += CellUtil.estimatedHeapSizeOf(c);\n+        size += CellUtil.estimatedHeapSizeOfWithoutTags(c);\n       }\n \n       return size;\n", "projectName": "apache.hbase", "bugLineNum": 5666, "bugNodeStartChar": 226924, "bugNodeLength": 31, "fixLineNum": 5666, "fixNodeStartChar": 226924, "fixNodeLength": 42, "sourceBeforeFix": "CellUtil.estimatedHeapSizeOf(c)", "sourceAfterFix": "CellUtil.estimatedHeapSizeOfWithoutTags(c)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "5038fc76c950029c78681dff816d7465f6acbb91", "fixCommitParentSHA1": "0a500e5d305b0c75a6a357a5ff7a9210a615a007", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java\nindex 7ce4e0b..298d5bc 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java\n@@ -544,7 +544,7 @@\n             outResult.add(cell);\n             count++;\n             totalBytesRead += CellUtil.estimatedSerializedSizeOf(cell);\n-            totalHeapSize += CellUtil.estimatedHeapSizeOf(cell);\n+            totalHeapSize += CellUtil.estimatedHeapSizeOfWithoutTags(cell);\n             if (totalBytesRead > maxRowSize) {\n               throw new RowTooBigException(\"Max row size allowed: \" + maxRowSize\n               + \", but the row is bigger than that.\");\n", "projectName": "apache.hbase", "bugLineNum": 547, "bugNodeStartChar": 20280, "bugNodeLength": 34, "fixLineNum": 547, "fixNodeStartChar": 20280, "fixNodeLength": 45, "sourceBeforeFix": "CellUtil.estimatedHeapSizeOf(cell)", "sourceAfterFix": "CellUtil.estimatedHeapSizeOfWithoutTags(cell)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "5038fc76c950029c78681dff816d7465f6acbb91", "fixCommitParentSHA1": "0a500e5d305b0c75a6a357a5ff7a9210a615a007", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java\nindex 7ce4e0b..298d5bc 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/StoreScanner.java\n@@ -544,7 +544,7 @@\n             outResult.add(cell);\n             count++;\n             totalBytesRead += CellUtil.estimatedSerializedSizeOf(cell);\n-            totalHeapSize += CellUtil.estimatedHeapSizeOf(cell);\n+            totalHeapSize += CellUtil.estimatedHeapSizeOfWithoutTags(cell);\n             if (totalBytesRead > maxRowSize) {\n               throw new RowTooBigException(\"Max row size allowed: \" + maxRowSize\n               + \", but the row is bigger than that.\");\n", "projectName": "apache.hbase", "bugLineNum": 547, "bugNodeStartChar": 20280, "bugNodeLength": 34, "fixLineNum": 547, "fixNodeStartChar": 20280, "fixNodeLength": 45, "sourceBeforeFix": "CellUtil.estimatedHeapSizeOf(cell)", "sourceAfterFix": "CellUtil.estimatedHeapSizeOfWithoutTags(cell)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "6a95dd35511f4216481d8d0ffd4952ed1893a1c4", "fixCommitParentSHA1": "27cf749af884edae55454c885c7fb066f0a33c79", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java\nindex 9a45116..11aa5db 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java\n@@ -232,7 +232,7 @@\n     htd.addFamily(hcd);\n     htd.setOwner(USER_OWNER);\n     admin.createTable(htd, new byte[][] { Bytes.toBytes(\"s\") });\n-    TEST_UTIL.waitTableEnabled(TEST_TABLE.getTableName());\n+    TEST_UTIL.waitUntilAllRegionsAssigned(TEST_TABLE.getTableName());\n \n     HRegion region = TEST_UTIL.getHBaseCluster().getRegions(TEST_TABLE.getTableName()).get(0);\n     RegionCoprocessorHost rcpHost = region.getCoprocessorHost();\n@@ -930,7 +930,7 @@\n       setPermission(loadPath, FsPermission.valueOf(\"-rwxrwxrwx\"));\n \n       try (HTable table = (HTable)TEST_UTIL.getConnection().getTable(tableName)) {\n-        TEST_UTIL.waitTableEnabled(tableName);\n+        TEST_UTIL.waitUntilAllRegionsAssigned(tableName);\n         LoadIncrementalHFiles loader = new LoadIncrementalHFiles(conf);\n         loader.doBulkLoad(loadPath, table);\n       }\n", "projectName": "apache.hbase", "bugLineNum": 235, "bugNodeStartChar": 11035, "bugNodeLength": 53, "fixLineNum": 235, "fixNodeStartChar": 11035, "fixNodeLength": 64, "sourceBeforeFix": "TEST_UTIL.waitTableEnabled(TEST_TABLE.getTableName())", "sourceAfterFix": "TEST_UTIL.waitUntilAllRegionsAssigned(TEST_TABLE.getTableName())"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "6a95dd35511f4216481d8d0ffd4952ed1893a1c4", "fixCommitParentSHA1": "27cf749af884edae55454c885c7fb066f0a33c79", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java\nindex 9a45116..11aa5db 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java\n@@ -232,7 +232,7 @@\n     htd.addFamily(hcd);\n     htd.setOwner(USER_OWNER);\n     admin.createTable(htd, new byte[][] { Bytes.toBytes(\"s\") });\n-    TEST_UTIL.waitTableEnabled(TEST_TABLE.getTableName());\n+    TEST_UTIL.waitUntilAllRegionsAssigned(TEST_TABLE.getTableName());\n \n     HRegion region = TEST_UTIL.getHBaseCluster().getRegions(TEST_TABLE.getTableName()).get(0);\n     RegionCoprocessorHost rcpHost = region.getCoprocessorHost();\n@@ -930,7 +930,7 @@\n       setPermission(loadPath, FsPermission.valueOf(\"-rwxrwxrwx\"));\n \n       try (HTable table = (HTable)TEST_UTIL.getConnection().getTable(tableName)) {\n-        TEST_UTIL.waitTableEnabled(tableName);\n+        TEST_UTIL.waitUntilAllRegionsAssigned(tableName);\n         LoadIncrementalHFiles loader = new LoadIncrementalHFiles(conf);\n         loader.doBulkLoad(loadPath, table);\n       }\n", "projectName": "apache.hbase", "bugLineNum": 235, "bugNodeStartChar": 11035, "bugNodeLength": 53, "fixLineNum": 235, "fixNodeStartChar": 11035, "fixNodeLength": 64, "sourceBeforeFix": "TEST_UTIL.waitTableEnabled(TEST_TABLE.getTableName())", "sourceAfterFix": "TEST_UTIL.waitUntilAllRegionsAssigned(TEST_TABLE.getTableName())"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "6a95dd35511f4216481d8d0ffd4952ed1893a1c4", "fixCommitParentSHA1": "27cf749af884edae55454c885c7fb066f0a33c79", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java\nindex 9a45116..11aa5db 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java\n@@ -232,7 +232,7 @@\n     htd.addFamily(hcd);\n     htd.setOwner(USER_OWNER);\n     admin.createTable(htd, new byte[][] { Bytes.toBytes(\"s\") });\n-    TEST_UTIL.waitTableEnabled(TEST_TABLE.getTableName());\n+    TEST_UTIL.waitUntilAllRegionsAssigned(TEST_TABLE.getTableName());\n \n     HRegion region = TEST_UTIL.getHBaseCluster().getRegions(TEST_TABLE.getTableName()).get(0);\n     RegionCoprocessorHost rcpHost = region.getCoprocessorHost();\n@@ -930,7 +930,7 @@\n       setPermission(loadPath, FsPermission.valueOf(\"-rwxrwxrwx\"));\n \n       try (HTable table = (HTable)TEST_UTIL.getConnection().getTable(tableName)) {\n-        TEST_UTIL.waitTableEnabled(tableName);\n+        TEST_UTIL.waitUntilAllRegionsAssigned(tableName);\n         LoadIncrementalHFiles loader = new LoadIncrementalHFiles(conf);\n         loader.doBulkLoad(loadPath, table);\n       }\n", "projectName": "apache.hbase", "bugLineNum": 933, "bugNodeStartChar": 34298, "bugNodeLength": 37, "fixLineNum": 933, "fixNodeStartChar": 34298, "fixNodeLength": 48, "sourceBeforeFix": "TEST_UTIL.waitTableEnabled(tableName)", "sourceAfterFix": "TEST_UTIL.waitUntilAllRegionsAssigned(tableName)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "6a95dd35511f4216481d8d0ffd4952ed1893a1c4", "fixCommitParentSHA1": "27cf749af884edae55454c885c7fb066f0a33c79", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java\nindex 9a45116..11aa5db 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/security/access/TestAccessController.java\n@@ -232,7 +232,7 @@\n     htd.addFamily(hcd);\n     htd.setOwner(USER_OWNER);\n     admin.createTable(htd, new byte[][] { Bytes.toBytes(\"s\") });\n-    TEST_UTIL.waitTableEnabled(TEST_TABLE.getTableName());\n+    TEST_UTIL.waitUntilAllRegionsAssigned(TEST_TABLE.getTableName());\n \n     HRegion region = TEST_UTIL.getHBaseCluster().getRegions(TEST_TABLE.getTableName()).get(0);\n     RegionCoprocessorHost rcpHost = region.getCoprocessorHost();\n@@ -930,7 +930,7 @@\n       setPermission(loadPath, FsPermission.valueOf(\"-rwxrwxrwx\"));\n \n       try (HTable table = (HTable)TEST_UTIL.getConnection().getTable(tableName)) {\n-        TEST_UTIL.waitTableEnabled(tableName);\n+        TEST_UTIL.waitUntilAllRegionsAssigned(tableName);\n         LoadIncrementalHFiles loader = new LoadIncrementalHFiles(conf);\n         loader.doBulkLoad(loadPath, table);\n       }\n", "projectName": "apache.hbase", "bugLineNum": 933, "bugNodeStartChar": 34298, "bugNodeLength": 37, "fixLineNum": 933, "fixNodeStartChar": 34298, "fixNodeLength": 48, "sourceBeforeFix": "TEST_UTIL.waitTableEnabled(tableName)", "sourceAfterFix": "TEST_UTIL.waitUntilAllRegionsAssigned(tableName)"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "105f9b328221eef30c61a36593927be9a61200b7", "fixCommitParentSHA1": "9b53a1c214f87bd0a38b12e8d308e7e3bde6de84", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\nindex e374aab..71b5646 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n@@ -7314,7 +7314,7 @@\n       ClassSize.OBJECT +\n       ClassSize.ARRAY +\n       45 * ClassSize.REFERENCE + 2 * Bytes.SIZEOF_INT +\n-      (13 * Bytes.SIZEOF_LONG) +\n+      (14 * Bytes.SIZEOF_LONG) +\n       5 * Bytes.SIZEOF_BOOLEAN);\n \n   // woefully out of date - currently missing:\n", "projectName": "apache.hbase", "bugLineNum": 7317, "bugNodeStartChar": 293423, "bugNodeLength": 22, "fixLineNum": 7317, "fixNodeStartChar": 293423, "fixNodeLength": 22, "sourceBeforeFix": "13 * Bytes.SIZEOF_LONG", "sourceAfterFix": "14 * Bytes.SIZEOF_LONG"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "20bc74dff0cf1e1834e99d1f2499a3f5e4c38a36", "fixCommitParentSHA1": "cecc475d2f194eed67edf16cd84fbf9716b8d5c5", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AsyncRpcChannel.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AsyncRpcChannel.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AsyncRpcChannel.java\nindex ffb2dcf..b3e01f3 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AsyncRpcChannel.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AsyncRpcChannel.java\n@@ -607,7 +607,7 @@\n     }\n     for (AsyncCall call : toCleanup) {\n       call.setFailed(new CallTimeoutException(\"Call id=\" + call.id + \", waitTime=\"\n-          + (currentTime - call.getRpcTimeout()) + \", rpcTimeout=\" + call.getRpcTimeout()));\n+          + (currentTime - call.getStartTime()) + \", rpcTimeout=\" + call.getRpcTimeout()));\n     }\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 610, "bugNodeStartChar": 21287, "bugNodeLength": 20, "fixLineNum": 610, "fixNodeStartChar": 21287, "fixNodeLength": 19, "sourceBeforeFix": "call.getRpcTimeout()", "sourceAfterFix": "call.getStartTime()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "20bc74dff0cf1e1834e99d1f2499a3f5e4c38a36", "fixCommitParentSHA1": "cecc475d2f194eed67edf16cd84fbf9716b8d5c5", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AsyncRpcChannel.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AsyncRpcChannel.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AsyncRpcChannel.java\nindex ffb2dcf..b3e01f3 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AsyncRpcChannel.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/ipc/AsyncRpcChannel.java\n@@ -607,7 +607,7 @@\n     }\n     for (AsyncCall call : toCleanup) {\n       call.setFailed(new CallTimeoutException(\"Call id=\" + call.id + \", waitTime=\"\n-          + (currentTime - call.getRpcTimeout()) + \", rpcTimeout=\" + call.getRpcTimeout()));\n+          + (currentTime - call.getStartTime()) + \", rpcTimeout=\" + call.getRpcTimeout()));\n     }\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 610, "bugNodeStartChar": 21287, "bugNodeLength": 20, "fixLineNum": 610, "fixNodeStartChar": 21287, "fixNodeLength": 19, "sourceBeforeFix": "call.getRpcTimeout()", "sourceAfterFix": "call.getStartTime()"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "02759f2d8c58092421f6b34f3585256baaf44f9d", "fixCommitParentSHA1": "b7f6a45803d6b56a2ff56ebcac6a78aee100b409", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java\nindex c560a43..5167157 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/TableName.java\n@@ -180,10 +180,11 @@\n     }\n \n     if (qualifierName[start] == '.' || qualifierName[start] == '-') {\n-      throw new IllegalArgumentException(\"Illegal first character <\" + qualifierName[0] +\n-                                         \"> at 0. Namespaces can only start with alphanumeric \" +\n+      throw new IllegalArgumentException(\"Illegal first character <\" + qualifierName[start] +\n+                                         \"> at 0. \" + (isSnapshot ? \"Snapshot\" : \"User-space table\") +\n+                                         \" qualifiers can only start with 'alphanumeric \" +\n                                          \"characters': i.e. [a-zA-Z_0-9]: \" +\n-                                         Bytes.toString(qualifierName));\n+                                         Bytes.toString(qualifierName, start, end));\n     }\n     for (int i = start; i < end; i++) {\n       if (Character.isLetterOrDigit(qualifierName[i]) ||\n@@ -194,7 +195,7 @@\n       }\n       throw new IllegalArgumentException(\"Illegal character code:\" + qualifierName[i] +\n                                          \", <\" + (char) qualifierName[i] + \"> at \" + i +\n-                                         \". \" + (isSnapshot ? \"snapshot\" : \"User-space table\") +\n+                                         \". \" + (isSnapshot ? \"Snapshot\" : \"User-space table\") +\n                                          \" qualifiers can only contain \" +\n                                          \"'alphanumeric characters': i.e. [a-zA-Z_0-9-.]: \" +\n                                          Bytes.toString(qualifierName, start, end));\n", "projectName": "apache.hbase", "bugLineNum": 186, "bugNodeStartChar": 7441, "bugNodeLength": 29, "fixLineNum": 186, "fixNodeStartChar": 7441, "fixNodeLength": 41, "sourceBeforeFix": "Bytes.toString(qualifierName)", "sourceAfterFix": "Bytes.toString(qualifierName,start,end)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "51334fb951232aa56add118d142e6b82da204494", "fixCommitParentSHA1": "e267db45ac1dca0b56ca562d6407f16ee1f68ab2", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\nindex d2ba69d..248b71a 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\n@@ -1684,7 +1684,7 @@\n     oldestUnflushedStoreSequenceIdsOfRegion =\n         new ConcurrentSkipListMap<byte[], Long>(Bytes.BYTES_COMPARATOR);\n     ConcurrentMap<byte[], Long> alreadyPut =\n-        oldestUnflushedStoreSequenceIds.put(encodedRegionName,\n+        oldestUnflushedStoreSequenceIds.putIfAbsent(encodedRegionName,\n           oldestUnflushedStoreSequenceIdsOfRegion);\n     return alreadyPut == null ? oldestUnflushedStoreSequenceIdsOfRegion : alreadyPut;\n   }\n", "projectName": "apache.hbase", "bugLineNum": 1687, "bugNodeStartChar": 71209, "bugNodeLength": 105, "fixLineNum": 1687, "fixNodeStartChar": 71209, "fixNodeLength": 113, "sourceBeforeFix": "oldestUnflushedStoreSequenceIds.put(encodedRegionName,oldestUnflushedStoreSequenceIdsOfRegion)", "sourceAfterFix": "oldestUnflushedStoreSequenceIds.putIfAbsent(encodedRegionName,oldestUnflushedStoreSequenceIdsOfRegion)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "51334fb951232aa56add118d142e6b82da204494", "fixCommitParentSHA1": "e267db45ac1dca0b56ca562d6407f16ee1f68ab2", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\nindex d2ba69d..248b71a 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/wal/FSHLog.java\n@@ -1684,7 +1684,7 @@\n     oldestUnflushedStoreSequenceIdsOfRegion =\n         new ConcurrentSkipListMap<byte[], Long>(Bytes.BYTES_COMPARATOR);\n     ConcurrentMap<byte[], Long> alreadyPut =\n-        oldestUnflushedStoreSequenceIds.put(encodedRegionName,\n+        oldestUnflushedStoreSequenceIds.putIfAbsent(encodedRegionName,\n           oldestUnflushedStoreSequenceIdsOfRegion);\n     return alreadyPut == null ? oldestUnflushedStoreSequenceIdsOfRegion : alreadyPut;\n   }\n", "projectName": "apache.hbase", "bugLineNum": 1687, "bugNodeStartChar": 71209, "bugNodeLength": 105, "fixLineNum": 1687, "fixNodeStartChar": 71209, "fixNodeLength": 113, "sourceBeforeFix": "oldestUnflushedStoreSequenceIds.put(encodedRegionName,oldestUnflushedStoreSequenceIdsOfRegion)", "sourceAfterFix": "oldestUnflushedStoreSequenceIds.putIfAbsent(encodedRegionName,oldestUnflushedStoreSequenceIdsOfRegion)"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "5cc0714840bf8f7797a118e4bac5dabdd20e3f67", "fixCommitParentSHA1": "94d57f81dc114feba14906b05b3d2c6b78bf3299", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\nindex bc60e8f..9d8c7cb 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\n@@ -185,7 +185,7 @@\n   }\n \n   @Override\n-  public void setClusterStatus(ClusterStatus st) {\n+  public synchronized void setClusterStatus(ClusterStatus st) {\n     super.setClusterStatus(st);\n     updateRegionLoad();\n     for(CostFromRegionLoadFunction cost : regionLoadFunctions) {\n@@ -194,7 +194,7 @@\n   }\n \n   @Override\n-  public void setMasterServices(MasterServices masterServices) {\n+  public synchronized void setMasterServices(MasterServices masterServices) {\n     super.setMasterServices(masterServices);\n     this.localityCost.setServices(masterServices);\n     this.localityCandidateGenerator.setServices(masterServices);\n@@ -202,7 +202,7 @@\n   }\n \n   @Override\n-  protected boolean areSomeRegionReplicasColocated(Cluster c) {\n+  protected synchronized boolean areSomeRegionReplicasColocated(Cluster c) {\n     regionReplicaHostCostFunction.init(c);\n     if (regionReplicaHostCostFunction.cost() > 0) return true;\n     regionReplicaRackCostFunction.init(c);\n@@ -215,7 +215,8 @@\n    * should always approach the optimal state given enough steps.\n    */\n   @Override\n-  public List<RegionPlan> balanceCluster(Map<ServerName, List<HRegionInfo>> clusterState) {\n+  public synchronized List<RegionPlan> balanceCluster(Map<ServerName,\n+    List<HRegionInfo>> clusterState) {\n     List<RegionPlan> plans = balanceMasterRegions(clusterState);\n     if (plans != null || clusterState == null || clusterState.size() <= 1) {\n       return plans;\n", "projectName": "apache.hbase", "bugLineNum": 187, "bugNodeStartChar": 7630, "bugNodeLength": 224, "fixLineNum": 187, "fixNodeStartChar": 7630, "fixNodeLength": 237, "sourceBeforeFix": "1", "sourceAfterFix": "33"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "5cc0714840bf8f7797a118e4bac5dabdd20e3f67", "fixCommitParentSHA1": "94d57f81dc114feba14906b05b3d2c6b78bf3299", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\nindex bc60e8f..9d8c7cb 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\n@@ -185,7 +185,7 @@\n   }\n \n   @Override\n-  public void setClusterStatus(ClusterStatus st) {\n+  public synchronized void setClusterStatus(ClusterStatus st) {\n     super.setClusterStatus(st);\n     updateRegionLoad();\n     for(CostFromRegionLoadFunction cost : regionLoadFunctions) {\n@@ -194,7 +194,7 @@\n   }\n \n   @Override\n-  public void setMasterServices(MasterServices masterServices) {\n+  public synchronized void setMasterServices(MasterServices masterServices) {\n     super.setMasterServices(masterServices);\n     this.localityCost.setServices(masterServices);\n     this.localityCandidateGenerator.setServices(masterServices);\n@@ -202,7 +202,7 @@\n   }\n \n   @Override\n-  protected boolean areSomeRegionReplicasColocated(Cluster c) {\n+  protected synchronized boolean areSomeRegionReplicasColocated(Cluster c) {\n     regionReplicaHostCostFunction.init(c);\n     if (regionReplicaHostCostFunction.cost() > 0) return true;\n     regionReplicaRackCostFunction.init(c);\n@@ -215,7 +215,8 @@\n    * should always approach the optimal state given enough steps.\n    */\n   @Override\n-  public List<RegionPlan> balanceCluster(Map<ServerName, List<HRegionInfo>> clusterState) {\n+  public synchronized List<RegionPlan> balanceCluster(Map<ServerName,\n+    List<HRegionInfo>> clusterState) {\n     List<RegionPlan> plans = balanceMasterRegions(clusterState);\n     if (plans != null || clusterState == null || clusterState.size() <= 1) {\n       return plans;\n", "projectName": "apache.hbase", "bugLineNum": 196, "bugNodeStartChar": 7858, "bugNodeLength": 240, "fixLineNum": 196, "fixNodeStartChar": 7858, "fixNodeLength": 253, "sourceBeforeFix": "1", "sourceAfterFix": "33"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "5cc0714840bf8f7797a118e4bac5dabdd20e3f67", "fixCommitParentSHA1": "94d57f81dc114feba14906b05b3d2c6b78bf3299", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\nindex bc60e8f..9d8c7cb 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\n@@ -185,7 +185,7 @@\n   }\n \n   @Override\n-  public void setClusterStatus(ClusterStatus st) {\n+  public synchronized void setClusterStatus(ClusterStatus st) {\n     super.setClusterStatus(st);\n     updateRegionLoad();\n     for(CostFromRegionLoadFunction cost : regionLoadFunctions) {\n@@ -194,7 +194,7 @@\n   }\n \n   @Override\n-  public void setMasterServices(MasterServices masterServices) {\n+  public synchronized void setMasterServices(MasterServices masterServices) {\n     super.setMasterServices(masterServices);\n     this.localityCost.setServices(masterServices);\n     this.localityCandidateGenerator.setServices(masterServices);\n@@ -202,7 +202,7 @@\n   }\n \n   @Override\n-  protected boolean areSomeRegionReplicasColocated(Cluster c) {\n+  protected synchronized boolean areSomeRegionReplicasColocated(Cluster c) {\n     regionReplicaHostCostFunction.init(c);\n     if (regionReplicaHostCostFunction.cost() > 0) return true;\n     regionReplicaRackCostFunction.init(c);\n@@ -215,7 +215,8 @@\n    * should always approach the optimal state given enough steps.\n    */\n   @Override\n-  public List<RegionPlan> balanceCluster(Map<ServerName, List<HRegionInfo>> clusterState) {\n+  public synchronized List<RegionPlan> balanceCluster(Map<ServerName,\n+    List<HRegionInfo>> clusterState) {\n     List<RegionPlan> plans = balanceMasterRegions(clusterState);\n     if (plans != null || clusterState == null || clusterState.size() <= 1) {\n       return plans;\n", "projectName": "apache.hbase", "bugLineNum": 204, "bugNodeStartChar": 8102, "bugNodeLength": 307, "fixLineNum": 204, "fixNodeStartChar": 8102, "fixNodeLength": 320, "sourceBeforeFix": "4", "sourceAfterFix": "36"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "5cc0714840bf8f7797a118e4bac5dabdd20e3f67", "fixCommitParentSHA1": "94d57f81dc114feba14906b05b3d2c6b78bf3299", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\nindex bc60e8f..9d8c7cb 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.java\n@@ -185,7 +185,7 @@\n   }\n \n   @Override\n-  public void setClusterStatus(ClusterStatus st) {\n+  public synchronized void setClusterStatus(ClusterStatus st) {\n     super.setClusterStatus(st);\n     updateRegionLoad();\n     for(CostFromRegionLoadFunction cost : regionLoadFunctions) {\n@@ -194,7 +194,7 @@\n   }\n \n   @Override\n-  public void setMasterServices(MasterServices masterServices) {\n+  public synchronized void setMasterServices(MasterServices masterServices) {\n     super.setMasterServices(masterServices);\n     this.localityCost.setServices(masterServices);\n     this.localityCandidateGenerator.setServices(masterServices);\n@@ -202,7 +202,7 @@\n   }\n \n   @Override\n-  protected boolean areSomeRegionReplicasColocated(Cluster c) {\n+  protected synchronized boolean areSomeRegionReplicasColocated(Cluster c) {\n     regionReplicaHostCostFunction.init(c);\n     if (regionReplicaHostCostFunction.cost() > 0) return true;\n     regionReplicaRackCostFunction.init(c);\n@@ -215,7 +215,8 @@\n    * should always approach the optimal state given enough steps.\n    */\n   @Override\n-  public List<RegionPlan> balanceCluster(Map<ServerName, List<HRegionInfo>> clusterState) {\n+  public synchronized List<RegionPlan> balanceCluster(Map<ServerName,\n+    List<HRegionInfo>> clusterState) {\n     List<RegionPlan> plans = balanceMasterRegions(clusterState);\n     if (plans != null || clusterState == null || clusterState.size() <= 1) {\n       return plans;\n", "projectName": "apache.hbase", "bugLineNum": 213, "bugNodeStartChar": 8413, "bugNodeLength": 3292, "fixLineNum": 213, "fixNodeStartChar": 8413, "fixNodeLength": 3309, "sourceBeforeFix": "1", "sourceAfterFix": "33"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "7aea38118e7af7d2c5e1ce54ca135b8c0261a2df", "fixCommitParentSHA1": "8a8b7de760a33c8195e287975d5b4a337d71b1fa", "bugFilePath": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java", "fixPatch": "diff --git a/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java b/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java\nindex 4465332..27d5437 100644\n--- a/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java\n+++ b/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java\n@@ -242,7 +242,7 @@\n           .addCounter(Interns.info(MOB_FILE_CACHE_ACCESS_COUNT, MOB_FILE_CACHE_ACCESS_COUNT_DESC),\n               rsWrap.getMobFileCacheAccessCount())\n           .addCounter(Interns.info(MOB_FILE_CACHE_MISS_COUNT, MOB_FILE_CACHE_MISS_COUNT_DESC),\n-              rsWrap.getMobFileCacheAccessCount())\n+              rsWrap.getMobFileCacheMissCount())\n           .addCounter(\n               Interns.info(MOB_FILE_CACHE_EVICTED_COUNT, MOB_FILE_CACHE_EVICTED_COUNT_DESC),\n               rsWrap.getMobFileCacheEvictedCount())\n", "projectName": "apache.hbase", "bugLineNum": 245, "bugNodeStartChar": 11209, "bugNodeLength": 35, "fixLineNum": 245, "fixNodeStartChar": 11209, "fixNodeLength": 33, "sourceBeforeFix": "rsWrap.getMobFileCacheAccessCount()", "sourceAfterFix": "rsWrap.getMobFileCacheMissCount()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "7aea38118e7af7d2c5e1ce54ca135b8c0261a2df", "fixCommitParentSHA1": "8a8b7de760a33c8195e287975d5b4a337d71b1fa", "bugFilePath": "hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java", "fixPatch": "diff --git a/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java b/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java\nindex 4465332..27d5437 100644\n--- a/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java\n+++ b/hbase-hadoop2-compat/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServerSourceImpl.java\n@@ -242,7 +242,7 @@\n           .addCounter(Interns.info(MOB_FILE_CACHE_ACCESS_COUNT, MOB_FILE_CACHE_ACCESS_COUNT_DESC),\n               rsWrap.getMobFileCacheAccessCount())\n           .addCounter(Interns.info(MOB_FILE_CACHE_MISS_COUNT, MOB_FILE_CACHE_MISS_COUNT_DESC),\n-              rsWrap.getMobFileCacheAccessCount())\n+              rsWrap.getMobFileCacheMissCount())\n           .addCounter(\n               Interns.info(MOB_FILE_CACHE_EVICTED_COUNT, MOB_FILE_CACHE_EVICTED_COUNT_DESC),\n               rsWrap.getMobFileCacheEvictedCount())\n", "projectName": "apache.hbase", "bugLineNum": 245, "bugNodeStartChar": 11209, "bugNodeLength": 35, "fixLineNum": 245, "fixNodeStartChar": 11209, "fixNodeLength": 33, "sourceBeforeFix": "rsWrap.getMobFileCacheAccessCount()", "sourceAfterFix": "rsWrap.getMobFileCacheMissCount()"}, {"bugType": "CHANGE_UNARY_OPERATOR", "fixCommitSHA1": "8a8b7de760a33c8195e287975d5b4a337d71b1fa", "fixCommitParentSHA1": "3876bb764d6ac2bd8b4d1f5f7b8e73cd36d32e59", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.java\nindex 76085fa..01bf414 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/compactions/CompactionRequest.java\n@@ -216,7 +216,7 @@\n    */\n   public boolean isRetainDeleteMarkers() {\n     return (this.retainDeleteMarkers != null) ? this.retainDeleteMarkers.booleanValue()\n-        : isAllFiles();\n+        : !isAllFiles();\n   }\n \n   @Override\n", "projectName": "apache.hbase", "bugLineNum": 219, "bugNodeStartChar": 7310, "bugNodeLength": 12, "fixLineNum": 219, "fixNodeStartChar": 7310, "fixNodeLength": 13, "sourceBeforeFix": "isAllFiles()", "sourceAfterFix": "!isAllFiles()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "dc5295df8c5288d29737cfe4d936a817c7a56e72", "fixCommitParentSHA1": "5aeec324e77e5f57d1b641594764097878b25c5b", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java\nindex 1b66341..b085b3e 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/util/Bytes.java\n@@ -1127,7 +1127,7 @@\n    * @return the short value\n    */\n   public static short toShort(byte[] bytes) {\n-    return toShortUnsafe(bytes, 0);\n+    return toShort(bytes, 0, SIZEOF_SHORT);\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1130, "bugNodeStartChar": 33326, "bugNodeLength": 23, "fixLineNum": 1130, "fixNodeStartChar": 33326, "fixNodeLength": 31, "sourceBeforeFix": "toShortUnsafe(bytes,0)", "sourceAfterFix": "toShort(bytes,0,SIZEOF_SHORT)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "e5d3850776174a63ddc2e0b5ead58409ca7c8706", "fixCommitParentSHA1": "0c86d83e1f966b5e0c72e53664f7e9ff5a71e488", "bugFilePath": "hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithMOB.java", "fixPatch": "diff --git a/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithMOB.java b/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithMOB.java\nindex 4697eed..b021cc4 100644\n--- a/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithMOB.java\n+++ b/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithMOB.java\n@@ -60,7 +60,7 @@\n   protected String[] getArgsForLoadTestToolInitTable() {\n     List<String> args = new ArrayList<String>();\n     args.add(\"-tn\");\n-    args.add(getTablename());\n+    args.add(getTablename().getNameAsString());\n     // pass all remaining args from conf with keys <test class name>.<load test tool arg>\n     String clazz = this.getClass().getSimpleName();\n     for (String arg : LOAD_TEST_TOOL_MOB_INIT_ARGS) {\n@@ -104,7 +104,7 @@\n   protected void initTable() throws IOException {\n     super.initTable();\n \n-    byte[] tableName = getTablename().getBytes();\n+    byte[] tableName = getTablename().getName();\n     HBaseAdmin admin = new HBaseAdmin(conf);\n     HTableDescriptor tableDesc = admin.getTableDescriptor(tableName);\n     LOG.info(\"Disabling table \" + getTablename());\n", "projectName": "apache.hbase", "bugLineNum": 107, "bugNodeStartChar": 3986, "bugNodeLength": 25, "fixLineNum": 107, "fixNodeStartChar": 3986, "fixNodeLength": 24, "sourceBeforeFix": "getTablename().getBytes()", "sourceAfterFix": "getTablename().getName()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "e5d3850776174a63ddc2e0b5ead58409ca7c8706", "fixCommitParentSHA1": "0c86d83e1f966b5e0c72e53664f7e9ff5a71e488", "bugFilePath": "hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithMOB.java", "fixPatch": "diff --git a/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithMOB.java b/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithMOB.java\nindex 4697eed..b021cc4 100644\n--- a/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithMOB.java\n+++ b/hbase-it/src/test/java/org/apache/hadoop/hbase/IntegrationTestIngestWithMOB.java\n@@ -60,7 +60,7 @@\n   protected String[] getArgsForLoadTestToolInitTable() {\n     List<String> args = new ArrayList<String>();\n     args.add(\"-tn\");\n-    args.add(getTablename());\n+    args.add(getTablename().getNameAsString());\n     // pass all remaining args from conf with keys <test class name>.<load test tool arg>\n     String clazz = this.getClass().getSimpleName();\n     for (String arg : LOAD_TEST_TOOL_MOB_INIT_ARGS) {\n@@ -104,7 +104,7 @@\n   protected void initTable() throws IOException {\n     super.initTable();\n \n-    byte[] tableName = getTablename().getBytes();\n+    byte[] tableName = getTablename().getName();\n     HBaseAdmin admin = new HBaseAdmin(conf);\n     HTableDescriptor tableDesc = admin.getTableDescriptor(tableName);\n     LOG.info(\"Disabling table \" + getTablename());\n", "projectName": "apache.hbase", "bugLineNum": 107, "bugNodeStartChar": 3986, "bugNodeLength": 25, "fixLineNum": 107, "fixNodeStartChar": 3986, "fixNodeLength": 24, "sourceBeforeFix": "getTablename().getBytes()", "sourceAfterFix": "getTablename().getName()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "2be3f90fa6dac2447ec3106f0f783c52e294c7d7", "fixCommitParentSHA1": "7a1b7ef261ea8db69b24d3729e51061f73c6ebcc", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java\nindex 7f03d85..e6d1708 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestHRegion.java\n@@ -1542,7 +1542,7 @@\n       Delete delete = new Delete(row1);\n       delete.deleteColumn(fam1, qf1);\n       res = region.checkAndMutate(row1, fam1, qf1, CompareOp.EQUAL, new BinaryComparator(val1),\n-          put, true);\n+          delete, true);\n       assertEquals(true, res);\n     } finally {\n       HRegion.closeHRegion(this.region);\n", "projectName": "apache.hbase", "bugLineNum": 1544, "bugNodeStartChar": 62378, "bugNodeLength": 104, "fixLineNum": 1544, "fixNodeStartChar": 62378, "fixNodeLength": 107, "sourceBeforeFix": "region.checkAndMutate(row1,fam1,qf1,CompareOp.EQUAL,new BinaryComparator(val1),put,true)", "sourceAfterFix": "region.checkAndMutate(row1,fam1,qf1,CompareOp.EQUAL,new BinaryComparator(val1),delete,true)"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "0b22eb07bb8ecfa456f170dc9a1dec418ed01e2a", "fixCommitParentSHA1": "7db2563c6a16b4cc69a2343172e0ff0277f1f0c6", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableLocator.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableLocator.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableLocator.java\nindex d2448b3..dccd7ca 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableLocator.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/TestMetaTableLocator.java\n@@ -326,7 +326,7 @@\n \n     void doWaiting() throws InterruptedException {\n       try {\n-        while (new MetaTableLocator().waitMetaRegionLocation(watcher, 100) == null);\n+        while (new MetaTableLocator().waitMetaRegionLocation(watcher, 10000) == null);\n       } catch (NotAllMetaRegionsOnlineException e) {\n         //Ignore\n       }\n", "projectName": "apache.hbase", "bugLineNum": 329, "bugNodeStartChar": 12313, "bugNodeLength": 59, "fixLineNum": 329, "fixNodeStartChar": 12313, "fixNodeLength": 61, "sourceBeforeFix": "new MetaTableLocator().waitMetaRegionLocation(watcher,100)", "sourceAfterFix": "new MetaTableLocator().waitMetaRegionLocation(watcher,10000)"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "ffabf9ba9b70baa679cca6cf804ef4ec275fdccc", "fixCommitParentSHA1": "72ba78667c12ebefc3a9c6d2fbd07aec593f7ac6", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedReader.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedReader.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedReader.java\nindex e6d4807..df0d3f8 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedReader.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedReader.java\n@@ -206,7 +206,7 @@\n           numKeys++;\n         } while (numKeys < batchSize);\n \n-        if (numKeys > 1) { //meaning there is some key to read\n+        if (numKeys > 0) { //meaning there is some key to read\n           readKey(keysForThisReader);\n           // We have verified some unique key(s).\n           numUniqueKeysVerified.getAndAdd(readingRandomKeyStartIndex == -1 ?\n", "projectName": "apache.hbase", "bugLineNum": 209, "bugNodeStartChar": 7095, "bugNodeLength": 11, "fixLineNum": 209, "fixNodeStartChar": 7095, "fixNodeLength": 11, "sourceBeforeFix": "numKeys > 1", "sourceAfterFix": "numKeys > 0"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "1a89a3fedeff90da5fa2e62fa49b26bfd8ec7f24", "fixCommitParentSHA1": "d16b2016401a1b56b0e257a187191434a7525563", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AnnotationReadingPriorityFunction.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AnnotationReadingPriorityFunction.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AnnotationReadingPriorityFunction.java\nindex 24fa862..b777589 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AnnotationReadingPriorityFunction.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AnnotationReadingPriorityFunction.java\n@@ -171,7 +171,7 @@\n       return HConstants.NORMAL_QOS;\n     }\n \n-    if (methodName.equals(\"scan\")) { // scanner methods...\n+    if (methodName.equalsIgnoreCase(\"scan\")) { // scanner methods...\n       ScanRequest request = (ScanRequest)param;\n       if (!request.hasScannerId()) {\n         return HConstants.NORMAL_QOS;\n", "projectName": "apache.hbase", "bugLineNum": 174, "bugNodeStartChar": 8455, "bugNodeLength": 25, "fixLineNum": 174, "fixNodeStartChar": 8455, "fixNodeLength": 35, "sourceBeforeFix": "methodName.equals(\"scan\")", "sourceAfterFix": "methodName.equalsIgnoreCase(\"scan\")"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "1a89a3fedeff90da5fa2e62fa49b26bfd8ec7f24", "fixCommitParentSHA1": "d16b2016401a1b56b0e257a187191434a7525563", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AnnotationReadingPriorityFunction.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AnnotationReadingPriorityFunction.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AnnotationReadingPriorityFunction.java\nindex 24fa862..b777589 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AnnotationReadingPriorityFunction.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/AnnotationReadingPriorityFunction.java\n@@ -171,7 +171,7 @@\n       return HConstants.NORMAL_QOS;\n     }\n \n-    if (methodName.equals(\"scan\")) { // scanner methods...\n+    if (methodName.equalsIgnoreCase(\"scan\")) { // scanner methods...\n       ScanRequest request = (ScanRequest)param;\n       if (!request.hasScannerId()) {\n         return HConstants.NORMAL_QOS;\n", "projectName": "apache.hbase", "bugLineNum": 174, "bugNodeStartChar": 8455, "bugNodeLength": 25, "fixLineNum": 174, "fixNodeStartChar": 8455, "fixNodeLength": 35, "sourceBeforeFix": "methodName.equals(\"scan\")", "sourceAfterFix": "methodName.equalsIgnoreCase(\"scan\")"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "58c20f3c76f7a73a355e36e5c0791d6c3522565b", "fixCommitParentSHA1": "8bcb70ddcf45bff817d1a23410859e1e9c89af14", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java\nindex f864ec5..a86ff09 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/handler/TestCloseRegionHandler.java\n@@ -104,7 +104,7 @@\n       HRegion spy = Mockito.spy(region);\n       final boolean abort = false;\n       Mockito.when(spy.close(abort)).\n-      thenThrow(new RuntimeException(\"Mocked failed close!\"));\n+      thenThrow(new IOException(\"Mocked failed close!\"));\n       // The CloseRegionHandler will try to get an HRegion that corresponds\n       // to the passed hri -- so insert the region into the online region Set.\n       rss.addToOnlineRegions(spy);\n", "projectName": "apache.hbase", "bugLineNum": 107, "bugNodeStartChar": 4124, "bugNodeLength": 44, "fixLineNum": 107, "fixNodeStartChar": 4124, "fixNodeLength": 39, "sourceBeforeFix": "new RuntimeException(\"Mocked failed close!\")", "sourceAfterFix": "new IOException(\"Mocked failed close!\")"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "25c95d8dd9ec2d4e712aaeccedec306be41a3c8a", "fixCommitParentSHA1": "b04e6a3cbd6ab891caaf65c65c8011a96878668a", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java\nindex 783ade9..e23ea37 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java\n@@ -190,7 +190,7 @@\n       try {\n         regionLocation = reverseDNS(regionAddress);\n       } catch (NamingException e) {\n-        LOG.error(\"Cannot resolve the host name for \" + regionAddress + \" because of \" + e);\n+        LOG.warn(\"Cannot resolve the host name for \" + regionAddress + \" because of \" + e);\n         regionLocation = location.getHostname();\n       }\n \n", "projectName": "apache.hbase", "bugLineNum": 193, "bugNodeStartChar": 7600, "bugNodeLength": 83, "fixLineNum": 193, "fixNodeStartChar": 7600, "fixNodeLength": 82, "sourceBeforeFix": "LOG.error(\"Cannot resolve the host name for \" + regionAddress + \" because of \"+ e)", "sourceAfterFix": "LOG.warn(\"Cannot resolve the host name for \" + regionAddress + \" because of \"+ e)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "25c95d8dd9ec2d4e712aaeccedec306be41a3c8a", "fixCommitParentSHA1": "b04e6a3cbd6ab891caaf65c65c8011a96878668a", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java\nindex 783ade9..e23ea37 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/TableInputFormatBase.java\n@@ -190,7 +190,7 @@\n       try {\n         regionLocation = reverseDNS(regionAddress);\n       } catch (NamingException e) {\n-        LOG.error(\"Cannot resolve the host name for \" + regionAddress + \" because of \" + e);\n+        LOG.warn(\"Cannot resolve the host name for \" + regionAddress + \" because of \" + e);\n         regionLocation = location.getHostname();\n       }\n \n", "projectName": "apache.hbase", "bugLineNum": 193, "bugNodeStartChar": 7600, "bugNodeLength": 83, "fixLineNum": 193, "fixNodeStartChar": 7600, "fixNodeLength": 82, "sourceBeforeFix": "LOG.error(\"Cannot resolve the host name for \" + regionAddress + \" because of \"+ e)", "sourceAfterFix": "LOG.warn(\"Cannot resolve the host name for \" + regionAddress + \" because of \"+ e)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "64dff91895f9df55fe3a07217a333efa4d37d92a", "fixCommitParentSHA1": "177bbff3919531e87739279e1435d649cfb10cc4", "bugFilePath": "hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java", "fixPatch": "diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\nindex 08799ba..703d15d 100644\n--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n@@ -133,7 +133,7 @@\n     try {\n       jarFile = new JarInputStream(new FileInputStream(jarFileName));\n     } catch (IOException ioEx) {\n-      LOG.error(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n+      LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n       throw ioEx;\n     }\n \n@@ -147,7 +147,7 @@\n           if (!proceedOnExceptions) {\n             throw ioEx;\n           }\n-          LOG.error(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n+          LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n           break;\n         }\n         if (entry == null) {\n@@ -172,7 +172,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n@@ -186,13 +186,13 @@\n       boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {\n     Set<Class<?>> classes = new HashSet<Class<?>>();\n     if (!baseDirectory.exists()) {\n-      LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n     File[] files = baseDirectory.listFiles(this.fileFilter);\n     if (files == null) {\n-      LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n@@ -207,7 +207,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 136, "bugNodeStartChar": 4989, "bugNodeLength": 71, "fixLineNum": 136, "fixNodeStartChar": 4989, "fixNodeLength": 70, "sourceBeforeFix": "LOG.error(\"Failed to look for classes in \" + jarFileName + \": \"+ ioEx)", "sourceAfterFix": "LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \"+ ioEx)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "64dff91895f9df55fe3a07217a333efa4d37d92a", "fixCommitParentSHA1": "177bbff3919531e87739279e1435d649cfb10cc4", "bugFilePath": "hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java", "fixPatch": "diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\nindex 08799ba..703d15d 100644\n--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n@@ -133,7 +133,7 @@\n     try {\n       jarFile = new JarInputStream(new FileInputStream(jarFileName));\n     } catch (IOException ioEx) {\n-      LOG.error(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n+      LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n       throw ioEx;\n     }\n \n@@ -147,7 +147,7 @@\n           if (!proceedOnExceptions) {\n             throw ioEx;\n           }\n-          LOG.error(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n+          LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n           break;\n         }\n         if (entry == null) {\n@@ -172,7 +172,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n@@ -186,13 +186,13 @@\n       boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {\n     Set<Class<?>> classes = new HashSet<Class<?>>();\n     if (!baseDirectory.exists()) {\n-      LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n     File[] files = baseDirectory.listFiles(this.fileFilter);\n     if (files == null) {\n-      LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n@@ -207,7 +207,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 136, "bugNodeStartChar": 4989, "bugNodeLength": 71, "fixLineNum": 136, "fixNodeStartChar": 4989, "fixNodeLength": 70, "sourceBeforeFix": "LOG.error(\"Failed to look for classes in \" + jarFileName + \": \"+ ioEx)", "sourceAfterFix": "LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \"+ ioEx)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "64dff91895f9df55fe3a07217a333efa4d37d92a", "fixCommitParentSHA1": "177bbff3919531e87739279e1435d649cfb10cc4", "bugFilePath": "hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java", "fixPatch": "diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\nindex 08799ba..703d15d 100644\n--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n@@ -133,7 +133,7 @@\n     try {\n       jarFile = new JarInputStream(new FileInputStream(jarFileName));\n     } catch (IOException ioEx) {\n-      LOG.error(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n+      LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n       throw ioEx;\n     }\n \n@@ -147,7 +147,7 @@\n           if (!proceedOnExceptions) {\n             throw ioEx;\n           }\n-          LOG.error(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n+          LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n           break;\n         }\n         if (entry == null) {\n@@ -172,7 +172,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n@@ -186,13 +186,13 @@\n       boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {\n     Set<Class<?>> classes = new HashSet<Class<?>>();\n     if (!baseDirectory.exists()) {\n-      LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n     File[] files = baseDirectory.listFiles(this.fileFilter);\n     if (files == null) {\n-      LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n@@ -207,7 +207,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 150, "bugNodeStartChar": 5378, "bugNodeLength": 71, "fixLineNum": 150, "fixNodeStartChar": 5378, "fixNodeLength": 70, "sourceBeforeFix": "LOG.error(\"Failed to get next entry from \" + jarFileName + \": \"+ ioEx)", "sourceAfterFix": "LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \"+ ioEx)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "64dff91895f9df55fe3a07217a333efa4d37d92a", "fixCommitParentSHA1": "177bbff3919531e87739279e1435d649cfb10cc4", "bugFilePath": "hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java", "fixPatch": "diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\nindex 08799ba..703d15d 100644\n--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n@@ -133,7 +133,7 @@\n     try {\n       jarFile = new JarInputStream(new FileInputStream(jarFileName));\n     } catch (IOException ioEx) {\n-      LOG.error(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n+      LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n       throw ioEx;\n     }\n \n@@ -147,7 +147,7 @@\n           if (!proceedOnExceptions) {\n             throw ioEx;\n           }\n-          LOG.error(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n+          LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n           break;\n         }\n         if (entry == null) {\n@@ -172,7 +172,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n@@ -186,13 +186,13 @@\n       boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {\n     Set<Class<?>> classes = new HashSet<Class<?>>();\n     if (!baseDirectory.exists()) {\n-      LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n     File[] files = baseDirectory.listFiles(this.fileFilter);\n     if (files == null) {\n-      LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n@@ -207,7 +207,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 150, "bugNodeStartChar": 5378, "bugNodeLength": 71, "fixLineNum": 150, "fixNodeStartChar": 5378, "fixNodeLength": 70, "sourceBeforeFix": "LOG.error(\"Failed to get next entry from \" + jarFileName + \": \"+ ioEx)", "sourceAfterFix": "LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \"+ ioEx)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "64dff91895f9df55fe3a07217a333efa4d37d92a", "fixCommitParentSHA1": "177bbff3919531e87739279e1435d649cfb10cc4", "bugFilePath": "hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java", "fixPatch": "diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\nindex 08799ba..703d15d 100644\n--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n@@ -133,7 +133,7 @@\n     try {\n       jarFile = new JarInputStream(new FileInputStream(jarFileName));\n     } catch (IOException ioEx) {\n-      LOG.error(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n+      LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n       throw ioEx;\n     }\n \n@@ -147,7 +147,7 @@\n           if (!proceedOnExceptions) {\n             throw ioEx;\n           }\n-          LOG.error(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n+          LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n           break;\n         }\n         if (entry == null) {\n@@ -172,7 +172,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n@@ -186,13 +186,13 @@\n       boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {\n     Set<Class<?>> classes = new HashSet<Class<?>>();\n     if (!baseDirectory.exists()) {\n-      LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n     File[] files = baseDirectory.listFiles(this.fileFilter);\n     if (files == null) {\n-      LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n@@ -207,7 +207,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 175, "bugNodeStartChar": 6284, "bugNodeLength": 50, "fixLineNum": 175, "fixNodeStartChar": 6284, "fixNodeLength": 49, "sourceBeforeFix": "LOG.error(\"Ignoring duplicate class \" + className)", "sourceAfterFix": "LOG.warn(\"Ignoring duplicate class \" + className)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "64dff91895f9df55fe3a07217a333efa4d37d92a", "fixCommitParentSHA1": "177bbff3919531e87739279e1435d649cfb10cc4", "bugFilePath": "hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java", "fixPatch": "diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\nindex 08799ba..703d15d 100644\n--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n@@ -133,7 +133,7 @@\n     try {\n       jarFile = new JarInputStream(new FileInputStream(jarFileName));\n     } catch (IOException ioEx) {\n-      LOG.error(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n+      LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n       throw ioEx;\n     }\n \n@@ -147,7 +147,7 @@\n           if (!proceedOnExceptions) {\n             throw ioEx;\n           }\n-          LOG.error(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n+          LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n           break;\n         }\n         if (entry == null) {\n@@ -172,7 +172,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n@@ -186,13 +186,13 @@\n       boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {\n     Set<Class<?>> classes = new HashSet<Class<?>>();\n     if (!baseDirectory.exists()) {\n-      LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n     File[] files = baseDirectory.listFiles(this.fileFilter);\n     if (files == null) {\n-      LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n@@ -207,7 +207,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 175, "bugNodeStartChar": 6284, "bugNodeLength": 50, "fixLineNum": 175, "fixNodeStartChar": 6284, "fixNodeLength": 49, "sourceBeforeFix": "LOG.error(\"Ignoring duplicate class \" + className)", "sourceAfterFix": "LOG.warn(\"Ignoring duplicate class \" + className)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "64dff91895f9df55fe3a07217a333efa4d37d92a", "fixCommitParentSHA1": "177bbff3919531e87739279e1435d649cfb10cc4", "bugFilePath": "hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java", "fixPatch": "diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\nindex 08799ba..703d15d 100644\n--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n@@ -133,7 +133,7 @@\n     try {\n       jarFile = new JarInputStream(new FileInputStream(jarFileName));\n     } catch (IOException ioEx) {\n-      LOG.error(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n+      LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n       throw ioEx;\n     }\n \n@@ -147,7 +147,7 @@\n           if (!proceedOnExceptions) {\n             throw ioEx;\n           }\n-          LOG.error(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n+          LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n           break;\n         }\n         if (entry == null) {\n@@ -172,7 +172,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n@@ -186,13 +186,13 @@\n       boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {\n     Set<Class<?>> classes = new HashSet<Class<?>>();\n     if (!baseDirectory.exists()) {\n-      LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n     File[] files = baseDirectory.listFiles(this.fileFilter);\n     if (files == null) {\n-      LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n@@ -207,7 +207,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 189, "bugNodeStartChar": 6698, "bugNodeLength": 62, "fixLineNum": 189, "fixNodeStartChar": 6698, "fixNodeLength": 61, "sourceBeforeFix": "LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath())", "sourceAfterFix": "LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath())"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "64dff91895f9df55fe3a07217a333efa4d37d92a", "fixCommitParentSHA1": "177bbff3919531e87739279e1435d649cfb10cc4", "bugFilePath": "hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java", "fixPatch": "diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\nindex 08799ba..703d15d 100644\n--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n@@ -133,7 +133,7 @@\n     try {\n       jarFile = new JarInputStream(new FileInputStream(jarFileName));\n     } catch (IOException ioEx) {\n-      LOG.error(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n+      LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n       throw ioEx;\n     }\n \n@@ -147,7 +147,7 @@\n           if (!proceedOnExceptions) {\n             throw ioEx;\n           }\n-          LOG.error(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n+          LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n           break;\n         }\n         if (entry == null) {\n@@ -172,7 +172,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n@@ -186,13 +186,13 @@\n       boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {\n     Set<Class<?>> classes = new HashSet<Class<?>>();\n     if (!baseDirectory.exists()) {\n-      LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n     File[] files = baseDirectory.listFiles(this.fileFilter);\n     if (files == null) {\n-      LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n@@ -207,7 +207,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 189, "bugNodeStartChar": 6698, "bugNodeLength": 62, "fixLineNum": 189, "fixNodeStartChar": 6698, "fixNodeLength": 61, "sourceBeforeFix": "LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath())", "sourceAfterFix": "LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath())"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "64dff91895f9df55fe3a07217a333efa4d37d92a", "fixCommitParentSHA1": "177bbff3919531e87739279e1435d649cfb10cc4", "bugFilePath": "hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java", "fixPatch": "diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\nindex 08799ba..703d15d 100644\n--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n@@ -133,7 +133,7 @@\n     try {\n       jarFile = new JarInputStream(new FileInputStream(jarFileName));\n     } catch (IOException ioEx) {\n-      LOG.error(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n+      LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n       throw ioEx;\n     }\n \n@@ -147,7 +147,7 @@\n           if (!proceedOnExceptions) {\n             throw ioEx;\n           }\n-          LOG.error(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n+          LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n           break;\n         }\n         if (entry == null) {\n@@ -172,7 +172,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n@@ -186,13 +186,13 @@\n       boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {\n     Set<Class<?>> classes = new HashSet<Class<?>>();\n     if (!baseDirectory.exists()) {\n-      LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n     File[] files = baseDirectory.listFiles(this.fileFilter);\n     if (files == null) {\n-      LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n@@ -207,7 +207,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 195, "bugNodeStartChar": 6883, "bugNodeLength": 72, "fixLineNum": 195, "fixNodeStartChar": 6883, "fixNodeLength": 71, "sourceBeforeFix": "LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath())", "sourceAfterFix": "LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath())"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "64dff91895f9df55fe3a07217a333efa4d37d92a", "fixCommitParentSHA1": "177bbff3919531e87739279e1435d649cfb10cc4", "bugFilePath": "hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java", "fixPatch": "diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\nindex 08799ba..703d15d 100644\n--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n@@ -133,7 +133,7 @@\n     try {\n       jarFile = new JarInputStream(new FileInputStream(jarFileName));\n     } catch (IOException ioEx) {\n-      LOG.error(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n+      LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n       throw ioEx;\n     }\n \n@@ -147,7 +147,7 @@\n           if (!proceedOnExceptions) {\n             throw ioEx;\n           }\n-          LOG.error(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n+          LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n           break;\n         }\n         if (entry == null) {\n@@ -172,7 +172,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n@@ -186,13 +186,13 @@\n       boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {\n     Set<Class<?>> classes = new HashSet<Class<?>>();\n     if (!baseDirectory.exists()) {\n-      LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n     File[] files = baseDirectory.listFiles(this.fileFilter);\n     if (files == null) {\n-      LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n@@ -207,7 +207,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 195, "bugNodeStartChar": 6883, "bugNodeLength": 72, "fixLineNum": 195, "fixNodeStartChar": 6883, "fixNodeLength": 71, "sourceBeforeFix": "LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath())", "sourceAfterFix": "LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath())"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "64dff91895f9df55fe3a07217a333efa4d37d92a", "fixCommitParentSHA1": "177bbff3919531e87739279e1435d649cfb10cc4", "bugFilePath": "hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java", "fixPatch": "diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\nindex 08799ba..703d15d 100644\n--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n@@ -133,7 +133,7 @@\n     try {\n       jarFile = new JarInputStream(new FileInputStream(jarFileName));\n     } catch (IOException ioEx) {\n-      LOG.error(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n+      LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n       throw ioEx;\n     }\n \n@@ -147,7 +147,7 @@\n           if (!proceedOnExceptions) {\n             throw ioEx;\n           }\n-          LOG.error(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n+          LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n           break;\n         }\n         if (entry == null) {\n@@ -172,7 +172,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n@@ -186,13 +186,13 @@\n       boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {\n     Set<Class<?>> classes = new HashSet<Class<?>>();\n     if (!baseDirectory.exists()) {\n-      LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n     File[] files = baseDirectory.listFiles(this.fileFilter);\n     if (files == null) {\n-      LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n@@ -207,7 +207,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 210, "bugNodeStartChar": 7480, "bugNodeLength": 50, "fixLineNum": 210, "fixNodeStartChar": 7480, "fixNodeLength": 49, "sourceBeforeFix": "LOG.error(\"Ignoring duplicate class \" + className)", "sourceAfterFix": "LOG.warn(\"Ignoring duplicate class \" + className)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "64dff91895f9df55fe3a07217a333efa4d37d92a", "fixCommitParentSHA1": "177bbff3919531e87739279e1435d649cfb10cc4", "bugFilePath": "hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java", "fixPatch": "diff --git a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\nindex 08799ba..703d15d 100644\n--- a/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n+++ b/hbase-common/src/test/java/org/apache/hadoop/hbase/ClassFinder.java\n@@ -133,7 +133,7 @@\n     try {\n       jarFile = new JarInputStream(new FileInputStream(jarFileName));\n     } catch (IOException ioEx) {\n-      LOG.error(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n+      LOG.warn(\"Failed to look for classes in \" + jarFileName + \": \" + ioEx);\n       throw ioEx;\n     }\n \n@@ -147,7 +147,7 @@\n           if (!proceedOnExceptions) {\n             throw ioEx;\n           }\n-          LOG.error(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n+          LOG.warn(\"Failed to get next entry from \" + jarFileName + \": \" + ioEx);\n           break;\n         }\n         if (entry == null) {\n@@ -172,7 +172,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n@@ -186,13 +186,13 @@\n       boolean proceedOnExceptions) throws ClassNotFoundException, LinkageError {\n     Set<Class<?>> classes = new HashSet<Class<?>>();\n     if (!baseDirectory.exists()) {\n-      LOG.error(\"Failed to find \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to find \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n     File[] files = baseDirectory.listFiles(this.fileFilter);\n     if (files == null) {\n-      LOG.error(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n+      LOG.warn(\"Failed to get files from \" + baseDirectory.getAbsolutePath());\n       return classes;\n     }\n \n@@ -207,7 +207,7 @@\n         Class<?> c = makeClass(className, proceedOnExceptions);\n         if (c != null) {\n           if (!classes.add(c)) {\n-            LOG.error(\"Ignoring duplicate class \" + className);\n+            LOG.warn(\"Ignoring duplicate class \" + className);\n           }\n         }\n       }\n", "projectName": "apache.hbase", "bugLineNum": 210, "bugNodeStartChar": 7480, "bugNodeLength": 50, "fixLineNum": 210, "fixNodeStartChar": 7480, "fixNodeLength": 49, "sourceBeforeFix": "LOG.error(\"Ignoring duplicate class \" + className)", "sourceAfterFix": "LOG.warn(\"Ignoring duplicate class \" + className)"}, {"bugType": "CHANGE_CALLER_IN_FUNCTION_CALL", "fixCommitSHA1": "76c6aee2c6d008e6f2345cdde262ad9ffb338afd", "fixCommitParentSHA1": "2d17ce39994b0baabd000b7afc68468e58155759", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\nindex 4978387..05c19de 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n@@ -201,7 +201,7 @@\n     if (c != 0) return c;\n \n     //type\n-    c = (0xff & a.getTypeByte()) - (0xff & b.getTypeByte());\n+    c = (0xff & b.getTypeByte()) - (0xff & a.getTypeByte());\n     return c;\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 204, "bugNodeStartChar": 7185, "bugNodeLength": 15, "fixLineNum": 204, "fixNodeStartChar": 7185, "fixNodeLength": 15, "sourceBeforeFix": "a.getTypeByte()", "sourceAfterFix": "b.getTypeByte()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "76c6aee2c6d008e6f2345cdde262ad9ffb338afd", "fixCommitParentSHA1": "2d17ce39994b0baabd000b7afc68468e58155759", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\nindex 4978387..05c19de 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n@@ -201,7 +201,7 @@\n     if (c != 0) return c;\n \n     //type\n-    c = (0xff & a.getTypeByte()) - (0xff & b.getTypeByte());\n+    c = (0xff & b.getTypeByte()) - (0xff & a.getTypeByte());\n     return c;\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 204, "bugNodeStartChar": 7185, "bugNodeLength": 15, "fixLineNum": 204, "fixNodeStartChar": 7185, "fixNodeLength": 15, "sourceBeforeFix": "a.getTypeByte()", "sourceAfterFix": "b.getTypeByte()"}, {"bugType": "CHANGE_CALLER_IN_FUNCTION_CALL", "fixCommitSHA1": "2ea3307765d2fe33b01481c853f15d4b4d927d02", "fixCommitParentSHA1": "a1a5f57bffc85b5e0585466fd05c84e593fee996", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\nindex 2e02ad2..4978387 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n@@ -86,7 +86,7 @@\n     if (c != 0) return c;\n \n     //type\n-    c = (0xff & a.getTypeByte()) - (0xff & b.getTypeByte());\n+    c = (0xff & b.getTypeByte()) - (0xff & a.getTypeByte());\n     if (c != 0) return c;\n \n     //mvccVersion: later sorts first\n", "projectName": "apache.hbase", "bugLineNum": 89, "bugNodeStartChar": 3479, "bugNodeLength": 15, "fixLineNum": 89, "fixNodeStartChar": 3479, "fixNodeLength": 15, "sourceBeforeFix": "a.getTypeByte()", "sourceAfterFix": "b.getTypeByte()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "2ea3307765d2fe33b01481c853f15d4b4d927d02", "fixCommitParentSHA1": "a1a5f57bffc85b5e0585466fd05c84e593fee996", "bugFilePath": "hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java", "fixPatch": "diff --git a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\nindex 2e02ad2..4978387 100644\n--- a/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n+++ b/hbase-common/src/main/java/org/apache/hadoop/hbase/CellComparator.java\n@@ -86,7 +86,7 @@\n     if (c != 0) return c;\n \n     //type\n-    c = (0xff & a.getTypeByte()) - (0xff & b.getTypeByte());\n+    c = (0xff & b.getTypeByte()) - (0xff & a.getTypeByte());\n     if (c != 0) return c;\n \n     //mvccVersion: later sorts first\n", "projectName": "apache.hbase", "bugLineNum": 89, "bugNodeStartChar": 3479, "bugNodeLength": 15, "fixLineNum": 89, "fixNodeStartChar": 3479, "fixNodeLength": 15, "sourceBeforeFix": "a.getTypeByte()", "sourceAfterFix": "b.getTypeByte()"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "bc9834426aefe5a931469ce8d35b0e54570ca57c", "fixCommitParentSHA1": "ddfc421a7dc3180e3700c092eab03a770f2498ee", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java\nindex a302d64..7fef0fd 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java\n@@ -134,18 +134,18 @@\n     return maximumTimestamp;\n   }\n \n-  public void write(final DataOutput out) throws IOException {\n+  public synchronized void write(final DataOutput out) throws IOException {\n     out.writeLong(minimumTimestamp);\n     out.writeLong(maximumTimestamp);\n   }\n \n-  public void readFields(final DataInput in) throws IOException {\n+  public synchronized void readFields(final DataInput in) throws IOException {\n     this.minimumTimestamp = in.readLong();\n     this.maximumTimestamp = in.readLong();\n   }\n \n   @Override\n-  public String toString() {\n+  public synchronized String toString() {\n     return \"[\" + minimumTimestamp + \",\" + maximumTimestamp + \"]\";\n   }\n }\n", "projectName": "apache.hbase", "bugLineNum": 137, "bugNodeStartChar": 4298, "bugNodeLength": 138, "fixLineNum": 137, "fixNodeStartChar": 4298, "fixNodeLength": 151, "sourceBeforeFix": "1", "sourceAfterFix": "33"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "bc9834426aefe5a931469ce8d35b0e54570ca57c", "fixCommitParentSHA1": "ddfc421a7dc3180e3700c092eab03a770f2498ee", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java\nindex a302d64..7fef0fd 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java\n@@ -134,18 +134,18 @@\n     return maximumTimestamp;\n   }\n \n-  public void write(final DataOutput out) throws IOException {\n+  public synchronized void write(final DataOutput out) throws IOException {\n     out.writeLong(minimumTimestamp);\n     out.writeLong(maximumTimestamp);\n   }\n \n-  public void readFields(final DataInput in) throws IOException {\n+  public synchronized void readFields(final DataInput in) throws IOException {\n     this.minimumTimestamp = in.readLong();\n     this.maximumTimestamp = in.readLong();\n   }\n \n   @Override\n-  public String toString() {\n+  public synchronized String toString() {\n     return \"[\" + minimumTimestamp + \",\" + maximumTimestamp + \"]\";\n   }\n }\n", "projectName": "apache.hbase", "bugLineNum": 142, "bugNodeStartChar": 4440, "bugNodeLength": 153, "fixLineNum": 142, "fixNodeStartChar": 4440, "fixNodeLength": 166, "sourceBeforeFix": "1", "sourceAfterFix": "33"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "bc9834426aefe5a931469ce8d35b0e54570ca57c", "fixCommitParentSHA1": "ddfc421a7dc3180e3700c092eab03a770f2498ee", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java\nindex a302d64..7fef0fd 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/TimeRangeTracker.java\n@@ -134,18 +134,18 @@\n     return maximumTimestamp;\n   }\n \n-  public void write(final DataOutput out) throws IOException {\n+  public synchronized void write(final DataOutput out) throws IOException {\n     out.writeLong(minimumTimestamp);\n     out.writeLong(maximumTimestamp);\n   }\n \n-  public void readFields(final DataInput in) throws IOException {\n+  public synchronized void readFields(final DataInput in) throws IOException {\n     this.minimumTimestamp = in.readLong();\n     this.maximumTimestamp = in.readLong();\n   }\n \n   @Override\n-  public String toString() {\n+  public synchronized String toString() {\n     return \"[\" + minimumTimestamp + \",\" + maximumTimestamp + \"]\";\n   }\n }\n", "projectName": "apache.hbase", "bugLineNum": 147, "bugNodeStartChar": 4597, "bugNodeLength": 108, "fixLineNum": 147, "fixNodeStartChar": 4597, "fixNodeLength": 121, "sourceBeforeFix": "1", "sourceAfterFix": "33"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "16b799dae56b54f82a14dc0e0ad24977f06df6f6", "fixCommitParentSHA1": "2859897de6fca78505d52e2d0feb71ff6260e149", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java\nindex 1f29969..4e83eeb 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java\n@@ -189,7 +189,7 @@\n   @Test\n   public void testJobConfigurationsWithTsvImporterTextMapper() throws Exception {\n     String table = \"test-\" + UUID.randomUUID();\n-    Path bulkOutputPath = new Path(util.getDataTestDir(table),\"hfiles\");\n+    Path bulkOutputPath = new Path(util.getDataTestDirOnTestFS(table),\"hfiles\");\n     String INPUT_FILE = \"InputFile1.csv\";\n     // Prepare the arguments required for the test.\n     String[] args =\n@@ -214,7 +214,7 @@\n   public void testBulkOutputWithTsvImporterTextMapper() throws Exception {\n     String table = \"test-\" + UUID.randomUUID();\n     String FAMILY = \"FAM\";\n-    Path bulkOutputPath = new Path(util.getDataTestDir(table),\"hfiles\");\n+    Path bulkOutputPath = new Path(util.getDataTestDirOnTestFS(table),\"hfiles\");\n     // Prepare the arguments required for the test.\n     String[] args =\n         new String[] {\n", "projectName": "apache.hbase", "bugLineNum": 192, "bugNodeStartChar": 6482, "bugNodeLength": 26, "fixLineNum": 192, "fixNodeStartChar": 6482, "fixNodeLength": 34, "sourceBeforeFix": "util.getDataTestDir(table)", "sourceAfterFix": "util.getDataTestDirOnTestFS(table)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "16b799dae56b54f82a14dc0e0ad24977f06df6f6", "fixCommitParentSHA1": "2859897de6fca78505d52e2d0feb71ff6260e149", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java\nindex 1f29969..4e83eeb 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java\n@@ -189,7 +189,7 @@\n   @Test\n   public void testJobConfigurationsWithTsvImporterTextMapper() throws Exception {\n     String table = \"test-\" + UUID.randomUUID();\n-    Path bulkOutputPath = new Path(util.getDataTestDir(table),\"hfiles\");\n+    Path bulkOutputPath = new Path(util.getDataTestDirOnTestFS(table),\"hfiles\");\n     String INPUT_FILE = \"InputFile1.csv\";\n     // Prepare the arguments required for the test.\n     String[] args =\n@@ -214,7 +214,7 @@\n   public void testBulkOutputWithTsvImporterTextMapper() throws Exception {\n     String table = \"test-\" + UUID.randomUUID();\n     String FAMILY = \"FAM\";\n-    Path bulkOutputPath = new Path(util.getDataTestDir(table),\"hfiles\");\n+    Path bulkOutputPath = new Path(util.getDataTestDirOnTestFS(table),\"hfiles\");\n     // Prepare the arguments required for the test.\n     String[] args =\n         new String[] {\n", "projectName": "apache.hbase", "bugLineNum": 192, "bugNodeStartChar": 6482, "bugNodeLength": 26, "fixLineNum": 192, "fixNodeStartChar": 6482, "fixNodeLength": 34, "sourceBeforeFix": "util.getDataTestDir(table)", "sourceAfterFix": "util.getDataTestDirOnTestFS(table)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "16b799dae56b54f82a14dc0e0ad24977f06df6f6", "fixCommitParentSHA1": "2859897de6fca78505d52e2d0feb71ff6260e149", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java\nindex 1f29969..4e83eeb 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java\n@@ -189,7 +189,7 @@\n   @Test\n   public void testJobConfigurationsWithTsvImporterTextMapper() throws Exception {\n     String table = \"test-\" + UUID.randomUUID();\n-    Path bulkOutputPath = new Path(util.getDataTestDir(table),\"hfiles\");\n+    Path bulkOutputPath = new Path(util.getDataTestDirOnTestFS(table),\"hfiles\");\n     String INPUT_FILE = \"InputFile1.csv\";\n     // Prepare the arguments required for the test.\n     String[] args =\n@@ -214,7 +214,7 @@\n   public void testBulkOutputWithTsvImporterTextMapper() throws Exception {\n     String table = \"test-\" + UUID.randomUUID();\n     String FAMILY = \"FAM\";\n-    Path bulkOutputPath = new Path(util.getDataTestDir(table),\"hfiles\");\n+    Path bulkOutputPath = new Path(util.getDataTestDirOnTestFS(table),\"hfiles\");\n     // Prepare the arguments required for the test.\n     String[] args =\n         new String[] {\n", "projectName": "apache.hbase", "bugLineNum": 217, "bugNodeStartChar": 7670, "bugNodeLength": 26, "fixLineNum": 217, "fixNodeStartChar": 7670, "fixNodeLength": 34, "sourceBeforeFix": "util.getDataTestDir(table)", "sourceAfterFix": "util.getDataTestDirOnTestFS(table)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "16b799dae56b54f82a14dc0e0ad24977f06df6f6", "fixCommitParentSHA1": "2859897de6fca78505d52e2d0feb71ff6260e149", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java\nindex 1f29969..4e83eeb 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestImportTsv.java\n@@ -189,7 +189,7 @@\n   @Test\n   public void testJobConfigurationsWithTsvImporterTextMapper() throws Exception {\n     String table = \"test-\" + UUID.randomUUID();\n-    Path bulkOutputPath = new Path(util.getDataTestDir(table),\"hfiles\");\n+    Path bulkOutputPath = new Path(util.getDataTestDirOnTestFS(table),\"hfiles\");\n     String INPUT_FILE = \"InputFile1.csv\";\n     // Prepare the arguments required for the test.\n     String[] args =\n@@ -214,7 +214,7 @@\n   public void testBulkOutputWithTsvImporterTextMapper() throws Exception {\n     String table = \"test-\" + UUID.randomUUID();\n     String FAMILY = \"FAM\";\n-    Path bulkOutputPath = new Path(util.getDataTestDir(table),\"hfiles\");\n+    Path bulkOutputPath = new Path(util.getDataTestDirOnTestFS(table),\"hfiles\");\n     // Prepare the arguments required for the test.\n     String[] args =\n         new String[] {\n", "projectName": "apache.hbase", "bugLineNum": 217, "bugNodeStartChar": 7670, "bugNodeLength": 26, "fixLineNum": 217, "fixNodeStartChar": 7670, "fixNodeLength": 34, "sourceBeforeFix": "util.getDataTestDir(table)", "sourceAfterFix": "util.getDataTestDirOnTestFS(table)"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "1280a4431f69ebc79bca46e1581f5b3c906166a5", "fixCommitParentSHA1": "6057d7a273389680a81f494f9523b5b4607246c7", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\nindex 88a15e9..106a9d3 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n@@ -4936,7 +4936,7 @@\n       ClassSize.ARRAY +\n       40 * ClassSize.REFERENCE + 2 * Bytes.SIZEOF_INT +\n       (11 * Bytes.SIZEOF_LONG) +\n-      4 * Bytes.SIZEOF_BOOLEAN);\n+      5 * Bytes.SIZEOF_BOOLEAN);\n \n   // woefully out of date - currently missing:\n   // 1 x HashMap - coprocessorServiceHandlers\n", "projectName": "apache.hbase", "bugLineNum": 4939, "bugNodeStartChar": 185225, "bugNodeLength": 24, "fixLineNum": 4939, "fixNodeStartChar": 185225, "fixNodeLength": 24, "sourceBeforeFix": "4 * Bytes.SIZEOF_BOOLEAN", "sourceAfterFix": "5 * Bytes.SIZEOF_BOOLEAN"}, {"bugType": "MORE_SPECIFIC_IF", "fixCommitSHA1": "db28d9720672b0198731ddf5d4427fd90b01610c", "fixCommitParentSHA1": "92e20f9f493b23a15a655d1466c0ae207ef16aea", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\nindex 8f8f98a..c4ea2b1 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n@@ -727,7 +727,7 @@\n         LOG.warn(\"Failed flushing store file, retring num=\" + i, e);\n         lastException = e;\n       }\n-      if (lastException != null) {\n+      if (lastException != null && i < (flushRetriesNumber - 1)) {\n         try {\n           Thread.sleep(pauseTime);\n         } catch (InterruptedException e) {\n", "projectName": "apache.hbase", "bugLineNum": 730, "bugNodeStartChar": 26556, "bugNodeLength": 21, "fixLineNum": 730, "fixNodeStartChar": 26556, "fixNodeLength": 53, "sourceBeforeFix": "lastException != null", "sourceAfterFix": "lastException != null && i < (flushRetriesNumber - 1)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "f528e817665b67e6c7eea0bfe7ca07c68b346e07", "fixCommitParentSHA1": "3bc9e2c95c6e45927ad7fb69383fab30748e669e", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/Increment.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Increment.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Increment.java\nindex 957fcdd..d480e1c 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Increment.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/Increment.java\n@@ -174,7 +174,7 @@\n    * @since 0.95.0\n    */\n   public Map<byte[], NavigableMap<byte [], Long>> getFamilyMapOfLongs() {\n-    NavigableMap<byte[], List<? extends Cell>> map = super.getFamilyMap();\n+    NavigableMap<byte[], List<? extends Cell>> map = super.getFamilyCellMap();\n     Map<byte [], NavigableMap<byte[], Long>> results =\n       new TreeMap<byte[], NavigableMap<byte [], Long>>(Bytes.BYTES_COMPARATOR);\n     for (Map.Entry<byte [], List<? extends Cell>> entry: map.entrySet()) {\n", "projectName": "apache.hbase", "bugLineNum": 177, "bugNodeStartChar": 6287, "bugNodeLength": 20, "fixLineNum": 177, "fixNodeStartChar": 6287, "fixNodeLength": 24, "sourceBeforeFix": "super.getFamilyMap()", "sourceAfterFix": "super.getFamilyCellMap()"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "b256284f5186c1d65be289ff5f77f1f1f9b1da10", "fixCommitParentSHA1": "2bbb39fc31ff3bd422a0fe3da2849c7128012e73", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestKeepDeletes.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestKeepDeletes.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestKeepDeletes.java\nindex f4f3b34..758ed86 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestKeepDeletes.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestKeepDeletes.java\n@@ -789,7 +789,8 @@\n   private int countDeleteMarkers(HRegion region) throws IOException {\n     Scan s = new Scan();\n     s.setRaw(true);\n-    s.setMaxVersions();\n+    // use max versions from the store(s)\n+    s.setMaxVersions(region.getStores().values().iterator().next().getScanInfo().getMaxVersions());\n     InternalScanner scan = region.getScanner(s);\n     List<KeyValue> kvs = new ArrayList<KeyValue>();\n     int res = 0;\n", "projectName": "apache.hbase", "bugLineNum": 792, "bugNodeStartChar": 23453, "bugNodeLength": 18, "fixLineNum": 793, "fixNodeStartChar": 23495, "fixNodeLength": 94, "sourceBeforeFix": "s.setMaxVersions()", "sourceAfterFix": "s.setMaxVersions(region.getStores().values().iterator().next().getScanInfo().getMaxVersions())"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "486b290863a66641b0ec30dbf2d9e349733cae44", "fixCommitParentSHA1": "2f64d221e1f4d11a64838effa7742ac89884f508", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\nindex cf6b749..a9bae62 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n@@ -1148,7 +1148,7 @@\n    */\n   public void closeRegion(final String regionname, final String serverName)\n   throws IOException {\n-    closeRegion(Bytes.toBytesBinary(regionname), serverName);\n+    closeRegion(Bytes.toBytes(regionname), serverName);\n   }\n \n   /**\n@@ -1266,7 +1266,7 @@\n    */\n   public void flush(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    flush(Bytes.toBytesBinary(tableNameOrRegionName));\n+    flush(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1335,7 +1335,7 @@\n    */\n   public void compact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    compact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    compact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1362,7 +1362,7 @@\n    */\n   public void compact(String tableOrRegionName, String columnFamily)\n     throws IOException,  InterruptedException {\n-    compact(Bytes.toBytesBinary(tableOrRegionName), Bytes.toBytes(columnFamily));\n+    compact(Bytes.toBytes(tableOrRegionName), Bytes.toBytes(columnFamily));\n   }\n \n   /**\n@@ -1389,7 +1389,7 @@\n    */\n   public void majorCompact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    majorCompact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    majorCompact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1696,7 +1696,7 @@\n    */\n   public void split(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName));\n+    split(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1714,7 +1714,7 @@\n \n   public void split(final String tableNameOrRegionName,\n     final String splitPoint) throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName), Bytes.toBytesBinary(splitPoint));\n+    split(Bytes.toBytes(tableNameOrRegionName), Bytes.toBytes(splitPoint));\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1151, "bugNodeStartChar": 45868, "bugNodeLength": 31, "fixLineNum": 1151, "fixNodeStartChar": 45868, "fixNodeLength": 25, "sourceBeforeFix": "Bytes.toBytesBinary(regionname)", "sourceAfterFix": "Bytes.toBytes(regionname)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "486b290863a66641b0ec30dbf2d9e349733cae44", "fixCommitParentSHA1": "2f64d221e1f4d11a64838effa7742ac89884f508", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\nindex cf6b749..a9bae62 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n@@ -1148,7 +1148,7 @@\n    */\n   public void closeRegion(final String regionname, final String serverName)\n   throws IOException {\n-    closeRegion(Bytes.toBytesBinary(regionname), serverName);\n+    closeRegion(Bytes.toBytes(regionname), serverName);\n   }\n \n   /**\n@@ -1266,7 +1266,7 @@\n    */\n   public void flush(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    flush(Bytes.toBytesBinary(tableNameOrRegionName));\n+    flush(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1335,7 +1335,7 @@\n    */\n   public void compact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    compact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    compact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1362,7 +1362,7 @@\n    */\n   public void compact(String tableOrRegionName, String columnFamily)\n     throws IOException,  InterruptedException {\n-    compact(Bytes.toBytesBinary(tableOrRegionName), Bytes.toBytes(columnFamily));\n+    compact(Bytes.toBytes(tableOrRegionName), Bytes.toBytes(columnFamily));\n   }\n \n   /**\n@@ -1389,7 +1389,7 @@\n    */\n   public void majorCompact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    majorCompact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    majorCompact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1696,7 +1696,7 @@\n    */\n   public void split(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName));\n+    split(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1714,7 +1714,7 @@\n \n   public void split(final String tableNameOrRegionName,\n     final String splitPoint) throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName), Bytes.toBytesBinary(splitPoint));\n+    split(Bytes.toBytes(tableNameOrRegionName), Bytes.toBytes(splitPoint));\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1151, "bugNodeStartChar": 45868, "bugNodeLength": 31, "fixLineNum": 1151, "fixNodeStartChar": 45868, "fixNodeLength": 25, "sourceBeforeFix": "Bytes.toBytesBinary(regionname)", "sourceAfterFix": "Bytes.toBytes(regionname)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "486b290863a66641b0ec30dbf2d9e349733cae44", "fixCommitParentSHA1": "2f64d221e1f4d11a64838effa7742ac89884f508", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\nindex cf6b749..a9bae62 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n@@ -1148,7 +1148,7 @@\n    */\n   public void closeRegion(final String regionname, final String serverName)\n   throws IOException {\n-    closeRegion(Bytes.toBytesBinary(regionname), serverName);\n+    closeRegion(Bytes.toBytes(regionname), serverName);\n   }\n \n   /**\n@@ -1266,7 +1266,7 @@\n    */\n   public void flush(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    flush(Bytes.toBytesBinary(tableNameOrRegionName));\n+    flush(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1335,7 +1335,7 @@\n    */\n   public void compact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    compact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    compact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1362,7 +1362,7 @@\n    */\n   public void compact(String tableOrRegionName, String columnFamily)\n     throws IOException,  InterruptedException {\n-    compact(Bytes.toBytesBinary(tableOrRegionName), Bytes.toBytes(columnFamily));\n+    compact(Bytes.toBytes(tableOrRegionName), Bytes.toBytes(columnFamily));\n   }\n \n   /**\n@@ -1389,7 +1389,7 @@\n    */\n   public void majorCompact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    majorCompact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    majorCompact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1696,7 +1696,7 @@\n    */\n   public void split(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName));\n+    split(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1714,7 +1714,7 @@\n \n   public void split(final String tableNameOrRegionName,\n     final String splitPoint) throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName), Bytes.toBytesBinary(splitPoint));\n+    split(Bytes.toBytes(tableNameOrRegionName), Bytes.toBytes(splitPoint));\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1269, "bugNodeStartChar": 50613, "bugNodeLength": 42, "fixLineNum": 1269, "fixNodeStartChar": 50613, "fixNodeLength": 36, "sourceBeforeFix": "Bytes.toBytesBinary(tableNameOrRegionName)", "sourceAfterFix": "Bytes.toBytes(tableNameOrRegionName)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "486b290863a66641b0ec30dbf2d9e349733cae44", "fixCommitParentSHA1": "2f64d221e1f4d11a64838effa7742ac89884f508", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\nindex cf6b749..a9bae62 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n@@ -1148,7 +1148,7 @@\n    */\n   public void closeRegion(final String regionname, final String serverName)\n   throws IOException {\n-    closeRegion(Bytes.toBytesBinary(regionname), serverName);\n+    closeRegion(Bytes.toBytes(regionname), serverName);\n   }\n \n   /**\n@@ -1266,7 +1266,7 @@\n    */\n   public void flush(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    flush(Bytes.toBytesBinary(tableNameOrRegionName));\n+    flush(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1335,7 +1335,7 @@\n    */\n   public void compact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    compact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    compact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1362,7 +1362,7 @@\n    */\n   public void compact(String tableOrRegionName, String columnFamily)\n     throws IOException,  InterruptedException {\n-    compact(Bytes.toBytesBinary(tableOrRegionName), Bytes.toBytes(columnFamily));\n+    compact(Bytes.toBytes(tableOrRegionName), Bytes.toBytes(columnFamily));\n   }\n \n   /**\n@@ -1389,7 +1389,7 @@\n    */\n   public void majorCompact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    majorCompact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    majorCompact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1696,7 +1696,7 @@\n    */\n   public void split(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName));\n+    split(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1714,7 +1714,7 @@\n \n   public void split(final String tableNameOrRegionName,\n     final String splitPoint) throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName), Bytes.toBytesBinary(splitPoint));\n+    split(Bytes.toBytes(tableNameOrRegionName), Bytes.toBytes(splitPoint));\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1269, "bugNodeStartChar": 50613, "bugNodeLength": 42, "fixLineNum": 1269, "fixNodeStartChar": 50613, "fixNodeLength": 36, "sourceBeforeFix": "Bytes.toBytesBinary(tableNameOrRegionName)", "sourceAfterFix": "Bytes.toBytes(tableNameOrRegionName)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "486b290863a66641b0ec30dbf2d9e349733cae44", "fixCommitParentSHA1": "2f64d221e1f4d11a64838effa7742ac89884f508", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\nindex cf6b749..a9bae62 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n@@ -1148,7 +1148,7 @@\n    */\n   public void closeRegion(final String regionname, final String serverName)\n   throws IOException {\n-    closeRegion(Bytes.toBytesBinary(regionname), serverName);\n+    closeRegion(Bytes.toBytes(regionname), serverName);\n   }\n \n   /**\n@@ -1266,7 +1266,7 @@\n    */\n   public void flush(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    flush(Bytes.toBytesBinary(tableNameOrRegionName));\n+    flush(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1335,7 +1335,7 @@\n    */\n   public void compact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    compact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    compact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1362,7 +1362,7 @@\n    */\n   public void compact(String tableOrRegionName, String columnFamily)\n     throws IOException,  InterruptedException {\n-    compact(Bytes.toBytesBinary(tableOrRegionName), Bytes.toBytes(columnFamily));\n+    compact(Bytes.toBytes(tableOrRegionName), Bytes.toBytes(columnFamily));\n   }\n \n   /**\n@@ -1389,7 +1389,7 @@\n    */\n   public void majorCompact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    majorCompact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    majorCompact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1696,7 +1696,7 @@\n    */\n   public void split(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName));\n+    split(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1714,7 +1714,7 @@\n \n   public void split(final String tableNameOrRegionName,\n     final String splitPoint) throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName), Bytes.toBytesBinary(splitPoint));\n+    split(Bytes.toBytes(tableNameOrRegionName), Bytes.toBytes(splitPoint));\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1338, "bugNodeStartChar": 52989, "bugNodeLength": 42, "fixLineNum": 1338, "fixNodeStartChar": 52989, "fixNodeLength": 36, "sourceBeforeFix": "Bytes.toBytesBinary(tableNameOrRegionName)", "sourceAfterFix": "Bytes.toBytes(tableNameOrRegionName)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "486b290863a66641b0ec30dbf2d9e349733cae44", "fixCommitParentSHA1": "2f64d221e1f4d11a64838effa7742ac89884f508", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\nindex cf6b749..a9bae62 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n@@ -1148,7 +1148,7 @@\n    */\n   public void closeRegion(final String regionname, final String serverName)\n   throws IOException {\n-    closeRegion(Bytes.toBytesBinary(regionname), serverName);\n+    closeRegion(Bytes.toBytes(regionname), serverName);\n   }\n \n   /**\n@@ -1266,7 +1266,7 @@\n    */\n   public void flush(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    flush(Bytes.toBytesBinary(tableNameOrRegionName));\n+    flush(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1335,7 +1335,7 @@\n    */\n   public void compact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    compact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    compact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1362,7 +1362,7 @@\n    */\n   public void compact(String tableOrRegionName, String columnFamily)\n     throws IOException,  InterruptedException {\n-    compact(Bytes.toBytesBinary(tableOrRegionName), Bytes.toBytes(columnFamily));\n+    compact(Bytes.toBytes(tableOrRegionName), Bytes.toBytes(columnFamily));\n   }\n \n   /**\n@@ -1389,7 +1389,7 @@\n    */\n   public void majorCompact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    majorCompact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    majorCompact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1696,7 +1696,7 @@\n    */\n   public void split(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName));\n+    split(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1714,7 +1714,7 @@\n \n   public void split(final String tableNameOrRegionName,\n     final String splitPoint) throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName), Bytes.toBytesBinary(splitPoint));\n+    split(Bytes.toBytes(tableNameOrRegionName), Bytes.toBytes(splitPoint));\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1338, "bugNodeStartChar": 52989, "bugNodeLength": 42, "fixLineNum": 1338, "fixNodeStartChar": 52989, "fixNodeLength": 36, "sourceBeforeFix": "Bytes.toBytesBinary(tableNameOrRegionName)", "sourceAfterFix": "Bytes.toBytes(tableNameOrRegionName)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "486b290863a66641b0ec30dbf2d9e349733cae44", "fixCommitParentSHA1": "2f64d221e1f4d11a64838effa7742ac89884f508", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\nindex cf6b749..a9bae62 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n@@ -1148,7 +1148,7 @@\n    */\n   public void closeRegion(final String regionname, final String serverName)\n   throws IOException {\n-    closeRegion(Bytes.toBytesBinary(regionname), serverName);\n+    closeRegion(Bytes.toBytes(regionname), serverName);\n   }\n \n   /**\n@@ -1266,7 +1266,7 @@\n    */\n   public void flush(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    flush(Bytes.toBytesBinary(tableNameOrRegionName));\n+    flush(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1335,7 +1335,7 @@\n    */\n   public void compact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    compact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    compact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1362,7 +1362,7 @@\n    */\n   public void compact(String tableOrRegionName, String columnFamily)\n     throws IOException,  InterruptedException {\n-    compact(Bytes.toBytesBinary(tableOrRegionName), Bytes.toBytes(columnFamily));\n+    compact(Bytes.toBytes(tableOrRegionName), Bytes.toBytes(columnFamily));\n   }\n \n   /**\n@@ -1389,7 +1389,7 @@\n    */\n   public void majorCompact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    majorCompact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    majorCompact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1696,7 +1696,7 @@\n    */\n   public void split(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName));\n+    split(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1714,7 +1714,7 @@\n \n   public void split(final String tableNameOrRegionName,\n     final String splitPoint) throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName), Bytes.toBytesBinary(splitPoint));\n+    split(Bytes.toBytes(tableNameOrRegionName), Bytes.toBytes(splitPoint));\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1365, "bugNodeStartChar": 53901, "bugNodeLength": 38, "fixLineNum": 1365, "fixNodeStartChar": 53901, "fixNodeLength": 32, "sourceBeforeFix": "Bytes.toBytesBinary(tableOrRegionName)", "sourceAfterFix": "Bytes.toBytes(tableOrRegionName)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "486b290863a66641b0ec30dbf2d9e349733cae44", "fixCommitParentSHA1": "2f64d221e1f4d11a64838effa7742ac89884f508", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\nindex cf6b749..a9bae62 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n@@ -1148,7 +1148,7 @@\n    */\n   public void closeRegion(final String regionname, final String serverName)\n   throws IOException {\n-    closeRegion(Bytes.toBytesBinary(regionname), serverName);\n+    closeRegion(Bytes.toBytes(regionname), serverName);\n   }\n \n   /**\n@@ -1266,7 +1266,7 @@\n    */\n   public void flush(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    flush(Bytes.toBytesBinary(tableNameOrRegionName));\n+    flush(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1335,7 +1335,7 @@\n    */\n   public void compact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    compact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    compact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1362,7 +1362,7 @@\n    */\n   public void compact(String tableOrRegionName, String columnFamily)\n     throws IOException,  InterruptedException {\n-    compact(Bytes.toBytesBinary(tableOrRegionName), Bytes.toBytes(columnFamily));\n+    compact(Bytes.toBytes(tableOrRegionName), Bytes.toBytes(columnFamily));\n   }\n \n   /**\n@@ -1389,7 +1389,7 @@\n    */\n   public void majorCompact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    majorCompact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    majorCompact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1696,7 +1696,7 @@\n    */\n   public void split(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName));\n+    split(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1714,7 +1714,7 @@\n \n   public void split(final String tableNameOrRegionName,\n     final String splitPoint) throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName), Bytes.toBytesBinary(splitPoint));\n+    split(Bytes.toBytes(tableNameOrRegionName), Bytes.toBytes(splitPoint));\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1365, "bugNodeStartChar": 53901, "bugNodeLength": 38, "fixLineNum": 1365, "fixNodeStartChar": 53901, "fixNodeLength": 32, "sourceBeforeFix": "Bytes.toBytesBinary(tableOrRegionName)", "sourceAfterFix": "Bytes.toBytes(tableOrRegionName)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "486b290863a66641b0ec30dbf2d9e349733cae44", "fixCommitParentSHA1": "2f64d221e1f4d11a64838effa7742ac89884f508", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\nindex cf6b749..a9bae62 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n@@ -1148,7 +1148,7 @@\n    */\n   public void closeRegion(final String regionname, final String serverName)\n   throws IOException {\n-    closeRegion(Bytes.toBytesBinary(regionname), serverName);\n+    closeRegion(Bytes.toBytes(regionname), serverName);\n   }\n \n   /**\n@@ -1266,7 +1266,7 @@\n    */\n   public void flush(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    flush(Bytes.toBytesBinary(tableNameOrRegionName));\n+    flush(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1335,7 +1335,7 @@\n    */\n   public void compact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    compact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    compact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1362,7 +1362,7 @@\n    */\n   public void compact(String tableOrRegionName, String columnFamily)\n     throws IOException,  InterruptedException {\n-    compact(Bytes.toBytesBinary(tableOrRegionName), Bytes.toBytes(columnFamily));\n+    compact(Bytes.toBytes(tableOrRegionName), Bytes.toBytes(columnFamily));\n   }\n \n   /**\n@@ -1389,7 +1389,7 @@\n    */\n   public void majorCompact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    majorCompact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    majorCompact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1696,7 +1696,7 @@\n    */\n   public void split(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName));\n+    split(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1714,7 +1714,7 @@\n \n   public void split(final String tableNameOrRegionName,\n     final String splitPoint) throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName), Bytes.toBytesBinary(splitPoint));\n+    split(Bytes.toBytes(tableNameOrRegionName), Bytes.toBytes(splitPoint));\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1392, "bugNodeStartChar": 54883, "bugNodeLength": 42, "fixLineNum": 1392, "fixNodeStartChar": 54883, "fixNodeLength": 36, "sourceBeforeFix": "Bytes.toBytesBinary(tableNameOrRegionName)", "sourceAfterFix": "Bytes.toBytes(tableNameOrRegionName)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "486b290863a66641b0ec30dbf2d9e349733cae44", "fixCommitParentSHA1": "2f64d221e1f4d11a64838effa7742ac89884f508", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\nindex cf6b749..a9bae62 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n@@ -1148,7 +1148,7 @@\n    */\n   public void closeRegion(final String regionname, final String serverName)\n   throws IOException {\n-    closeRegion(Bytes.toBytesBinary(regionname), serverName);\n+    closeRegion(Bytes.toBytes(regionname), serverName);\n   }\n \n   /**\n@@ -1266,7 +1266,7 @@\n    */\n   public void flush(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    flush(Bytes.toBytesBinary(tableNameOrRegionName));\n+    flush(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1335,7 +1335,7 @@\n    */\n   public void compact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    compact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    compact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1362,7 +1362,7 @@\n    */\n   public void compact(String tableOrRegionName, String columnFamily)\n     throws IOException,  InterruptedException {\n-    compact(Bytes.toBytesBinary(tableOrRegionName), Bytes.toBytes(columnFamily));\n+    compact(Bytes.toBytes(tableOrRegionName), Bytes.toBytes(columnFamily));\n   }\n \n   /**\n@@ -1389,7 +1389,7 @@\n    */\n   public void majorCompact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    majorCompact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    majorCompact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1696,7 +1696,7 @@\n    */\n   public void split(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName));\n+    split(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1714,7 +1714,7 @@\n \n   public void split(final String tableNameOrRegionName,\n     final String splitPoint) throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName), Bytes.toBytesBinary(splitPoint));\n+    split(Bytes.toBytes(tableNameOrRegionName), Bytes.toBytes(splitPoint));\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1392, "bugNodeStartChar": 54883, "bugNodeLength": 42, "fixLineNum": 1392, "fixNodeStartChar": 54883, "fixNodeLength": 36, "sourceBeforeFix": "Bytes.toBytesBinary(tableNameOrRegionName)", "sourceAfterFix": "Bytes.toBytes(tableNameOrRegionName)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "486b290863a66641b0ec30dbf2d9e349733cae44", "fixCommitParentSHA1": "2f64d221e1f4d11a64838effa7742ac89884f508", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\nindex cf6b749..a9bae62 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n@@ -1148,7 +1148,7 @@\n    */\n   public void closeRegion(final String regionname, final String serverName)\n   throws IOException {\n-    closeRegion(Bytes.toBytesBinary(regionname), serverName);\n+    closeRegion(Bytes.toBytes(regionname), serverName);\n   }\n \n   /**\n@@ -1266,7 +1266,7 @@\n    */\n   public void flush(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    flush(Bytes.toBytesBinary(tableNameOrRegionName));\n+    flush(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1335,7 +1335,7 @@\n    */\n   public void compact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    compact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    compact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1362,7 +1362,7 @@\n    */\n   public void compact(String tableOrRegionName, String columnFamily)\n     throws IOException,  InterruptedException {\n-    compact(Bytes.toBytesBinary(tableOrRegionName), Bytes.toBytes(columnFamily));\n+    compact(Bytes.toBytes(tableOrRegionName), Bytes.toBytes(columnFamily));\n   }\n \n   /**\n@@ -1389,7 +1389,7 @@\n    */\n   public void majorCompact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    majorCompact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    majorCompact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1696,7 +1696,7 @@\n    */\n   public void split(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName));\n+    split(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1714,7 +1714,7 @@\n \n   public void split(final String tableNameOrRegionName,\n     final String splitPoint) throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName), Bytes.toBytesBinary(splitPoint));\n+    split(Bytes.toBytes(tableNameOrRegionName), Bytes.toBytes(splitPoint));\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1699, "bugNodeStartChar": 66557, "bugNodeLength": 42, "fixLineNum": 1699, "fixNodeStartChar": 66557, "fixNodeLength": 36, "sourceBeforeFix": "Bytes.toBytesBinary(tableNameOrRegionName)", "sourceAfterFix": "Bytes.toBytes(tableNameOrRegionName)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "486b290863a66641b0ec30dbf2d9e349733cae44", "fixCommitParentSHA1": "2f64d221e1f4d11a64838effa7742ac89884f508", "bugFilePath": "hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java", "fixPatch": "diff --git a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\nindex cf6b749..a9bae62 100644\n--- a/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n+++ b/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HBaseAdmin.java\n@@ -1148,7 +1148,7 @@\n    */\n   public void closeRegion(final String regionname, final String serverName)\n   throws IOException {\n-    closeRegion(Bytes.toBytesBinary(regionname), serverName);\n+    closeRegion(Bytes.toBytes(regionname), serverName);\n   }\n \n   /**\n@@ -1266,7 +1266,7 @@\n    */\n   public void flush(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    flush(Bytes.toBytesBinary(tableNameOrRegionName));\n+    flush(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1335,7 +1335,7 @@\n    */\n   public void compact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    compact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    compact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1362,7 +1362,7 @@\n    */\n   public void compact(String tableOrRegionName, String columnFamily)\n     throws IOException,  InterruptedException {\n-    compact(Bytes.toBytesBinary(tableOrRegionName), Bytes.toBytes(columnFamily));\n+    compact(Bytes.toBytes(tableOrRegionName), Bytes.toBytes(columnFamily));\n   }\n \n   /**\n@@ -1389,7 +1389,7 @@\n    */\n   public void majorCompact(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    majorCompact(Bytes.toBytesBinary(tableNameOrRegionName));\n+    majorCompact(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1696,7 +1696,7 @@\n    */\n   public void split(final String tableNameOrRegionName)\n   throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName));\n+    split(Bytes.toBytes(tableNameOrRegionName));\n   }\n \n   /**\n@@ -1714,7 +1714,7 @@\n \n   public void split(final String tableNameOrRegionName,\n     final String splitPoint) throws IOException, InterruptedException {\n-    split(Bytes.toBytesBinary(tableNameOrRegionName), Bytes.toBytesBinary(splitPoint));\n+    split(Bytes.toBytes(tableNameOrRegionName), Bytes.toBytes(splitPoint));\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1699, "bugNodeStartChar": 66557, "bugNodeLength": 42, "fixLineNum": 1699, "fixNodeStartChar": 66557, "fixNodeLength": 36, "sourceBeforeFix": "Bytes.toBytesBinary(tableNameOrRegionName)", "sourceAfterFix": "Bytes.toBytes(tableNameOrRegionName)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "851141a35746241636a39315553f49d89643b358", "fixCommitParentSHA1": "11d986a0effa3317d03d02e7e207338e8ba72281", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java\nindex d7bcc80..f266794 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestStoreFile.java\n@@ -175,6 +175,7 @@\n   public void testHFileLink() throws IOException {\n     final String columnFamily = \"f\";\n \n+    // force temp data in hbase/target/test-data instead of /tmp/hbase-xxxx/ \n     Configuration testConf = new Configuration(this.conf);\n     FSUtils.setRootDir(testConf, this.testDir);\n \n@@ -197,7 +198,7 @@\n                   HFileLink.createHFileLinkName(hri, storeFilePath.getName()));\n \n     // Try to open store file from link\n-    StoreFile hsf = new StoreFile(this.fs, linkFilePath, conf, cacheConf,\n+    StoreFile hsf = new StoreFile(this.fs, linkFilePath, testConf, cacheConf,\n         BloomType.NONE, NoOpDataBlockEncoder.INSTANCE);\n     assertTrue(hsf.isLink());\n \n", "projectName": "apache.hbase", "bugLineNum": 200, "bugNodeStartChar": 7753, "bugNodeLength": 108, "fixLineNum": 200, "fixNodeStartChar": 7753, "fixNodeLength": 112, "sourceBeforeFix": "new StoreFile(this.fs,linkFilePath,conf,cacheConf,BloomType.NONE,NoOpDataBlockEncoder.INSTANCE)", "sourceAfterFix": "new StoreFile(this.fs,linkFilePath,testConf,cacheConf,BloomType.NONE,NoOpDataBlockEncoder.INSTANCE)"}, {"bugType": "SWAP_BOOLEAN_LITERAL", "fixCommitSHA1": "4405698ee99fe26d0ac9317a2df96096f2731a7b", "fixCommitParentSHA1": "3b006f510e98f24d640b63e393a1dfcdf0e69f53", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java\nindex 3e5238e..1282585 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/snapshot/RegionServerSnapshotManager.java\n@@ -347,7 +347,11 @@\n       Collection<Future<Void>> tasks = futures;\n       LOG.debug(\"cancelling \" + tasks.size() + \" tasks for snapshot \" + name);\n       for (Future<Void> f: tasks) {\n-        f.cancel(true);\n+        // TODO Ideally we'd interrupt hbase threads when we cancel.  However it seems that there\n+        // are places in the HBase code where row/region locks are taken and not released in a\n+        // finally block.  Thus we cancel without interrupting.  Cancellations will be slower to\n+        // complete but we won't suffer from unreleased locks due to poor code discipline.\n+        f.cancel(false);\n       }\n \n       // evict remaining tasks and futures from taskPool.\n", "projectName": "apache.hbase", "bugLineNum": 350, "bugNodeStartChar": 15274, "bugNodeLength": 14, "fixLineNum": 354, "fixNodeStartChar": 15655, "fixNodeLength": 15, "sourceBeforeFix": "f.cancel(true)", "sourceAfterFix": "f.cancel(false)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "e9f14f107361d9cef5582c2d2a8e657691e76ec6", "fixCommitParentSHA1": "4d7b2824beda162637d8d72c97381d89f1383f59", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\nindex 82840c5..8ba27bb 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\n@@ -85,7 +85,7 @@\n     HRegionInfo mockRegionInfo = Mockito.mock(HRegionInfo.class);\n     Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);\n     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);\n     qosFunction.setRegionServer(mockRS);\n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.HIGH_QOS);\n   }\n@@ -132,14 +132,14 @@\n     Mockito.when(mockRegionScanner.getRegionInfo()).thenReturn(mockRegionInfo);\n     Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);\n     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);\n \n     qosFunction.setRegionServer(mockRS);\n \n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.HIGH_QOS);\n \n     //the same as above but with non-meta region\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(false);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(false);\n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.NORMAL_QOS);\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 88, "bugNodeStartChar": 4131, "bugNodeLength": 29, "fixLineNum": 88, "fixNodeStartChar": 4131, "fixNodeLength": 28, "sourceBeforeFix": "mockRegionInfo.isMetaRegion()", "sourceAfterFix": "mockRegionInfo.isMetaTable()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "e9f14f107361d9cef5582c2d2a8e657691e76ec6", "fixCommitParentSHA1": "4d7b2824beda162637d8d72c97381d89f1383f59", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\nindex 82840c5..8ba27bb 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\n@@ -85,7 +85,7 @@\n     HRegionInfo mockRegionInfo = Mockito.mock(HRegionInfo.class);\n     Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);\n     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);\n     qosFunction.setRegionServer(mockRS);\n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.HIGH_QOS);\n   }\n@@ -132,14 +132,14 @@\n     Mockito.when(mockRegionScanner.getRegionInfo()).thenReturn(mockRegionInfo);\n     Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);\n     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);\n \n     qosFunction.setRegionServer(mockRS);\n \n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.HIGH_QOS);\n \n     //the same as above but with non-meta region\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(false);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(false);\n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.NORMAL_QOS);\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 88, "bugNodeStartChar": 4131, "bugNodeLength": 29, "fixLineNum": 88, "fixNodeStartChar": 4131, "fixNodeLength": 28, "sourceBeforeFix": "mockRegionInfo.isMetaRegion()", "sourceAfterFix": "mockRegionInfo.isMetaTable()"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "e9f14f107361d9cef5582c2d2a8e657691e76ec6", "fixCommitParentSHA1": "4d7b2824beda162637d8d72c97381d89f1383f59", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\nindex 82840c5..8ba27bb 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\n@@ -85,7 +85,7 @@\n     HRegionInfo mockRegionInfo = Mockito.mock(HRegionInfo.class);\n     Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);\n     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);\n     qosFunction.setRegionServer(mockRS);\n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.HIGH_QOS);\n   }\n@@ -132,14 +132,14 @@\n     Mockito.when(mockRegionScanner.getRegionInfo()).thenReturn(mockRegionInfo);\n     Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);\n     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);\n \n     qosFunction.setRegionServer(mockRS);\n \n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.HIGH_QOS);\n \n     //the same as above but with non-meta region\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(false);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(false);\n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.NORMAL_QOS);\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 135, "bugNodeStartChar": 6532, "bugNodeLength": 29, "fixLineNum": 135, "fixNodeStartChar": 6532, "fixNodeLength": 28, "sourceBeforeFix": "mockRegionInfo.isMetaRegion()", "sourceAfterFix": "mockRegionInfo.isMetaTable()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "e9f14f107361d9cef5582c2d2a8e657691e76ec6", "fixCommitParentSHA1": "4d7b2824beda162637d8d72c97381d89f1383f59", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\nindex 82840c5..8ba27bb 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\n@@ -85,7 +85,7 @@\n     HRegionInfo mockRegionInfo = Mockito.mock(HRegionInfo.class);\n     Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);\n     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);\n     qosFunction.setRegionServer(mockRS);\n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.HIGH_QOS);\n   }\n@@ -132,14 +132,14 @@\n     Mockito.when(mockRegionScanner.getRegionInfo()).thenReturn(mockRegionInfo);\n     Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);\n     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);\n \n     qosFunction.setRegionServer(mockRS);\n \n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.HIGH_QOS);\n \n     //the same as above but with non-meta region\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(false);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(false);\n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.NORMAL_QOS);\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 135, "bugNodeStartChar": 6532, "bugNodeLength": 29, "fixLineNum": 135, "fixNodeStartChar": 6532, "fixNodeLength": 28, "sourceBeforeFix": "mockRegionInfo.isMetaRegion()", "sourceAfterFix": "mockRegionInfo.isMetaTable()"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "e9f14f107361d9cef5582c2d2a8e657691e76ec6", "fixCommitParentSHA1": "4d7b2824beda162637d8d72c97381d89f1383f59", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\nindex 82840c5..8ba27bb 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\n@@ -85,7 +85,7 @@\n     HRegionInfo mockRegionInfo = Mockito.mock(HRegionInfo.class);\n     Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);\n     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);\n     qosFunction.setRegionServer(mockRS);\n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.HIGH_QOS);\n   }\n@@ -132,14 +132,14 @@\n     Mockito.when(mockRegionScanner.getRegionInfo()).thenReturn(mockRegionInfo);\n     Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);\n     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);\n \n     qosFunction.setRegionServer(mockRS);\n \n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.HIGH_QOS);\n \n     //the same as above but with non-meta region\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(false);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(false);\n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.NORMAL_QOS);\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 142, "bugNodeStartChar": 6762, "bugNodeLength": 29, "fixLineNum": 142, "fixNodeStartChar": 6762, "fixNodeLength": 28, "sourceBeforeFix": "mockRegionInfo.isMetaRegion()", "sourceAfterFix": "mockRegionInfo.isMetaTable()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "e9f14f107361d9cef5582c2d2a8e657691e76ec6", "fixCommitParentSHA1": "4d7b2824beda162637d8d72c97381d89f1383f59", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\nindex 82840c5..8ba27bb 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestPriorityRpc.java\n@@ -85,7 +85,7 @@\n     HRegionInfo mockRegionInfo = Mockito.mock(HRegionInfo.class);\n     Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);\n     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);\n     qosFunction.setRegionServer(mockRS);\n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.HIGH_QOS);\n   }\n@@ -132,14 +132,14 @@\n     Mockito.when(mockRegionScanner.getRegionInfo()).thenReturn(mockRegionInfo);\n     Mockito.when(mockRS.getRegion((RegionSpecifier)Mockito.any())).thenReturn(mockRegion);\n     Mockito.when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(true);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(true);\n \n     qosFunction.setRegionServer(mockRS);\n \n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.HIGH_QOS);\n \n     //the same as above but with non-meta region\n-    Mockito.when(mockRegionInfo.isMetaRegion()).thenReturn(false);\n+    Mockito.when(mockRegionInfo.isMetaTable()).thenReturn(false);\n     assertTrue (qosFunction.apply(rpcRequest) == HConstants.NORMAL_QOS);\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 142, "bugNodeStartChar": 6762, "bugNodeLength": 29, "fixLineNum": 142, "fixNodeStartChar": 6762, "fixNodeLength": 28, "sourceBeforeFix": "mockRegionInfo.isMetaRegion()", "sourceAfterFix": "mockRegionInfo.isMetaTable()"}, {"bugType": "CHANGE_CALLER_IN_FUNCTION_CALL", "fixCommitSHA1": "4409ba741c1e9edc6a7b9e47829343417a339f9c", "fixCommitParentSHA1": "92c98a76d111c4f8870bd8be15f3cff6fd0ff51b", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBasePolicyProvider.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBasePolicyProvider.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBasePolicyProvider.java\nindex a1c32ff..6fcaddd 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBasePolicyProvider.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBasePolicyProvider.java\n@@ -51,7 +51,7 @@\n     conf.set(\"hadoop.policy.file\", \"hbase-policy.xml\");\n     if (conf.getBoolean(\n           ServiceAuthorizationManager.SERVICE_AUTHORIZATION_CONFIG, false)) {\n-      ServiceAuthorizationManager.refresh(conf, new HBasePolicyProvider());\n+      authManager.refresh(conf, new HBasePolicyProvider());\n     }\n   }\n }\n", "projectName": "apache.hbase", "bugLineNum": 54, "bugNodeStartChar": 2367, "bugNodeLength": 68, "fixLineNum": 54, "fixNodeStartChar": 2367, "fixNodeLength": 52, "sourceBeforeFix": "ServiceAuthorizationManager.refresh(conf,new HBasePolicyProvider())", "sourceAfterFix": "authManager.refresh(conf,new HBasePolicyProvider())"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "4409ba741c1e9edc6a7b9e47829343417a339f9c", "fixCommitParentSHA1": "92c98a76d111c4f8870bd8be15f3cff6fd0ff51b", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBasePolicyProvider.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBasePolicyProvider.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBasePolicyProvider.java\nindex a1c32ff..6fcaddd 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBasePolicyProvider.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/security/HBasePolicyProvider.java\n@@ -51,7 +51,7 @@\n     conf.set(\"hadoop.policy.file\", \"hbase-policy.xml\");\n     if (conf.getBoolean(\n           ServiceAuthorizationManager.SERVICE_AUTHORIZATION_CONFIG, false)) {\n-      ServiceAuthorizationManager.refresh(conf, new HBasePolicyProvider());\n+      authManager.refresh(conf, new HBasePolicyProvider());\n     }\n   }\n }\n", "projectName": "apache.hbase", "bugLineNum": 54, "bugNodeStartChar": 2367, "bugNodeLength": 68, "fixLineNum": 54, "fixNodeStartChar": 2367, "fixNodeLength": 52, "sourceBeforeFix": "ServiceAuthorizationManager.refresh(conf,new HBasePolicyProvider())", "sourceAfterFix": "authManager.refresh(conf,new HBasePolicyProvider())"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "c8486bb7052487867fe9c7221681d4d4bc027541", "fixCommitParentSHA1": "cfafe13c1fc4b7f0f3e8f01f69c91ca2a030b836", "bugFilePath": "hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplication.java", "fixPatch": "diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplication.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplication.java\nindex 5741a07..5a9aaf2 100644\n--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplication.java\n+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/replication/TestReplication.java\n@@ -77,7 +77,7 @@\n   private static final int NB_ROWS_IN_BATCH = 100;\n   private static final int NB_ROWS_IN_BIG_BATCH =\n       NB_ROWS_IN_BATCH * 10;\n-  private static final long SLEEP_TIME = 500;\n+  private static final long SLEEP_TIME = 1500;\n   private static final int NB_RETRIES = 10;\n \n   private static final byte[] tableName = Bytes.toBytes(\"test\");\n", "projectName": "apache.hbase", "bugLineNum": 80, "bugNodeStartChar": 3227, "bugNodeLength": 16, "fixLineNum": 80, "fixNodeStartChar": 3227, "fixNodeLength": 17, "sourceBeforeFix": "SLEEP_TIME=500", "sourceAfterFix": "SLEEP_TIME=1500"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "5d19fcfd8328e89ac9ff5c4a31734d7ed152a501", "fixCommitParentSHA1": "3d759b79c8a49cd0dfb02d3938d413f64f9762ee", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\nindex 3f6c578..3f13698 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HStore.java\n@@ -1837,7 +1837,7 @@\n   }\n \n   public static final long FIXED_OVERHEAD =\n-      ClassSize.align((20 * ClassSize.REFERENCE) + (6 * Bytes.SIZEOF_LONG)\n+      ClassSize.align((20 * ClassSize.REFERENCE) + (4 * Bytes.SIZEOF_LONG)\n               + (3 * Bytes.SIZEOF_INT) + Bytes.SIZEOF_BOOLEAN);\n \n   public static final long DEEP_OVERHEAD = ClassSize.align(FIXED_OVERHEAD\n", "projectName": "apache.hbase", "bugLineNum": 1840, "bugNodeStartChar": 65243, "bugNodeLength": 21, "fixLineNum": 1840, "fixNodeStartChar": 65243, "fixNodeLength": 21, "sourceBeforeFix": "6 * Bytes.SIZEOF_LONG", "sourceAfterFix": "4 * Bytes.SIZEOF_LONG"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "e74cd24ff2229b060e219af33c3abe5cbf1079d1", "fixCommitParentSHA1": "5b7f4bb5353977371d95e9ccb8e523f64d1ecd19", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java\nindex 9b68c5c..4b355f7 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java\n@@ -441,7 +441,7 @@\n                   Bytes.toStringBinary(data));\n               throw e;\n             }\n-            LOG.error(\"Node \" + path + \" already exists and this is not a \" +\n+            LOG.info(\"Node \" + path + \" already exists and this is not a \" +\n                 \"retry\");\n             throw e;\n \n", "projectName": "apache.hbase", "bugLineNum": 444, "bugNodeStartChar": 15443, "bugNodeLength": 90, "fixLineNum": 444, "fixNodeStartChar": 15443, "fixNodeLength": 89, "sourceBeforeFix": "LOG.error(\"Node \" + path + \" already exists and this is not a \"+ \"retry\")", "sourceAfterFix": "LOG.info(\"Node \" + path + \" already exists and this is not a \"+ \"retry\")"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "e74cd24ff2229b060e219af33c3abe5cbf1079d1", "fixCommitParentSHA1": "5b7f4bb5353977371d95e9ccb8e523f64d1ecd19", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java\nindex 9b68c5c..4b355f7 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/zookeeper/RecoverableZooKeeper.java\n@@ -441,7 +441,7 @@\n                   Bytes.toStringBinary(data));\n               throw e;\n             }\n-            LOG.error(\"Node \" + path + \" already exists and this is not a \" +\n+            LOG.info(\"Node \" + path + \" already exists and this is not a \" +\n                 \"retry\");\n             throw e;\n \n", "projectName": "apache.hbase", "bugLineNum": 444, "bugNodeStartChar": 15443, "bugNodeLength": 90, "fixLineNum": 444, "fixNodeStartChar": 15443, "fixNodeLength": 89, "sourceBeforeFix": "LOG.error(\"Node \" + path + \" already exists and this is not a \"+ \"retry\")", "sourceAfterFix": "LOG.info(\"Node \" + path + \" already exists and this is not a \"+ \"retry\")"}, {"bugType": "LESS_SPECIFIC_IF", "fixCommitSHA1": "933a38f9e928bb7651864fcb1506ebbed6b8dbbc", "fixCommitParentSHA1": "9d107882d3e982c01b408e930d9d85a6257f16c3", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/metrics/MetricsMBeanBase.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/metrics/MetricsMBeanBase.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/metrics/MetricsMBeanBase.java\nindex ce5e323..88dd95d 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/metrics/MetricsMBeanBase.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/metrics/MetricsMBeanBase.java\n@@ -75,7 +75,8 @@\n   private static MetricsRegistry copyMinusHBaseMetrics(final MetricsRegistry mr) {\n     MetricsRegistry copy = new MetricsRegistry();\n     for (MetricsBase metric : mr.getMetricsList()) {\n-      if (metric instanceof MetricsRate || metric instanceof MetricsString) {\n+      if (metric instanceof MetricsRate || metric instanceof MetricsString ||\n+          metric instanceof MetricsHistogram || metric instanceof ExactCounterMetric) {\n         continue;\n       }\n       copy.add(metric.getName(), metric);\n", "projectName": "apache.hbase", "bugLineNum": 78, "bugNodeStartChar": 2980, "bugNodeLength": 64, "fixLineNum": 78, "fixNodeStartChar": 2980, "fixNodeLength": 152, "sourceBeforeFix": "metric instanceof MetricsRate || metric instanceof MetricsString", "sourceAfterFix": "metric instanceof MetricsRate || metric instanceof MetricsString || metric instanceof MetricsHistogram|| metric instanceof ExactCounterMetric"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "2706742224ec0e89dee98a7b99e91d4c2853a63c", "fixCommitParentSHA1": "ce86fdc233ec6796816cdc04bb3e1eaa99262863", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/util/hbck/OfflineMetaRepair.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/util/hbck/OfflineMetaRepair.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/util/hbck/OfflineMetaRepair.java\nindex ae2c9f7..71e6b2f 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/util/hbck/OfflineMetaRepair.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/util/hbck/OfflineMetaRepair.java\n@@ -43,7 +43,7 @@\n @InterfaceAudience.Public\n @InterfaceStability.Evolving\n public class OfflineMetaRepair {\n-  private static final Log LOG = LogFactory.getLog(HBaseFsck.class.getName());\n+  private static final Log LOG = LogFactory.getLog(OfflineMetaRepair.class.getName());\n \n   protected static void printUsageAndExit() {\n     StringBuilder sb = new StringBuilder();\n", "projectName": "apache.hbase", "bugLineNum": 46, "bugNodeStartChar": 1908, "bugNodeLength": 15, "fixLineNum": 46, "fixNodeStartChar": 1908, "fixNodeLength": 23, "sourceBeforeFix": "HBaseFsck.class", "sourceAfterFix": "OfflineMetaRepair.class"}, {"bugType": "CHANGE_UNARY_OPERATOR", "fixCommitSHA1": "c8b6b7ad22c1d315fa94ecb681f868be1df27744", "fixCommitParentSHA1": "57afee6a6bb2e7284fe0886ca64e92f404a51419", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/CleanerChore.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/CleanerChore.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/CleanerChore.java\nindex 6d32122..8711c82 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/CleanerChore.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/master/cleaner/CleanerChore.java\n@@ -218,7 +218,7 @@\n     }\n     // delete this file if it passes all the cleaners\n     LOG.debug(\"Removing:\" + filePath + \" from archive\");\n-    if (this.fs.delete(filePath, false)) {\n+    if (!this.fs.delete(filePath, false)) {\n       LOG.warn(\"Attempted to delete:\" + filePath\n           + \", but couldn't. Run cleaner chain and attempt to delete on next pass.\");\n     }\n", "projectName": "apache.hbase", "bugLineNum": 221, "bugNodeStartChar": 8425, "bugNodeLength": 31, "fixLineNum": 221, "fixNodeStartChar": 8425, "fixNodeLength": 32, "sourceBeforeFix": "this.fs.delete(filePath,false)", "sourceAfterFix": "!this.fs.delete(filePath,false)"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "9a1ba2926a59ce9fd80e6355fabdeccdec6ad19f", "fixCommitParentSHA1": "91d42fe70a89fef0342e8bd9a4d085dbbc0a8952", "bugFilePath": "hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java", "fixPatch": "diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java\nindex 5a38121..193a4a0 100644\n--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java\n+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServerRunner.java\n@@ -247,7 +247,7 @@\n       setupServer();\n       tserver.serve();\n     } catch (Exception e) {\n-      LOG.fatal(\"Cannot run ThriftServer\");\n+      LOG.fatal(\"Cannot run ThriftServer\", e);\n       // Crash the process if the ThriftServer is not running\n       System.exit(-1);\n     }\n", "projectName": "apache.hbase", "bugLineNum": 250, "bugNodeStartChar": 9337, "bugNodeLength": 36, "fixLineNum": 250, "fixNodeStartChar": 9337, "fixNodeLength": 39, "sourceBeforeFix": "LOG.fatal(\"Cannot run ThriftServer\")", "sourceAfterFix": "LOG.fatal(\"Cannot run ThriftServer\",e)"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "0f708f7370f47b739585b54cd19c8da241fe3f9e", "fixCommitParentSHA1": "953d89e3a93bfd9355b421e704cbab0894cf1a0e", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java b/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java\nindex d64e147..702f622 100644\n--- a/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java\n+++ b/src/main/java/org/apache/hadoop/hbase/master/DefaultLoadBalancer.java\n@@ -106,7 +106,7 @@\n   * regions which were assigned to the server after some other region server\n   * crashed.\n   */\n-   private class RegionInfoComparator implements Comparator<HRegionInfo> {\n+   private static class RegionInfoComparator implements Comparator<HRegionInfo> {\n        @Override\n        public int compare(HRegionInfo l, HRegionInfo r) {\n           long diff = r.getRegionId() - l.getRegionId();\n", "projectName": "apache.hbase", "bugLineNum": 109, "bugNodeStartChar": 3885, "bugNodeLength": 306, "fixLineNum": 109, "fixNodeStartChar": 3885, "fixNodeLength": 313, "sourceBeforeFix": "2", "sourceAfterFix": "10"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "3039d610149aa9a633141bf41abcbd1923dcdff8", "fixCommitParentSHA1": "7dbde6f9327e026b3e9ae0f68c8ac6a0ce6e76cb", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java b/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java\nindex 30f17ee..bd524e7 100644\n--- a/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java\n+++ b/src/main/java/org/apache/hadoop/hbase/util/RegionSplitter.java\n@@ -584,7 +584,7 @@\n    * @throws IOException if the specified SplitAlgorithm class couldn't be\n    * instantiated\n    */\n-  static SplitAlgorithm newSplitAlgoInstance(Configuration conf,\n+  public static SplitAlgorithm newSplitAlgoInstance(Configuration conf,\n           String splitClassName) throws IOException {\n     Class<?> splitClass;\n \n", "projectName": "apache.hbase", "bugLineNum": 583, "bugNodeStartChar": 23820, "bugNodeLength": 1326, "fixLineNum": 583, "fixNodeStartChar": 23820, "fixNodeLength": 1333, "sourceBeforeFix": "8", "sourceAfterFix": "9"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "e896f6d400c7ad946141adbf7317df7c680fcdc6", "fixCommitParentSHA1": "1f2aadb80dacd061a2816d32a232db8bb5d54cb1", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java b/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java\nindex 1647b02..a406839 100644\n--- a/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java\n+++ b/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java\n@@ -174,7 +174,7 @@\n     } catch (DoNotRetryIOException e) {\n       throw e;\n     } catch (IOException e) {\n-      LOG.debug(\"recovered from \" + StringUtils.stringifyException(e));\n+      LOG.info(\"recovered from \" + StringUtils.stringifyException(e));\n       if (lastSuccessfulRow == null) {\n         LOG.warn(\"We are restarting the first next() invocation,\" +\n             \" if your mapper's restarted a few other times like this\" +\n", "projectName": "apache.hbase", "bugLineNum": 177, "bugNodeStartChar": 5533, "bugNodeLength": 64, "fixLineNum": 177, "fixNodeStartChar": 5533, "fixNodeLength": 63, "sourceBeforeFix": "LOG.debug(\"recovered from \" + StringUtils.stringifyException(e))", "sourceAfterFix": "LOG.info(\"recovered from \" + StringUtils.stringifyException(e))"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "e896f6d400c7ad946141adbf7317df7c680fcdc6", "fixCommitParentSHA1": "1f2aadb80dacd061a2816d32a232db8bb5d54cb1", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java b/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java\nindex 1647b02..a406839 100644\n--- a/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java\n+++ b/src/main/java/org/apache/hadoop/hbase/mapreduce/TableRecordReaderImpl.java\n@@ -174,7 +174,7 @@\n     } catch (DoNotRetryIOException e) {\n       throw e;\n     } catch (IOException e) {\n-      LOG.debug(\"recovered from \" + StringUtils.stringifyException(e));\n+      LOG.info(\"recovered from \" + StringUtils.stringifyException(e));\n       if (lastSuccessfulRow == null) {\n         LOG.warn(\"We are restarting the first next() invocation,\" +\n             \" if your mapper's restarted a few other times like this\" +\n", "projectName": "apache.hbase", "bugLineNum": 177, "bugNodeStartChar": 5533, "bugNodeLength": 64, "fixLineNum": 177, "fixNodeStartChar": 5533, "fixNodeLength": 63, "sourceBeforeFix": "LOG.debug(\"recovered from \" + StringUtils.stringifyException(e))", "sourceAfterFix": "LOG.info(\"recovered from \" + StringUtils.stringifyException(e))"}, {"bugType": "ADD_THROWS_EXCEPTION", "fixCommitSHA1": "930eb4975915906bb8e88c4376ad40954f67c806", "fixCommitParentSHA1": "08a9170236a20323c6627b30934c2cb66b4cfb2b", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/replication/regionserver/Replication.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/replication/regionserver/Replication.java b/src/main/java/org/apache/hadoop/hbase/replication/regionserver/Replication.java\nindex 983ab86..464de86 100644\n--- a/src/main/java/org/apache/hadoop/hbase/replication/regionserver/Replication.java\n+++ b/src/main/java/org/apache/hadoop/hbase/replication/regionserver/Replication.java\n@@ -191,7 +191,7 @@\n   }\n \n   @Override\n-  public void postLogRoll(Path oldPath, Path newPath) {\n+  public void postLogRoll(Path oldPath, Path newPath) throws IOException {\n     getReplicationManager().logRolled(newPath);\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 193, "bugNodeStartChar": 6316, "bugNodeLength": 117, "fixLineNum": 193, "fixNodeStartChar": 6316, "fixNodeLength": 136, "sourceBeforeFix": "1", "sourceAfterFix": "1"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "0b83bf1d7a47be379c1bf8bc332232884f9331b5", "fixCommitParentSHA1": "89c642d7544549010d74c46044d76cfe1e1e0e5b", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\nindex 4d885c6..7cbdb98 100644\n--- a/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n@@ -3690,7 +3690,7 @@\n   public static final long FIXED_OVERHEAD = ClassSize.align(\n       ClassSize.OBJECT +\n       ClassSize.ARRAY +\n-      27 * ClassSize.REFERENCE + Bytes.SIZEOF_INT +\n+      28 * ClassSize.REFERENCE + Bytes.SIZEOF_INT +\n       (4 * Bytes.SIZEOF_LONG) +\n       Bytes.SIZEOF_BOOLEAN);\n \n", "projectName": "apache.hbase", "bugLineNum": 3693, "bugNodeStartChar": 127042, "bugNodeLength": 24, "fixLineNum": 3693, "fixNodeStartChar": 127042, "fixNodeLength": 24, "sourceBeforeFix": "27 * ClassSize.REFERENCE", "sourceAfterFix": "28 * ClassSize.REFERENCE"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "0b83bf1d7a47be379c1bf8bc332232884f9331b5", "fixCommitParentSHA1": "89c642d7544549010d74c46044d76cfe1e1e0e5b", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/regionserver/Store.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java b/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java\nindex 9c6fd01..564f55a 100644\n--- a/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java\n+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/Store.java\n@@ -1789,7 +1789,7 @@\n \n   public static final long FIXED_OVERHEAD = ClassSize.align(\n       ClassSize.OBJECT + (16 * ClassSize.REFERENCE) +\n-      (8 * Bytes.SIZEOF_LONG) + (1 * Bytes.SIZEOF_DOUBLE) +\n+      (7 * Bytes.SIZEOF_LONG) + (1 * Bytes.SIZEOF_DOUBLE) +\n       (6 * Bytes.SIZEOF_INT) + (3 * Bytes.SIZEOF_BOOLEAN));\n \n   public static final long DEEP_OVERHEAD = ClassSize.align(FIXED_OVERHEAD +\n", "projectName": "apache.hbase", "bugLineNum": 1792, "bugNodeStartChar": 63934, "bugNodeLength": 21, "fixLineNum": 1792, "fixNodeStartChar": 63934, "fixNodeLength": 21, "sourceBeforeFix": "8 * Bytes.SIZEOF_LONG", "sourceAfterFix": "7 * Bytes.SIZEOF_LONG"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "ee55d1e74445f403ce06c0a5457265c1b2544172", "fixCommitParentSHA1": "2356e400a2ba271bb9735da0e231d846356dce7d", "bugFilePath": "src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRolling.java", "fixPatch": "diff --git a/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRolling.java b/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRolling.java\nindex 8856b93..cca86d9 100644\n--- a/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRolling.java\n+++ b/src/test/java/org/apache/hadoop/hbase/regionserver/wal/TestLogRolling.java\n@@ -474,7 +474,7 @@\n     writeData(table, 5);\n \n     // force a log roll to read back and verify previously written logs\n-    log.rollWriter();\n+    log.rollWriter(true);\n \n     // read back the data written\n     Set<String> loggedRows = new HashSet<String>();\n", "projectName": "apache.hbase", "bugLineNum": 477, "bugNodeStartChar": 17745, "bugNodeLength": 16, "fixLineNum": 477, "fixNodeStartChar": 17745, "fixNodeLength": 20, "sourceBeforeFix": "log.rollWriter()", "sourceAfterFix": "log.rollWriter(true)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "4c5264d4b3c9fd50ffe24a43a046e1e101a08854", "fixCommitParentSHA1": "76a743e8f0314bdc5840419e1d59c43be84d66d3", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/thrift/ThriftServer.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServer.java b/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServer.java\nindex d551478..be5f36d 100644\n--- a/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServer.java\n+++ b/src/main/java/org/apache/hadoop/hbase/thrift/ThriftServer.java\n@@ -1005,7 +1005,7 @@\n           printUsageAndExit(options, -1);\n         }\n       } else {\n-        listenAddress = InetAddress.getLocalHost();\n+        listenAddress = InetAddress.getByName(\"0.0.0.0\");\n       }\n       TServerTransport serverTransport = new TServerSocket(new InetSocketAddress(listenAddress, listenPort));\n \n", "projectName": "apache.hbase", "bugLineNum": 1008, "bugNodeStartChar": 36013, "bugNodeLength": 26, "fixLineNum": 1008, "fixNodeStartChar": 36013, "fixNodeLength": 32, "sourceBeforeFix": "InetAddress.getLocalHost()", "sourceAfterFix": "InetAddress.getByName(\"0.0.0.0\")"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "cf35402980c9661ecfb22593da783a0cb3dfe913", "fixCommitParentSHA1": "7bbeb3231bc9e40e0c31da1101c7e2208215ba6f", "bugFilePath": "src/test/java/org/apache/hadoop/hbase/util/TestCompressionTest.java", "fixPatch": "diff --git a/src/test/java/org/apache/hadoop/hbase/util/TestCompressionTest.java b/src/test/java/org/apache/hadoop/hbase/util/TestCompressionTest.java\nindex 3170ab3..14bf24f0 100644\n--- a/src/test/java/org/apache/hadoop/hbase/util/TestCompressionTest.java\n+++ b/src/test/java/org/apache/hadoop/hbase/util/TestCompressionTest.java\n@@ -54,6 +54,6 @@\n     assertFalse(CompressionTest.testCompression(\"LZO\"));\n     assertTrue(CompressionTest.testCompression(\"NONE\"));\n     assertTrue(CompressionTest.testCompression(\"GZ\"));\n-    assertTrue(CompressionTest.testCompression(\"SNAPPY\"));\n+    assertFalse(CompressionTest.testCompression(\"SNAPPY\"));\n   }\n }\n", "projectName": "apache.hbase", "bugLineNum": 57, "bugNodeStartChar": 1901, "bugNodeLength": 53, "fixLineNum": 57, "fixNodeStartChar": 1901, "fixNodeLength": 54, "sourceBeforeFix": "assertTrue(CompressionTest.testCompression(\"SNAPPY\"))", "sourceAfterFix": "assertFalse(CompressionTest.testCompression(\"SNAPPY\"))"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "cf35402980c9661ecfb22593da783a0cb3dfe913", "fixCommitParentSHA1": "7bbeb3231bc9e40e0c31da1101c7e2208215ba6f", "bugFilePath": "src/test/java/org/apache/hadoop/hbase/util/TestCompressionTest.java", "fixPatch": "diff --git a/src/test/java/org/apache/hadoop/hbase/util/TestCompressionTest.java b/src/test/java/org/apache/hadoop/hbase/util/TestCompressionTest.java\nindex 3170ab3..14bf24f0 100644\n--- a/src/test/java/org/apache/hadoop/hbase/util/TestCompressionTest.java\n+++ b/src/test/java/org/apache/hadoop/hbase/util/TestCompressionTest.java\n@@ -54,6 +54,6 @@\n     assertFalse(CompressionTest.testCompression(\"LZO\"));\n     assertTrue(CompressionTest.testCompression(\"NONE\"));\n     assertTrue(CompressionTest.testCompression(\"GZ\"));\n-    assertTrue(CompressionTest.testCompression(\"SNAPPY\"));\n+    assertFalse(CompressionTest.testCompression(\"SNAPPY\"));\n   }\n }\n", "projectName": "apache.hbase", "bugLineNum": 57, "bugNodeStartChar": 1901, "bugNodeLength": 53, "fixLineNum": 57, "fixNodeStartChar": 1901, "fixNodeLength": 54, "sourceBeforeFix": "assertTrue(CompressionTest.testCompression(\"SNAPPY\"))", "sourceAfterFix": "assertFalse(CompressionTest.testCompression(\"SNAPPY\"))"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "1bf409f05285c855256698f91988202341b2853b", "fixCommitParentSHA1": "dc2659524af86a060cc31cb6fc8dc6f508eea4a3", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java b/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java\nindex 92acb35..9f01a96 100644\n--- a/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java\n+++ b/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java\n@@ -243,7 +243,7 @@\n         \"servers=\" + numServers + \" \" +\n         \"regions=\" + numRegions + \" average=\" + average + \" \" +\n         \"mostloaded=\" + serversByLoad.lastKey().getLoad() +\n-        \" leastloaded=\" + serversByLoad.lastKey().getLoad());\n+        \" leastloaded=\" + serversByLoad.firstKey().getLoad());\n       return null;\n     }\n     int min = numRegions / numServers;\n", "projectName": "apache.hbase", "bugLineNum": 246, "bugNodeStartChar": 10641, "bugNodeLength": 23, "fixLineNum": 246, "fixNodeStartChar": 10641, "fixNodeLength": 24, "sourceBeforeFix": "serversByLoad.lastKey()", "sourceAfterFix": "serversByLoad.firstKey()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "1bf409f05285c855256698f91988202341b2853b", "fixCommitParentSHA1": "dc2659524af86a060cc31cb6fc8dc6f508eea4a3", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java b/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java\nindex 92acb35..9f01a96 100644\n--- a/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java\n+++ b/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java\n@@ -243,7 +243,7 @@\n         \"servers=\" + numServers + \" \" +\n         \"regions=\" + numRegions + \" average=\" + average + \" \" +\n         \"mostloaded=\" + serversByLoad.lastKey().getLoad() +\n-        \" leastloaded=\" + serversByLoad.lastKey().getLoad());\n+        \" leastloaded=\" + serversByLoad.firstKey().getLoad());\n       return null;\n     }\n     int min = numRegions / numServers;\n", "projectName": "apache.hbase", "bugLineNum": 246, "bugNodeStartChar": 10641, "bugNodeLength": 23, "fixLineNum": 246, "fixNodeStartChar": 10641, "fixNodeLength": 24, "sourceBeforeFix": "serversByLoad.lastKey()", "sourceAfterFix": "serversByLoad.firstKey()"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "6fb0428103ae6b75100a32aadffca730d663dbd5", "fixCommitParentSHA1": "93a75bb3eb4b015f054e787fd138d7764fe20237", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java b/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java\nindex 463e880..4b5d62f 100644\n--- a/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java\n+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/MemStore.java\n@@ -823,7 +823,7 @@\n   }\n \n   public final static long FIXED_OVERHEAD = ClassSize.align(\n-      ClassSize.OBJECT + (11 * ClassSize.REFERENCE));\n+      ClassSize.OBJECT + (12 * ClassSize.REFERENCE));\n \n   public final static long DEEP_OVERHEAD = ClassSize.align(FIXED_OVERHEAD +\n       ClassSize.REENTRANT_LOCK + ClassSize.ATOMIC_LONG +\n", "projectName": "apache.hbase", "bugLineNum": 826, "bugNodeStartChar": 27544, "bugNodeLength": 24, "fixLineNum": 826, "fixNodeStartChar": 27544, "fixNodeLength": 24, "sourceBeforeFix": "11 * ClassSize.REFERENCE", "sourceAfterFix": "12 * ClassSize.REFERENCE"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "6164a0cb8522b0bc75e3338364d25175d094937b", "fixCommitParentSHA1": "e7b8bd4ab0bea1fefa3f70953cdeafc9d4524aef", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java b/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java\nindex c348f7a..70affa0 100644\n--- a/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java\n+++ b/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java\n@@ -112,7 +112,7 @@\n  */\n @SuppressWarnings(\"serial\")\n public class HConnectionManager {\n-  static final int MAX_CACHED_HBASE_INSTANCES = 31;\n+  static final int MAX_CACHED_HBASE_INSTANCES = 2001;\n \n   // A LRU Map of Configuration hashcode -> TableServers. We set instances to 31.\n   // The zk default max connections to the ensemble from the one client is 30 so\n", "projectName": "apache.hbase", "bugLineNum": 115, "bugNodeStartChar": 5718, "bugNodeLength": 31, "fixLineNum": 115, "fixNodeStartChar": 5718, "fixNodeLength": 33, "sourceBeforeFix": "MAX_CACHED_HBASE_INSTANCES=31", "sourceAfterFix": "MAX_CACHED_HBASE_INSTANCES=2001"}, {"bugType": "CHANGE_OPERATOR", "fixCommitSHA1": "0641df92c5dd9d8d92944e9165ffe5f2d2c9c9ec", "fixCommitParentSHA1": "8e9918a88a321c6a04869756b6472e963500268c", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java b/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java\nindex 37f99a6..827073c 100644\n--- a/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java\n+++ b/src/main/java/org/apache/hadoop/hbase/zookeeper/ZKUtil.java\n@@ -900,7 +900,7 @@\n   throws KeeperException {\n     try {\n       ZooKeeper zk = zkw.getZooKeeper();\n-      if (zk.exists(znode, false) != null) {\n+      if (zk.exists(znode, false) == null) {\n         zk.create(znode, new byte[0], Ids.OPEN_ACL_UNSAFE,\n             CreateMode.PERSISTENT);\n       }\n", "projectName": "apache.hbase", "bugLineNum": 903, "bugNodeStartChar": 31609, "bugNodeLength": 31, "fixLineNum": 903, "fixNodeStartChar": 31609, "fixNodeLength": 31, "sourceBeforeFix": "zk.exists(znode,false) != null", "sourceAfterFix": "zk.exists(znode,false) == null"}, {"bugType": "ADD_THROWS_EXCEPTION", "fixCommitSHA1": "f616c0c70964fb4e88c3dc60c59d99b6d1d4759a", "fixCommitParentSHA1": "a7f8453d506ea390215464faba30ad061c016216", "bugFilePath": "src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java", "fixPatch": "diff --git a/src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java b/src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java\nindex a55935b..d01043c 100644\n--- a/src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java\n+++ b/src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java\n@@ -52,7 +52,7 @@\n   }\n \n   @Test\n-  public void testTableWithStringName() {\n+  public void testTableWithStringName() throws Exception {\n     HTablePool pool =\n       new HTablePool(TEST_UTIL.getConfiguration(), Integer.MAX_VALUE);\n     String tableName = Bytes.toString(TABLENAME);\n@@ -86,7 +86,7 @@\n   }\n \n   @Test\n-  public void testTableWithMaxSize() {\n+  public void testTableWithMaxSize() throws Exception {\n     HTablePool pool = new HTablePool(TEST_UTIL.getConfiguration(), 2);\n \n     // Request tables from an empty pool\n", "projectName": "apache.hbase", "bugLineNum": 54, "bugNodeStartChar": 1835, "bugNodeLength": 527, "fixLineNum": 54, "fixNodeStartChar": 1835, "fixNodeLength": 544, "sourceBeforeFix": "1", "sourceAfterFix": "1"}, {"bugType": "ADD_THROWS_EXCEPTION", "fixCommitSHA1": "f616c0c70964fb4e88c3dc60c59d99b6d1d4759a", "fixCommitParentSHA1": "a7f8453d506ea390215464faba30ad061c016216", "bugFilePath": "src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java", "fixPatch": "diff --git a/src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java b/src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java\nindex a55935b..d01043c 100644\n--- a/src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java\n+++ b/src/test/java/org/apache/hadoop/hbase/client/TestHTablePool.java\n@@ -52,7 +52,7 @@\n   }\n \n   @Test\n-  public void testTableWithStringName() {\n+  public void testTableWithStringName() throws Exception {\n     HTablePool pool =\n       new HTablePool(TEST_UTIL.getConfiguration(), Integer.MAX_VALUE);\n     String tableName = Bytes.toString(TABLENAME);\n@@ -86,7 +86,7 @@\n   }\n \n   @Test\n-  public void testTableWithMaxSize() {\n+  public void testTableWithMaxSize() throws Exception {\n     HTablePool pool = new HTablePool(TEST_UTIL.getConfiguration(), 2);\n \n     // Request tables from an empty pool\n", "projectName": "apache.hbase", "bugLineNum": 88, "bugNodeStartChar": 2863, "bugNodeLength": 858, "fixLineNum": 88, "fixNodeStartChar": 2863, "fixNodeLength": 875, "sourceBeforeFix": "1", "sourceAfterFix": "1"}, {"bugType": "CHANGE_CALLER_IN_FUNCTION_CALL", "fixCommitSHA1": "c222e2b4862045d5ef7040103e1c50b6593dda20", "fixCommitParentSHA1": "fbd1666643c9d614112b4a6f54ed0ee68b9b1426", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java b/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java\nindex beb0233..f9d6934 100644\n--- a/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java\n+++ b/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java\n@@ -271,11 +271,11 @@\n         if (skipBadLines) {\n           System.err.println(\n               \"Bad line at offset: \" + offset.get() + \":\\n\" +\n-              badLine.getMessage());\n+              e.getMessage());\n           badLineCount.increment(1);\n           return;\n         } else {\n-          throw new IOException(badLine);\n+          throw new IOException(e);\n         }\n       } catch (InterruptedException e) {\n         e.printStackTrace();\n", "projectName": "apache.hbase", "bugLineNum": 274, "bugNodeStartChar": 9184, "bugNodeLength": 20, "fixLineNum": 274, "fixNodeStartChar": 9184, "fixNodeLength": 14, "sourceBeforeFix": "badLine.getMessage()", "sourceAfterFix": "e.getMessage()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "c222e2b4862045d5ef7040103e1c50b6593dda20", "fixCommitParentSHA1": "fbd1666643c9d614112b4a6f54ed0ee68b9b1426", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java b/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java\nindex beb0233..f9d6934 100644\n--- a/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java\n+++ b/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java\n@@ -271,11 +271,11 @@\n         if (skipBadLines) {\n           System.err.println(\n               \"Bad line at offset: \" + offset.get() + \":\\n\" +\n-              badLine.getMessage());\n+              e.getMessage());\n           badLineCount.increment(1);\n           return;\n         } else {\n-          throw new IOException(badLine);\n+          throw new IOException(e);\n         }\n       } catch (InterruptedException e) {\n         e.printStackTrace();\n", "projectName": "apache.hbase", "bugLineNum": 274, "bugNodeStartChar": 9184, "bugNodeLength": 20, "fixLineNum": 274, "fixNodeStartChar": 9184, "fixNodeLength": 14, "sourceBeforeFix": "badLine.getMessage()", "sourceAfterFix": "e.getMessage()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "c222e2b4862045d5ef7040103e1c50b6593dda20", "fixCommitParentSHA1": "fbd1666643c9d614112b4a6f54ed0ee68b9b1426", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java b/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java\nindex beb0233..f9d6934 100644\n--- a/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java\n+++ b/src/main/java/org/apache/hadoop/hbase/mapreduce/ImportTsv.java\n@@ -271,11 +271,11 @@\n         if (skipBadLines) {\n           System.err.println(\n               \"Bad line at offset: \" + offset.get() + \":\\n\" +\n-              badLine.getMessage());\n+              e.getMessage());\n           badLineCount.increment(1);\n           return;\n         } else {\n-          throw new IOException(badLine);\n+          throw new IOException(e);\n         }\n       } catch (InterruptedException e) {\n         e.printStackTrace();\n", "projectName": "apache.hbase", "bugLineNum": 278, "bugNodeStartChar": 9295, "bugNodeLength": 24, "fixLineNum": 278, "fixNodeStartChar": 9295, "fixNodeLength": 18, "sourceBeforeFix": "new IOException(badLine)", "sourceAfterFix": "new IOException(e)"}, {"bugType": "CHANGE_OPERATOR", "fixCommitSHA1": "1889d7ed5c71d8e82e3d440962d7d7ef26c0956f", "fixCommitParentSHA1": "23916d541da5aab910311d3b3f86982f2c29cc8f", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/master/handler/OpenedRegionHandler.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/master/handler/OpenedRegionHandler.java b/src/main/java/org/apache/hadoop/hbase/master/handler/OpenedRegionHandler.java\nindex 5913058..c478ab7 100644\n--- a/src/main/java/org/apache/hadoop/hbase/master/handler/OpenedRegionHandler.java\n+++ b/src/main/java/org/apache/hadoop/hbase/master/handler/OpenedRegionHandler.java\n@@ -93,7 +93,7 @@\n     }\n     // Code to defend against case where we get SPLIT before region open\n     // processing completes; temporary till we make SPLITs go via zk -- 0.92.\n-    if (this.assignmentManager.isRegionInTransition(regionInfo) == null) {\n+    if (this.assignmentManager.isRegionInTransition(regionInfo) != null) {\n       this.assignmentManager.regionOnline(regionInfo, serverInfo);\n     } else {\n       LOG.warn(\"Skipping the onlining of \" + regionInfo.getRegionNameAsString() +\n", "projectName": "apache.hbase", "bugLineNum": 96, "bugNodeStartChar": 3297, "bugNodeLength": 63, "fixLineNum": 96, "fixNodeStartChar": 3297, "fixNodeLength": 63, "sourceBeforeFix": "this.assignmentManager.isRegionInTransition(regionInfo) == null", "sourceAfterFix": "this.assignmentManager.isRegionInTransition(regionInfo) != null"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "4573c829b4c62ce1ad2a8f214ecea56654128cf9", "fixCommitParentSHA1": "87a95ec3e1eb86ff86a8acf50d40e7acae55be33", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java b/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\nindex 6596872..8f4fde9 100644\n--- a/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\n+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/MemStoreFlusher.java\n@@ -239,7 +239,7 @@\n       } catch (ConcurrentModificationException ex) {\n         continue;\n       } catch (Exception ex) {\n-        LOG.error(\"Cache flusher failed for entry \" + fqe);\n+        LOG.error(\"Cache flusher failed for entry \" + fqe, ex);\n         if (!server.checkFileSystem()) {\n           break;\n         }\n", "projectName": "apache.hbase", "bugLineNum": 242, "bugNodeStartChar": 9636, "bugNodeLength": 50, "fixLineNum": 242, "fixNodeStartChar": 9636, "fixNodeLength": 54, "sourceBeforeFix": "LOG.error(\"Cache flusher failed for entry \" + fqe)", "sourceAfterFix": "LOG.error(\"Cache flusher failed for entry \" + fqe,ex)"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "d41dd79f10b62df7ed89aa6b048390bf2b440775", "fixCommitParentSHA1": "b5365c49aa5d5b12676b6291f9189b17a7e49560", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java b/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java\nindex 901be8b..cd83b05 100644\n--- a/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java\n+++ b/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java\n@@ -173,7 +173,7 @@\n       LOG.info(\"Skipping load balancing.  servers=\" + numServers + \" \" +\n           \"regions=\" + numRegions + \" average=\" + average + \" \" +\n           \"mostloaded=\" + serversByLoad.lastKey().getLoad().getNumberOfRegions() +\n-          \" leastloaded=\" + serversByLoad.lastKey().getLoad().getNumberOfRegions());\n+          \" leastloaded=\" + serversByLoad.firstKey().getLoad().getNumberOfRegions());\n       return null;\n     }\n \n", "projectName": "apache.hbase", "bugLineNum": 176, "bugNodeStartChar": 7966, "bugNodeLength": 23, "fixLineNum": 176, "fixNodeStartChar": 7966, "fixNodeLength": 24, "sourceBeforeFix": "serversByLoad.lastKey()", "sourceAfterFix": "serversByLoad.firstKey()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "d41dd79f10b62df7ed89aa6b048390bf2b440775", "fixCommitParentSHA1": "b5365c49aa5d5b12676b6291f9189b17a7e49560", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java b/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java\nindex 901be8b..cd83b05 100644\n--- a/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java\n+++ b/src/main/java/org/apache/hadoop/hbase/master/LoadBalancer.java\n@@ -173,7 +173,7 @@\n       LOG.info(\"Skipping load balancing.  servers=\" + numServers + \" \" +\n           \"regions=\" + numRegions + \" average=\" + average + \" \" +\n           \"mostloaded=\" + serversByLoad.lastKey().getLoad().getNumberOfRegions() +\n-          \" leastloaded=\" + serversByLoad.lastKey().getLoad().getNumberOfRegions());\n+          \" leastloaded=\" + serversByLoad.firstKey().getLoad().getNumberOfRegions());\n       return null;\n     }\n \n", "projectName": "apache.hbase", "bugLineNum": 176, "bugNodeStartChar": 7966, "bugNodeLength": 23, "fixLineNum": 176, "fixNodeStartChar": 7966, "fixNodeLength": 24, "sourceBeforeFix": "serversByLoad.lastKey()", "sourceAfterFix": "serversByLoad.firstKey()"}, {"bugType": "LESS_SPECIFIC_IF", "fixCommitSHA1": "28012b50ce6ee39b180978ae71682657cc461eb8", "fixCommitParentSHA1": "605ebb05ec99c26013f29043bc65057d649a7544", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/metrics/PersistentMetricsTimeVaryingRate.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/metrics/PersistentMetricsTimeVaryingRate.java b/src/main/java/org/apache/hadoop/hbase/metrics/PersistentMetricsTimeVaryingRate.java\nindex bf6367d..cf2fc28 100644\n--- a/src/main/java/org/apache/hadoop/hbase/metrics/PersistentMetricsTimeVaryingRate.java\n+++ b/src/main/java/org/apache/hadoop/hbase/metrics/PersistentMetricsTimeVaryingRate.java\n@@ -128,7 +128,7 @@\n     if (curOps > 0) {\n       long curTime = this.getPreviousIntervalAverageTime();\n       long totalTime = curTime * curOps;\n-      if (totalTime / curTime == curOps) {\n+      if (curTime == 0 || totalTime / curTime == curOps) {\n         super.inc(curOps, totalTime);\n       } else {\n         LOG.info(\"Stats for \" + this.getName() + \" overflowed! resetting\");\n", "projectName": "apache.hbase", "bugLineNum": 131, "bugNodeStartChar": 4454, "bugNodeLength": 29, "fixLineNum": 131, "fixNodeStartChar": 4454, "fixNodeLength": 45, "sourceBeforeFix": "totalTime / curTime == curOps", "sourceAfterFix": "curTime == 0 || totalTime / curTime == curOps"}, {"bugType": "LESS_SPECIFIC_IF", "fixCommitSHA1": "28012b50ce6ee39b180978ae71682657cc461eb8", "fixCommitParentSHA1": "605ebb05ec99c26013f29043bc65057d649a7544", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/metrics/PersistentMetricsTimeVaryingRate.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/metrics/PersistentMetricsTimeVaryingRate.java b/src/main/java/org/apache/hadoop/hbase/metrics/PersistentMetricsTimeVaryingRate.java\nindex bf6367d..cf2fc28 100644\n--- a/src/main/java/org/apache/hadoop/hbase/metrics/PersistentMetricsTimeVaryingRate.java\n+++ b/src/main/java/org/apache/hadoop/hbase/metrics/PersistentMetricsTimeVaryingRate.java\n@@ -128,7 +128,7 @@\n     if (curOps > 0) {\n       long curTime = this.getPreviousIntervalAverageTime();\n       long totalTime = curTime * curOps;\n-      if (totalTime / curTime == curOps) {\n+      if (curTime == 0 || totalTime / curTime == curOps) {\n         super.inc(curOps, totalTime);\n       } else {\n         LOG.info(\"Stats for \" + this.getName() + \" overflowed! resetting\");\n", "projectName": "apache.hbase", "bugLineNum": 131, "bugNodeStartChar": 4454, "bugNodeLength": 29, "fixLineNum": 131, "fixNodeStartChar": 4454, "fixNodeLength": 45, "sourceBeforeFix": "totalTime / curTime == curOps", "sourceAfterFix": "curTime == 0 || totalTime / curTime == curOps"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "be91a5326f6a289ae9d34437a63c8ba8434fe2b2", "fixCommitParentSHA1": "61fb4c2d774e6e54cd7baac6189e246b87b39ea4", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\nindex 6ff062b..a60b62f 100644\n--- a/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n@@ -3281,7 +3281,7 @@\n \n   public static final long FIXED_OVERHEAD = ClassSize.align(\n       (4 * Bytes.SIZEOF_LONG) + Bytes.SIZEOF_BOOLEAN +\n-      (22 * ClassSize.REFERENCE) + ClassSize.OBJECT + Bytes.SIZEOF_INT);\n+      (23 * ClassSize.REFERENCE) + ClassSize.OBJECT + Bytes.SIZEOF_INT);\n \n   public static final long DEEP_OVERHEAD = ClassSize.align(FIXED_OVERHEAD +\n       (ClassSize.OBJECT * 2) + (2 * ClassSize.ATOMIC_BOOLEAN) +\n", "projectName": "apache.hbase", "bugLineNum": 3284, "bugNodeStartChar": 111663, "bugNodeLength": 24, "fixLineNum": 3284, "fixNodeStartChar": 111663, "fixNodeLength": 24, "sourceBeforeFix": "22 * ClassSize.REFERENCE", "sourceAfterFix": "23 * ClassSize.REFERENCE"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "ce7567c23bf357a2ab98a6f11bd112f36f8177ba", "fixCommitParentSHA1": "6fd4989c82deeb9af063a96b114a22d756b41a90", "bugFilePath": "src/test/java/org/apache/hadoop/hbase/rest/TestTransform.java", "fixPatch": "diff --git a/src/test/java/org/apache/hadoop/hbase/rest/TestTransform.java b/src/test/java/org/apache/hadoop/hbase/rest/TestTransform.java\nindex 548f909..a65a924 100644\n--- a/src/test/java/org/apache/hadoop/hbase/rest/TestTransform.java\n+++ b/src/test/java/org/apache/hadoop/hbase/rest/TestTransform.java\n@@ -91,7 +91,7 @@\n     assertEquals(response.getCode(), 200);\n \n     // get the table contents directly\n-    HTable table = new HTable(TABLE);\n+    HTable table = new HTable(TEST_UTIL.getConfiguration(), TABLE);\n     Get get = new Get(Bytes.toBytes(ROW_1));\n     get.addFamily(Bytes.toBytes(CFA));\n     get.addFamily(Bytes.toBytes(CFB));\n", "projectName": "apache.hbase", "bugLineNum": 94, "bugNodeStartChar": 3679, "bugNodeLength": 17, "fixLineNum": 94, "fixNodeStartChar": 3679, "fixNodeLength": 47, "sourceBeforeFix": "new HTable(TABLE)", "sourceAfterFix": "new HTable(TEST_UTIL.getConfiguration(),TABLE)"}, {"bugType": "ADD_THROWS_EXCEPTION", "fixCommitSHA1": "509beae1e2d9a01e952f9eaf0c4a88037076fc63", "fixCommitParentSHA1": "349b7a74c84a7a273e0fbca304fffa7dfe24f58d", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java b/src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java\nindex bb35527..11d3e88 100644\n--- a/src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java\n+++ b/src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java\n@@ -299,14 +299,18 @@\n   /**\n    * Opens the specified region.\n    * @param region region to open\n+   * @param RegionServerStoppedException\n+   * @param IOException\n    */\n-  public void openRegion(final HRegionInfo region);\n+  public void openRegion(final HRegionInfo region) throws IOException;\n \n   /**\n    * Opens the specified regions.\n    * @param regions regions to open\n+   * @param RegionServerStoppedException\n+   * @param IOException\n    */\n-  public void openRegions(final List<HRegionInfo> regions);\n+  public void openRegions(final List<HRegionInfo> regions) throws IOException;\n \n   /**\n    * Closes the specified region.\n", "projectName": "apache.hbase", "bugLineNum": 299, "bugNodeStartChar": 9717, "bugNodeLength": 128, "fixLineNum": 299, "fixNodeStartChar": 9717, "fixNodeLength": 147, "sourceBeforeFix": "1", "sourceAfterFix": "1"}, {"bugType": "ADD_THROWS_EXCEPTION", "fixCommitSHA1": "509beae1e2d9a01e952f9eaf0c4a88037076fc63", "fixCommitParentSHA1": "349b7a74c84a7a273e0fbca304fffa7dfe24f58d", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java b/src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java\nindex bb35527..11d3e88 100644\n--- a/src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java\n+++ b/src/main/java/org/apache/hadoop/hbase/ipc/HRegionInterface.java\n@@ -299,14 +299,18 @@\n   /**\n    * Opens the specified region.\n    * @param region region to open\n+   * @param RegionServerStoppedException\n+   * @param IOException\n    */\n-  public void openRegion(final HRegionInfo region);\n+  public void openRegion(final HRegionInfo region) throws IOException;\n \n   /**\n    * Opens the specified regions.\n    * @param regions regions to open\n+   * @param RegionServerStoppedException\n+   * @param IOException\n    */\n-  public void openRegions(final List<HRegionInfo> regions);\n+  public void openRegions(final List<HRegionInfo> regions) throws IOException;\n \n   /**\n    * Closes the specified region.\n", "projectName": "apache.hbase", "bugLineNum": 305, "bugNodeStartChar": 9849, "bugNodeLength": 139, "fixLineNum": 305, "fixNodeStartChar": 9849, "fixNodeLength": 158, "sourceBeforeFix": "1", "sourceAfterFix": "1"}, {"bugType": "ADD_THROWS_EXCEPTION", "fixCommitSHA1": "509beae1e2d9a01e952f9eaf0c4a88037076fc63", "fixCommitParentSHA1": "349b7a74c84a7a273e0fbca304fffa7dfe24f58d", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/master/ServerManager.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java b/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java\nindex a8344e2..de75519 100644\n--- a/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java\n+++ b/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java\n@@ -506,7 +506,8 @@\n    * @param server server to open a region\n    * @param region region to open\n    */\n-  public void sendRegionOpen(HServerInfo server, HRegionInfo region) {\n+  public void sendRegionOpen(HServerInfo server, HRegionInfo region) \n+  throws IOException {\n     HRegionInterface hri = getServerConnection(server);\n     if (hri == null) {\n       LOG.warn(\"Attempting to send OPEN RPC to server \" + server.getServerName()\n@@ -524,7 +525,8 @@\n    * @param server server to open a region\n    * @param regions regions to open\n    */\n-  public void sendRegionOpen(HServerInfo server, List<HRegionInfo> regions) {\n+  public void sendRegionOpen(HServerInfo server, List<HRegionInfo> regions)\n+  throws IOException {\n     HRegionInterface hri = getServerConnection(server);\n     if (hri == null) {\n       LOG.warn(\"Attempting to send OPEN RPC to server \" + server.getServerName()\n", "projectName": "apache.hbase", "bugLineNum": 501, "bugNodeStartChar": 19018, "bugNodeLength": 593, "fixLineNum": 501, "fixNodeStartChar": 19018, "fixNodeLength": 615, "sourceBeforeFix": "1", "sourceAfterFix": "1"}, {"bugType": "ADD_THROWS_EXCEPTION", "fixCommitSHA1": "509beae1e2d9a01e952f9eaf0c4a88037076fc63", "fixCommitParentSHA1": "349b7a74c84a7a273e0fbca304fffa7dfe24f58d", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/master/ServerManager.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java b/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java\nindex a8344e2..de75519 100644\n--- a/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java\n+++ b/src/main/java/org/apache/hadoop/hbase/master/ServerManager.java\n@@ -506,7 +506,8 @@\n    * @param server server to open a region\n    * @param region region to open\n    */\n-  public void sendRegionOpen(HServerInfo server, HRegionInfo region) {\n+  public void sendRegionOpen(HServerInfo server, HRegionInfo region) \n+  throws IOException {\n     HRegionInterface hri = getServerConnection(server);\n     if (hri == null) {\n       LOG.warn(\"Attempting to send OPEN RPC to server \" + server.getServerName()\n@@ -524,7 +525,8 @@\n    * @param server server to open a region\n    * @param regions regions to open\n    */\n-  public void sendRegionOpen(HServerInfo server, List<HRegionInfo> regions) {\n+  public void sendRegionOpen(HServerInfo server, List<HRegionInfo> regions)\n+  throws IOException {\n     HRegionInterface hri = getServerConnection(server);\n     if (hri == null) {\n       LOG.warn(\"Attempting to send OPEN RPC to server \" + server.getServerName()\n", "projectName": "apache.hbase", "bugLineNum": 519, "bugNodeStartChar": 19615, "bugNodeLength": 604, "fixLineNum": 519, "fixNodeStartChar": 19615, "fixNodeLength": 625, "sourceBeforeFix": "1", "sourceAfterFix": "1"}, {"bugType": "ADD_THROWS_EXCEPTION", "fixCommitSHA1": "509beae1e2d9a01e952f9eaf0c4a88037076fc63", "fixCommitParentSHA1": "349b7a74c84a7a273e0fbca304fffa7dfe24f58d", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java b/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\nindex 692e657..fab65c7 100644\n--- a/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\n+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\n@@ -1929,7 +1929,8 @@\n   // Region open/close direct RPCs\n \n   @Override\n-  public void openRegion(HRegionInfo region) {\n+  public void openRegion(HRegionInfo region)\n+  throws RegionServerStoppedException {\n     LOG.info(\"Received request to open region: \" +\n       region.getRegionNameAsString());\n     if (this.stopped) throw new RegionServerStoppedException();\n@@ -1943,7 +1944,8 @@\n   }\n \n   @Override\n-  public void openRegions(List<HRegionInfo> regions) {\n+  public void openRegions(List<HRegionInfo> regions)\n+  throws RegionServerStoppedException {\n     LOG.info(\"Received request to open \" + regions.size() + \" region(s)\");\n     for (HRegionInfo region: regions) openRegion(region);\n   }\n", "projectName": "apache.hbase", "bugLineNum": 1931, "bugNodeStartChar": 67014, "bugNodeLength": 511, "fixLineNum": 1931, "fixNodeStartChar": 67014, "fixNodeLength": 549, "sourceBeforeFix": "1", "sourceAfterFix": "1"}, {"bugType": "ADD_THROWS_EXCEPTION", "fixCommitSHA1": "509beae1e2d9a01e952f9eaf0c4a88037076fc63", "fixCommitParentSHA1": "349b7a74c84a7a273e0fbca304fffa7dfe24f58d", "bugFilePath": "src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java", "fixPatch": "diff --git a/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java b/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\nindex 692e657..fab65c7 100644\n--- a/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\n+++ b/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\n@@ -1929,7 +1929,8 @@\n   // Region open/close direct RPCs\n \n   @Override\n-  public void openRegion(HRegionInfo region) {\n+  public void openRegion(HRegionInfo region)\n+  throws RegionServerStoppedException {\n     LOG.info(\"Received request to open region: \" +\n       region.getRegionNameAsString());\n     if (this.stopped) throw new RegionServerStoppedException();\n@@ -1943,7 +1944,8 @@\n   }\n \n   @Override\n-  public void openRegions(List<HRegionInfo> regions) {\n+  public void openRegions(List<HRegionInfo> regions)\n+  throws RegionServerStoppedException {\n     LOG.info(\"Received request to open \" + regions.size() + \" region(s)\");\n     for (HRegionInfo region: regions) openRegion(region);\n   }\n", "projectName": "apache.hbase", "bugLineNum": 1945, "bugNodeStartChar": 67529, "bugNodeLength": 201, "fixLineNum": 1945, "fixNodeStartChar": 67529, "fixNodeLength": 239, "sourceBeforeFix": "1", "sourceAfterFix": "1"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "2dfce22970d9e762a86cf2a2df0861e3d6b26848", "fixCommitParentSHA1": "46c53f14607363b07ade6246e6612171d57dea9b", "bugFilePath": "src/test/java/org/apache/hadoop/hbase/avro/TestAvroServer.java", "fixPatch": "diff --git a/src/test/java/org/apache/hadoop/hbase/avro/TestAvroServer.java b/src/test/java/org/apache/hadoop/hbase/avro/TestAvroServer.java\nindex cc5cc2e..015563c 100644\n--- a/src/test/java/org/apache/hadoop/hbase/avro/TestAvroServer.java\n+++ b/src/test/java/org/apache/hadoop/hbase/avro/TestAvroServer.java\n@@ -94,7 +94,7 @@\n    *\n    * @throws Exception\n    */\n-  @Test (timeout=60000)\n+  @Test (timeout=300000)\n   public void testTableAdminAndMetadata() throws Exception {\n     AvroServer.HBaseImpl impl = new AvroServer.HBaseImpl();\n \n", "projectName": "apache.hbase", "bugLineNum": 97, "bugNodeStartChar": 3284, "bugNodeLength": 13, "fixLineNum": 97, "fixNodeStartChar": 3284, "fixNodeLength": 14, "sourceBeforeFix": "timeout=60000", "sourceAfterFix": "timeout=300000"}, {"bugType": "CHANGE_NUMERAL", "fixCommitSHA1": "eab3e07e39e5ef5e14db8a77f71a2741dd261ca4", "fixCommitParentSHA1": "51455471542c372563f24b0099a5a340dfedf96a", "bugFilePath": "src/test/java/org/apache/hadoop/hbase/regionserver/TestCompaction.java", "fixPatch": "diff --git a/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompaction.java b/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompaction.java\nindex 34b8044..2c3747d 100644\n--- a/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompaction.java\n+++ b/src/test/java/org/apache/hadoop/hbase/regionserver/TestCompaction.java\n@@ -61,7 +61,7 @@\n \n     // Set cache flush size to 1MB\n     conf.setInt(\"hbase.hregion.memstore.flush.size\", 1024*1024);\n-    conf.setInt(\"hbase.hregion.memstore.block.multiplier\", 10);\n+    conf.setInt(\"hbase.hregion.memstore.block.multiplier\", 100);\n     this.cluster = null;\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 64, "bugNodeStartChar": 2373, "bugNodeLength": 58, "fixLineNum": 64, "fixNodeStartChar": 2373, "fixNodeLength": 59, "sourceBeforeFix": "conf.setInt(\"hbase.hregion.memstore.block.multiplier\",10)", "sourceAfterFix": "conf.setInt(\"hbase.hregion.memstore.block.multiplier\",100)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "40514e7f4f12edaaa009b529a2280d9a442989b1", "fixCommitParentSHA1": "196882e2cd68962d64e0a009a6f28496379f55cb", "bugFilePath": "core/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java", "fixPatch": "diff --git a/core/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java b/core/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java\nindex b91c4e7..b80c8ec 100644\n--- a/core/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java\n+++ b/core/src/test/java/org/apache/hadoop/hbase/MiniHBaseCluster.java\n@@ -113,7 +113,7 @@\n    * Subclass so can get at protected methods (none at moment).\n    */\n   public static class MiniHBaseClusterRegionServer extends HRegionServer {\n-    public MiniHBaseClusterRegionServer(HBaseConfiguration conf)\n+    public MiniHBaseClusterRegionServer(Configuration conf)\n         throws IOException {\n       super(conf);\n     }\n", "projectName": "apache.hbase", "bugLineNum": 116, "bugNodeStartChar": 4126, "bugNodeLength": 23, "fixLineNum": 116, "fixNodeStartChar": 4126, "fixNodeLength": 18, "sourceBeforeFix": "HBaseConfiguration conf", "sourceAfterFix": "Configuration conf"}, {"bugType": "CHANGE_MODIFIER", "fixCommitSHA1": "e7e57abc47f85afd7bc2745293a72107068d260a", "fixCommitParentSHA1": "15fc0d66c6b9747467d43e14d2b18a06517f11f3", "bugFilePath": "src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java b/src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\nindex 6fb327d..4e7f45a 100644\n--- a/src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\n+++ b/src/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\n@@ -1236,7 +1236,7 @@\n   }\n \n   /** @return the HLog */\n-  HLog getLog() {\n+  public HLog getLog() {\n     return this.hlog;\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 1238, "bugNodeStartChar": 44295, "bugNodeLength": 67, "fixLineNum": 1238, "fixNodeStartChar": 44295, "fixNodeLength": 74, "sourceBeforeFix": "0", "sourceAfterFix": "1"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "53b0527a5dd35cd2e36650a6352b882cc32f714f", "fixCommitParentSHA1": "1ddddec0180252872f3ef595b69745ba253ac800", "bugFilePath": "src/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java\nindex f985ef8..51e4612 100644\n--- a/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n+++ b/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n@@ -1199,7 +1199,7 @@\n    * @throws IOException\n    */\n   public void put(Put put) throws IOException {\n-    this.put(put, null, put.writeToWAL());\n+    this.put(put, null, put.getWriteToWAL());\n   }\n   \n   /**\n@@ -1217,7 +1217,7 @@\n    * @throws IOException\n    */\n   public void put(Put put, Integer lockid) throws IOException {\n-    this.put(put, lockid, put.writeToWAL());\n+    this.put(put, lockid, put.getWriteToWAL());\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1202, "bugNodeStartChar": 42618, "bugNodeLength": 16, "fixLineNum": 1202, "fixNodeStartChar": 42618, "fixNodeLength": 19, "sourceBeforeFix": "put.writeToWAL()", "sourceAfterFix": "put.getWriteToWAL()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "53b0527a5dd35cd2e36650a6352b882cc32f714f", "fixCommitParentSHA1": "1ddddec0180252872f3ef595b69745ba253ac800", "bugFilePath": "src/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java\nindex f985ef8..51e4612 100644\n--- a/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n+++ b/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n@@ -1199,7 +1199,7 @@\n    * @throws IOException\n    */\n   public void put(Put put) throws IOException {\n-    this.put(put, null, put.writeToWAL());\n+    this.put(put, null, put.getWriteToWAL());\n   }\n   \n   /**\n@@ -1217,7 +1217,7 @@\n    * @throws IOException\n    */\n   public void put(Put put, Integer lockid) throws IOException {\n-    this.put(put, lockid, put.writeToWAL());\n+    this.put(put, lockid, put.getWriteToWAL());\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1202, "bugNodeStartChar": 42618, "bugNodeLength": 16, "fixLineNum": 1202, "fixNodeStartChar": 42618, "fixNodeLength": 19, "sourceBeforeFix": "put.writeToWAL()", "sourceAfterFix": "put.getWriteToWAL()"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "53b0527a5dd35cd2e36650a6352b882cc32f714f", "fixCommitParentSHA1": "1ddddec0180252872f3ef595b69745ba253ac800", "bugFilePath": "src/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java\nindex f985ef8..51e4612 100644\n--- a/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n+++ b/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n@@ -1199,7 +1199,7 @@\n    * @throws IOException\n    */\n   public void put(Put put) throws IOException {\n-    this.put(put, null, put.writeToWAL());\n+    this.put(put, null, put.getWriteToWAL());\n   }\n   \n   /**\n@@ -1217,7 +1217,7 @@\n    * @throws IOException\n    */\n   public void put(Put put, Integer lockid) throws IOException {\n-    this.put(put, lockid, put.writeToWAL());\n+    this.put(put, lockid, put.getWriteToWAL());\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1220, "bugNodeStartChar": 42992, "bugNodeLength": 16, "fixLineNum": 1220, "fixNodeStartChar": 42992, "fixNodeLength": 19, "sourceBeforeFix": "put.writeToWAL()", "sourceAfterFix": "put.getWriteToWAL()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "53b0527a5dd35cd2e36650a6352b882cc32f714f", "fixCommitParentSHA1": "1ddddec0180252872f3ef595b69745ba253ac800", "bugFilePath": "src/java/org/apache/hadoop/hbase/regionserver/HRegion.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java b/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java\nindex f985ef8..51e4612 100644\n--- a/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n+++ b/src/java/org/apache/hadoop/hbase/regionserver/HRegion.java\n@@ -1199,7 +1199,7 @@\n    * @throws IOException\n    */\n   public void put(Put put) throws IOException {\n-    this.put(put, null, put.writeToWAL());\n+    this.put(put, null, put.getWriteToWAL());\n   }\n   \n   /**\n@@ -1217,7 +1217,7 @@\n    * @throws IOException\n    */\n   public void put(Put put, Integer lockid) throws IOException {\n-    this.put(put, lockid, put.writeToWAL());\n+    this.put(put, lockid, put.getWriteToWAL());\n   }\n \n   /**\n", "projectName": "apache.hbase", "bugLineNum": 1220, "bugNodeStartChar": 42992, "bugNodeLength": 16, "fixLineNum": 1220, "fixNodeStartChar": 42992, "fixNodeLength": 19, "sourceBeforeFix": "put.writeToWAL()", "sourceAfterFix": "put.getWriteToWAL()"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "6ac21bbb487fce83e2743e00ccddf63052c9dc4b", "fixCommitParentSHA1": "e9c8ea8156621d136d276d51c988b286af1b6614", "bugFilePath": "src/java/org/apache/hadoop/hbase/zookeeper/HQuorumPeer.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/zookeeper/HQuorumPeer.java b/src/java/org/apache/hadoop/hbase/zookeeper/HQuorumPeer.java\nindex 226e20f..c7cc69b 100644\n--- a/src/java/org/apache/hadoop/hbase/zookeeper/HQuorumPeer.java\n+++ b/src/java/org/apache/hadoop/hbase/zookeeper/HQuorumPeer.java\n@@ -213,7 +213,7 @@\n     } catch (IOException e) {\n       String msg = \"fail to read properties from \" + ZOOKEEPER_CONFIG_NAME;\n       LOG.fatal(msg);\n-      throw new IOException(msg);\n+      throw new IOException(msg, e);\n     }\n     for (Entry<Object, Object> entry : properties.entrySet()) {\n       String value = entry.getValue().toString().trim();\n", "projectName": "apache.hbase", "bugLineNum": 216, "bugNodeStartChar": 8415, "bugNodeLength": 20, "fixLineNum": 216, "fixNodeStartChar": 8415, "fixNodeLength": 23, "sourceBeforeFix": "new IOException(msg)", "sourceAfterFix": "new IOException(msg,e)"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "ceb0d5e68bc6cbf8015be6d5dd785991fbc81455", "fixCommitParentSHA1": "de1cc3ec7befee17d1a75a3b4549c92352464957", "bugFilePath": "src/contrib/stargate/src/test/org/apache/hadoop/hbase/stargate/TestRowResource.java", "fixPatch": "diff --git a/src/contrib/stargate/src/test/org/apache/hadoop/hbase/stargate/TestRowResource.java b/src/contrib/stargate/src/test/org/apache/hadoop/hbase/stargate/TestRowResource.java\nindex 0a8b9b7..fa76018 100644\n--- a/src/contrib/stargate/src/test/org/apache/hadoop/hbase/stargate/TestRowResource.java\n+++ b/src/contrib/stargate/src/test/org/apache/hadoop/hbase/stargate/TestRowResource.java\n@@ -317,7 +317,7 @@\n     Thread.yield();\n \n     // make sure the fake row was not actually created\n-    response = client.get(path);\n+    response = client.get(path, MIMETYPE_XML);\n     assertEquals(response.getCode(), 404);\n \n     // check that all of the values were created\n@@ -349,7 +349,7 @@\n     Thread.yield();\n \n     // make sure the fake row was not actually created\n-    response = client.get(path);\n+    response = client.get(path, MIMETYPE_PROTOBUF);\n     assertEquals(response.getCode(), 404);\n \n     // check that all of the values were created\n", "projectName": "apache.hbase", "bugLineNum": 320, "bugNodeStartChar": 11806, "bugNodeLength": 16, "fixLineNum": 320, "fixNodeStartChar": 11806, "fixNodeLength": 30, "sourceBeforeFix": "client.get(path)", "sourceAfterFix": "client.get(path,MIMETYPE_XML)"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "ceb0d5e68bc6cbf8015be6d5dd785991fbc81455", "fixCommitParentSHA1": "de1cc3ec7befee17d1a75a3b4549c92352464957", "bugFilePath": "src/contrib/stargate/src/test/org/apache/hadoop/hbase/stargate/TestRowResource.java", "fixPatch": "diff --git a/src/contrib/stargate/src/test/org/apache/hadoop/hbase/stargate/TestRowResource.java b/src/contrib/stargate/src/test/org/apache/hadoop/hbase/stargate/TestRowResource.java\nindex 0a8b9b7..fa76018 100644\n--- a/src/contrib/stargate/src/test/org/apache/hadoop/hbase/stargate/TestRowResource.java\n+++ b/src/contrib/stargate/src/test/org/apache/hadoop/hbase/stargate/TestRowResource.java\n@@ -317,7 +317,7 @@\n     Thread.yield();\n \n     // make sure the fake row was not actually created\n-    response = client.get(path);\n+    response = client.get(path, MIMETYPE_XML);\n     assertEquals(response.getCode(), 404);\n \n     // check that all of the values were created\n@@ -349,7 +349,7 @@\n     Thread.yield();\n \n     // make sure the fake row was not actually created\n-    response = client.get(path);\n+    response = client.get(path, MIMETYPE_PROTOBUF);\n     assertEquals(response.getCode(), 404);\n \n     // check that all of the values were created\n", "projectName": "apache.hbase", "bugLineNum": 352, "bugNodeStartChar": 13178, "bugNodeLength": 16, "fixLineNum": 352, "fixNodeStartChar": 13178, "fixNodeLength": 35, "sourceBeforeFix": "client.get(path)", "sourceAfterFix": "client.get(path,MIMETYPE_PROTOBUF)"}, {"bugType": "OVERLOAD_METHOD_MORE_ARGS", "fixCommitSHA1": "a2fe91696b850bdea3e1f4fa8621188076dba7d0", "fixCommitParentSHA1": "c671863d64fae759954dd6ad0fa897c29c9f8667", "bugFilePath": "src/java/org/apache/hadoop/hbase/io/hfile/HFile.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/io/hfile/HFile.java b/src/java/org/apache/hadoop/hbase/io/hfile/HFile.java\nindex 3bf079a..5c96420 100644\n--- a/src/java/org/apache/hadoop/hbase/io/hfile/HFile.java\n+++ b/src/java/org/apache/hadoop/hbase/io/hfile/HFile.java\n@@ -1167,7 +1167,9 @@\n           return false; // key is before the start of the file.\n \n         // Question: does this block begin with 'key'?\n-        if (this.reader.comparator.compare(reader.blockIndex.blockKeys[b], key) == 0) {\n+        if (this.reader.comparator.compare(reader.blockIndex.blockKeys[b],\n+            0, reader.blockIndex.blockKeys[b].length,\n+            key, offset, length) == 0) {\n           // Ok the key we're interested in is the first of the block, so go back one.\n           if (b == 0) {\n             // we have a 'problem', the key we want is the first of the file.\n", "projectName": "apache.hbase", "bugLineNum": 1170, "bugNodeStartChar": 41454, "bugNodeLength": 67, "fixLineNum": 1170, "fixNodeStartChar": 41454, "fixNodeLength": 149, "sourceBeforeFix": "this.reader.comparator.compare(reader.blockIndex.blockKeys[b],key)", "sourceAfterFix": "this.reader.comparator.compare(reader.blockIndex.blockKeys[b],0,reader.blockIndex.blockKeys[b].length,key,offset,length)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "8aeb808e008d2a96885b6ee67997a70b432624ee", "fixCommitParentSHA1": "44bbcbded751f695c926b0c51f995325c4022418", "bugFilePath": "src/java/org/apache/hadoop/hbase/regionserver/Store.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/regionserver/Store.java b/src/java/org/apache/hadoop/hbase/regionserver/Store.java\nindex 740d2e6..d918473 100644\n--- a/src/java/org/apache/hadoop/hbase/regionserver/Store.java\n+++ b/src/java/org/apache/hadoop/hbase/regionserver/Store.java\n@@ -882,7 +882,7 @@\n           if (timesSeen <= maxVersions && !(expired = isExpired(kv, ttl, now))) {\n             // If this value key is same as a deleted key, skip\n             if (lastDelete != null &&\n-                this.comparator.compare(kv, lastDelete) == 0) {\n+                this.comparatorIgnoringType.compare(kv, lastDelete) == 0) {\n               deleted = true;\n             } else if (kv.isDeleteType()) {\n               // If a deleted value, skip\n", "projectName": "apache.hbase", "bugLineNum": 885, "bugNodeStartChar": 32499, "bugNodeLength": 15, "fixLineNum": 885, "fixNodeStartChar": 32499, "fixNodeLength": 27, "sourceBeforeFix": "this.comparator", "sourceAfterFix": "this.comparatorIgnoringType"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "9704f6049c41315c3de3fa6be6faf01e62c67863", "fixCommitParentSHA1": "bfda6ae20e55c8190b157eda7925a1d1a8d82f26", "bugFilePath": "src/test/org/apache/hadoop/hbase/TestInfoServers.java", "fixPatch": "diff --git a/src/test/org/apache/hadoop/hbase/TestInfoServers.java b/src/test/org/apache/hadoop/hbase/TestInfoServers.java\nindex 9a79b00..911ac44 100644\n--- a/src/test/org/apache/hadoop/hbase/TestInfoServers.java\n+++ b/src/test/org/apache/hadoop/hbase/TestInfoServers.java\n@@ -50,11 +50,11 @@\n     new HTable(conf, \".META.\");\n     int port = cluster.getMaster().getInfoServer().getPort();\n     assertHasExpectedContent(new URL(\"http://localhost:\" + port +\n-      \"/index.html\"), \"Master\");\n+      \"/index.html\"), \"master\");\n     port = cluster.getRegionThreads().get(0).getRegionServer().\n       getInfoServer().getPort();\n     assertHasExpectedContent(new URL(\"http://localhost:\" + port +\n-      \"/index.html\"), \"Region Server\");\n+      \"/index.html\"), \"regionserver\");\n   }\n   \n   private void assertHasExpectedContent(final URL u, final String expected)\n@@ -71,6 +71,6 @@\n     }\n     bis.close();\n     String content = sb.toString();\n-    assertTrue(content.matches(expected));\n+    assertTrue(content.contains(expected));\n   }\n }\n\\ No newline at end of file\n", "projectName": "apache.hbase", "bugLineNum": 74, "bugNodeStartChar": 2798, "bugNodeLength": 25, "fixLineNum": 74, "fixNodeStartChar": 2798, "fixNodeLength": 26, "sourceBeforeFix": "content.matches(expected)", "sourceAfterFix": "content.contains(expected)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "9704f6049c41315c3de3fa6be6faf01e62c67863", "fixCommitParentSHA1": "bfda6ae20e55c8190b157eda7925a1d1a8d82f26", "bugFilePath": "src/test/org/apache/hadoop/hbase/TestInfoServers.java", "fixPatch": "diff --git a/src/test/org/apache/hadoop/hbase/TestInfoServers.java b/src/test/org/apache/hadoop/hbase/TestInfoServers.java\nindex 9a79b00..911ac44 100644\n--- a/src/test/org/apache/hadoop/hbase/TestInfoServers.java\n+++ b/src/test/org/apache/hadoop/hbase/TestInfoServers.java\n@@ -50,11 +50,11 @@\n     new HTable(conf, \".META.\");\n     int port = cluster.getMaster().getInfoServer().getPort();\n     assertHasExpectedContent(new URL(\"http://localhost:\" + port +\n-      \"/index.html\"), \"Master\");\n+      \"/index.html\"), \"master\");\n     port = cluster.getRegionThreads().get(0).getRegionServer().\n       getInfoServer().getPort();\n     assertHasExpectedContent(new URL(\"http://localhost:\" + port +\n-      \"/index.html\"), \"Region Server\");\n+      \"/index.html\"), \"regionserver\");\n   }\n   \n   private void assertHasExpectedContent(final URL u, final String expected)\n@@ -71,6 +71,6 @@\n     }\n     bis.close();\n     String content = sb.toString();\n-    assertTrue(content.matches(expected));\n+    assertTrue(content.contains(expected));\n   }\n }\n\\ No newline at end of file\n", "projectName": "apache.hbase", "bugLineNum": 74, "bugNodeStartChar": 2798, "bugNodeLength": 25, "fixLineNum": 74, "fixNodeStartChar": 2798, "fixNodeLength": 26, "sourceBeforeFix": "content.matches(expected)", "sourceAfterFix": "content.contains(expected)"}, {"bugType": "ADD_THROWS_EXCEPTION", "fixCommitSHA1": "78ce1b10c99e206776b8f2834114eaf85306ab92", "fixCommitParentSHA1": "2492b8b6599e7424625756f4b6a37abf7d4f7d2c", "bugFilePath": "src/java/org/apache/hadoop/hbase/mapred/TableMapReduceUtil.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/mapred/TableMapReduceUtil.java b/src/java/org/apache/hadoop/hbase/mapred/TableMapReduceUtil.java\nindex 29a7221..972f696 100644\n--- a/src/java/org/apache/hadoop/hbase/mapred/TableMapReduceUtil.java\n+++ b/src/java/org/apache/hadoop/hbase/mapred/TableMapReduceUtil.java\n@@ -69,7 +69,8 @@\n    * @throws IOException \n    */\n   public static void initTableReduceJob(String table,\n-      Class<? extends TableReduce> reducer, JobConf job) {\n+    Class<? extends TableReduce> reducer, JobConf job)\n+  throws IOException {\n     initTableReduceJob(table, reducer, job, null);\n   }\n \n", "projectName": "apache.hbase", "bugLineNum": 62, "bugNodeStartChar": 2254, "bugNodeLength": 361, "fixLineNum": 62, "fixNodeStartChar": 2254, "fixNodeLength": 380, "sourceBeforeFix": "9", "sourceAfterFix": "9"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "423fca2f16ef73c1e4bce7cf11660a510be1456e", "fixCommitParentSHA1": "f63ecc9a063d9db0be6c787648cf69317002cf4e", "bugFilePath": "src/java/org/apache/hadoop/hbase/master/BaseScanner.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/master/BaseScanner.java b/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\nindex cdcd77b..3ef9898 100644\n--- a/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\n+++ b/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\n@@ -240,7 +240,8 @@\n       return false;\n     }\n     if (!info.isOffline()) {\n-      LOG.warn(\"Region is split but not offline: \" + info.getRegionName());\n+      LOG.warn(\"Region is split but not offline: \" +\n+        info.getRegionNameAsString());\n     }\n     return true;\n   }\n@@ -268,7 +269,7 @@\n         parent.getRegionName(), rowContent, COL_SPLITB);\n     \n     if (!hasReferencesA && !hasReferencesB) {\n-      LOG.info(\"Deleting region \" + parent.getRegionName() +\n+      LOG.info(\"Deleting region \" + parent.getRegionNameAsString() +\n         \" because daughter splits no longer hold references\");\n       HRegion.deleteRegion(master.fs, master.rootdir, parent);\n       \n@@ -334,8 +335,8 @@\n     }\n     \n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(split.getRegionName().toString()\n-          +\" no longer has references to \" + parent.toString());\n+      LOG.debug(split.getRegionNameAsString() +\n+        \" no longer has references to \" + parent.toString());\n     }\n     \n     BatchUpdate b = new BatchUpdate(parent);\n@@ -365,7 +366,7 @@\n         // Skip if region is on kill list\n         if(LOG.isDebugEnabled()) {\n           LOG.debug(\"not assigning region (on kill list): \" +\n-            info.getRegionName());\n+            info.getRegionNameAsString());\n         }\n         return;\n       }\n@@ -385,7 +386,7 @@\n       // The current assignment is invalid\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Current assignment of \" +\n-          Bytes.toString(info.getRegionName()) +\n+          info.getRegionNameAsString() +\n           \" is not valid: serverInfo: \" + storedInfo + \", passed startCode: \" +\n           startCode + \", storedInfo.startCode: \" +\n           ((storedInfo != null)? storedInfo.getStartCode(): -1) +\n", "projectName": "apache.hbase", "bugLineNum": 243, "bugNodeStartChar": 9107, "bugNodeLength": 20, "fixLineNum": 244, "fixNodeStartChar": 9115, "fixNodeLength": 28, "sourceBeforeFix": "info.getRegionName()", "sourceAfterFix": "info.getRegionNameAsString()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "423fca2f16ef73c1e4bce7cf11660a510be1456e", "fixCommitParentSHA1": "f63ecc9a063d9db0be6c787648cf69317002cf4e", "bugFilePath": "src/java/org/apache/hadoop/hbase/master/BaseScanner.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/master/BaseScanner.java b/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\nindex cdcd77b..3ef9898 100644\n--- a/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\n+++ b/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\n@@ -240,7 +240,8 @@\n       return false;\n     }\n     if (!info.isOffline()) {\n-      LOG.warn(\"Region is split but not offline: \" + info.getRegionName());\n+      LOG.warn(\"Region is split but not offline: \" +\n+        info.getRegionNameAsString());\n     }\n     return true;\n   }\n@@ -268,7 +269,7 @@\n         parent.getRegionName(), rowContent, COL_SPLITB);\n     \n     if (!hasReferencesA && !hasReferencesB) {\n-      LOG.info(\"Deleting region \" + parent.getRegionName() +\n+      LOG.info(\"Deleting region \" + parent.getRegionNameAsString() +\n         \" because daughter splits no longer hold references\");\n       HRegion.deleteRegion(master.fs, master.rootdir, parent);\n       \n@@ -334,8 +335,8 @@\n     }\n     \n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(split.getRegionName().toString()\n-          +\" no longer has references to \" + parent.toString());\n+      LOG.debug(split.getRegionNameAsString() +\n+        \" no longer has references to \" + parent.toString());\n     }\n     \n     BatchUpdate b = new BatchUpdate(parent);\n@@ -365,7 +366,7 @@\n         // Skip if region is on kill list\n         if(LOG.isDebugEnabled()) {\n           LOG.debug(\"not assigning region (on kill list): \" +\n-            info.getRegionName());\n+            info.getRegionNameAsString());\n         }\n         return;\n       }\n@@ -385,7 +386,7 @@\n       // The current assignment is invalid\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Current assignment of \" +\n-          Bytes.toString(info.getRegionName()) +\n+          info.getRegionNameAsString() +\n           \" is not valid: serverInfo: \" + storedInfo + \", passed startCode: \" +\n           startCode + \", storedInfo.startCode: \" +\n           ((storedInfo != null)? storedInfo.getStartCode(): -1) +\n", "projectName": "apache.hbase", "bugLineNum": 243, "bugNodeStartChar": 9107, "bugNodeLength": 20, "fixLineNum": 244, "fixNodeStartChar": 9115, "fixNodeLength": 28, "sourceBeforeFix": "info.getRegionName()", "sourceAfterFix": "info.getRegionNameAsString()"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "423fca2f16ef73c1e4bce7cf11660a510be1456e", "fixCommitParentSHA1": "f63ecc9a063d9db0be6c787648cf69317002cf4e", "bugFilePath": "src/java/org/apache/hadoop/hbase/master/BaseScanner.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/master/BaseScanner.java b/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\nindex cdcd77b..3ef9898 100644\n--- a/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\n+++ b/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\n@@ -240,7 +240,8 @@\n       return false;\n     }\n     if (!info.isOffline()) {\n-      LOG.warn(\"Region is split but not offline: \" + info.getRegionName());\n+      LOG.warn(\"Region is split but not offline: \" +\n+        info.getRegionNameAsString());\n     }\n     return true;\n   }\n@@ -268,7 +269,7 @@\n         parent.getRegionName(), rowContent, COL_SPLITB);\n     \n     if (!hasReferencesA && !hasReferencesB) {\n-      LOG.info(\"Deleting region \" + parent.getRegionName() +\n+      LOG.info(\"Deleting region \" + parent.getRegionNameAsString() +\n         \" because daughter splits no longer hold references\");\n       HRegion.deleteRegion(master.fs, master.rootdir, parent);\n       \n@@ -334,8 +335,8 @@\n     }\n     \n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(split.getRegionName().toString()\n-          +\" no longer has references to \" + parent.toString());\n+      LOG.debug(split.getRegionNameAsString() +\n+        \" no longer has references to \" + parent.toString());\n     }\n     \n     BatchUpdate b = new BatchUpdate(parent);\n@@ -365,7 +366,7 @@\n         // Skip if region is on kill list\n         if(LOG.isDebugEnabled()) {\n           LOG.debug(\"not assigning region (on kill list): \" +\n-            info.getRegionName());\n+            info.getRegionNameAsString());\n         }\n         return;\n       }\n@@ -385,7 +386,7 @@\n       // The current assignment is invalid\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Current assignment of \" +\n-          Bytes.toString(info.getRegionName()) +\n+          info.getRegionNameAsString() +\n           \" is not valid: serverInfo: \" + storedInfo + \", passed startCode: \" +\n           startCode + \", storedInfo.startCode: \" +\n           ((storedInfo != null)? storedInfo.getStartCode(): -1) +\n", "projectName": "apache.hbase", "bugLineNum": 271, "bugNodeStartChar": 10150, "bugNodeLength": 22, "fixLineNum": 271, "fixNodeStartChar": 10150, "fixNodeLength": 30, "sourceBeforeFix": "parent.getRegionName()", "sourceAfterFix": "parent.getRegionNameAsString()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "423fca2f16ef73c1e4bce7cf11660a510be1456e", "fixCommitParentSHA1": "f63ecc9a063d9db0be6c787648cf69317002cf4e", "bugFilePath": "src/java/org/apache/hadoop/hbase/master/BaseScanner.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/master/BaseScanner.java b/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\nindex cdcd77b..3ef9898 100644\n--- a/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\n+++ b/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\n@@ -240,7 +240,8 @@\n       return false;\n     }\n     if (!info.isOffline()) {\n-      LOG.warn(\"Region is split but not offline: \" + info.getRegionName());\n+      LOG.warn(\"Region is split but not offline: \" +\n+        info.getRegionNameAsString());\n     }\n     return true;\n   }\n@@ -268,7 +269,7 @@\n         parent.getRegionName(), rowContent, COL_SPLITB);\n     \n     if (!hasReferencesA && !hasReferencesB) {\n-      LOG.info(\"Deleting region \" + parent.getRegionName() +\n+      LOG.info(\"Deleting region \" + parent.getRegionNameAsString() +\n         \" because daughter splits no longer hold references\");\n       HRegion.deleteRegion(master.fs, master.rootdir, parent);\n       \n@@ -334,8 +335,8 @@\n     }\n     \n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(split.getRegionName().toString()\n-          +\" no longer has references to \" + parent.toString());\n+      LOG.debug(split.getRegionNameAsString() +\n+        \" no longer has references to \" + parent.toString());\n     }\n     \n     BatchUpdate b = new BatchUpdate(parent);\n@@ -365,7 +366,7 @@\n         // Skip if region is on kill list\n         if(LOG.isDebugEnabled()) {\n           LOG.debug(\"not assigning region (on kill list): \" +\n-            info.getRegionName());\n+            info.getRegionNameAsString());\n         }\n         return;\n       }\n@@ -385,7 +386,7 @@\n       // The current assignment is invalid\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Current assignment of \" +\n-          Bytes.toString(info.getRegionName()) +\n+          info.getRegionNameAsString() +\n           \" is not valid: serverInfo: \" + storedInfo + \", passed startCode: \" +\n           startCode + \", storedInfo.startCode: \" +\n           ((storedInfo != null)? storedInfo.getStartCode(): -1) +\n", "projectName": "apache.hbase", "bugLineNum": 271, "bugNodeStartChar": 10150, "bugNodeLength": 22, "fixLineNum": 271, "fixNodeStartChar": 10150, "fixNodeLength": 30, "sourceBeforeFix": "parent.getRegionName()", "sourceAfterFix": "parent.getRegionNameAsString()"}, {"bugType": "DIFFERENT_METHOD_SAME_ARGS", "fixCommitSHA1": "423fca2f16ef73c1e4bce7cf11660a510be1456e", "fixCommitParentSHA1": "f63ecc9a063d9db0be6c787648cf69317002cf4e", "bugFilePath": "src/java/org/apache/hadoop/hbase/master/BaseScanner.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/master/BaseScanner.java b/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\nindex cdcd77b..3ef9898 100644\n--- a/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\n+++ b/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\n@@ -240,7 +240,8 @@\n       return false;\n     }\n     if (!info.isOffline()) {\n-      LOG.warn(\"Region is split but not offline: \" + info.getRegionName());\n+      LOG.warn(\"Region is split but not offline: \" +\n+        info.getRegionNameAsString());\n     }\n     return true;\n   }\n@@ -268,7 +269,7 @@\n         parent.getRegionName(), rowContent, COL_SPLITB);\n     \n     if (!hasReferencesA && !hasReferencesB) {\n-      LOG.info(\"Deleting region \" + parent.getRegionName() +\n+      LOG.info(\"Deleting region \" + parent.getRegionNameAsString() +\n         \" because daughter splits no longer hold references\");\n       HRegion.deleteRegion(master.fs, master.rootdir, parent);\n       \n@@ -334,8 +335,8 @@\n     }\n     \n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(split.getRegionName().toString()\n-          +\" no longer has references to \" + parent.toString());\n+      LOG.debug(split.getRegionNameAsString() +\n+        \" no longer has references to \" + parent.toString());\n     }\n     \n     BatchUpdate b = new BatchUpdate(parent);\n@@ -365,7 +366,7 @@\n         // Skip if region is on kill list\n         if(LOG.isDebugEnabled()) {\n           LOG.debug(\"not assigning region (on kill list): \" +\n-            info.getRegionName());\n+            info.getRegionNameAsString());\n         }\n         return;\n       }\n@@ -385,7 +386,7 @@\n       // The current assignment is invalid\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Current assignment of \" +\n-          Bytes.toString(info.getRegionName()) +\n+          info.getRegionNameAsString() +\n           \" is not valid: serverInfo: \" + storedInfo + \", passed startCode: \" +\n           startCode + \", storedInfo.startCode: \" +\n           ((storedInfo != null)? storedInfo.getStartCode(): -1) +\n", "projectName": "apache.hbase", "bugLineNum": 368, "bugNodeStartChar": 13427, "bugNodeLength": 20, "fixLineNum": 368, "fixNodeStartChar": 13427, "fixNodeLength": 28, "sourceBeforeFix": "info.getRegionName()", "sourceAfterFix": "info.getRegionNameAsString()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "423fca2f16ef73c1e4bce7cf11660a510be1456e", "fixCommitParentSHA1": "f63ecc9a063d9db0be6c787648cf69317002cf4e", "bugFilePath": "src/java/org/apache/hadoop/hbase/master/BaseScanner.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/master/BaseScanner.java b/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\nindex cdcd77b..3ef9898 100644\n--- a/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\n+++ b/src/java/org/apache/hadoop/hbase/master/BaseScanner.java\n@@ -240,7 +240,8 @@\n       return false;\n     }\n     if (!info.isOffline()) {\n-      LOG.warn(\"Region is split but not offline: \" + info.getRegionName());\n+      LOG.warn(\"Region is split but not offline: \" +\n+        info.getRegionNameAsString());\n     }\n     return true;\n   }\n@@ -268,7 +269,7 @@\n         parent.getRegionName(), rowContent, COL_SPLITB);\n     \n     if (!hasReferencesA && !hasReferencesB) {\n-      LOG.info(\"Deleting region \" + parent.getRegionName() +\n+      LOG.info(\"Deleting region \" + parent.getRegionNameAsString() +\n         \" because daughter splits no longer hold references\");\n       HRegion.deleteRegion(master.fs, master.rootdir, parent);\n       \n@@ -334,8 +335,8 @@\n     }\n     \n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(split.getRegionName().toString()\n-          +\" no longer has references to \" + parent.toString());\n+      LOG.debug(split.getRegionNameAsString() +\n+        \" no longer has references to \" + parent.toString());\n     }\n     \n     BatchUpdate b = new BatchUpdate(parent);\n@@ -365,7 +366,7 @@\n         // Skip if region is on kill list\n         if(LOG.isDebugEnabled()) {\n           LOG.debug(\"not assigning region (on kill list): \" +\n-            info.getRegionName());\n+            info.getRegionNameAsString());\n         }\n         return;\n       }\n@@ -385,7 +386,7 @@\n       // The current assignment is invalid\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Current assignment of \" +\n-          Bytes.toString(info.getRegionName()) +\n+          info.getRegionNameAsString() +\n           \" is not valid: serverInfo: \" + storedInfo + \", passed startCode: \" +\n           startCode + \", storedInfo.startCode: \" +\n           ((storedInfo != null)? storedInfo.getStartCode(): -1) +\n", "projectName": "apache.hbase", "bugLineNum": 368, "bugNodeStartChar": 13427, "bugNodeLength": 20, "fixLineNum": 368, "fixNodeStartChar": 13427, "fixNodeLength": 28, "sourceBeforeFix": "info.getRegionName()", "sourceAfterFix": "info.getRegionNameAsString()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "1eda3c24396baa2067d8a048fd98a6ac13785a55", "fixCommitParentSHA1": "3f3e2c575620d78c1df34b15a1c4815f16dfb1ee", "bugFilePath": "src/java/org/apache/hadoop/hbase/util/Migrate.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/util/Migrate.java b/src/java/org/apache/hadoop/hbase/util/Migrate.java\nindex aa87eae..47bdb6c 100644\n--- a/src/java/org/apache/hadoop/hbase/util/Migrate.java\n+++ b/src/java/org/apache/hadoop/hbase/util/Migrate.java\n@@ -342,7 +342,7 @@\n   throws IOException {\n     // Create directory where table will live\n \n-    Path tableDir = new Path(rootdir, tableName.toString());\n+    Path tableDir = new Path(rootdir, Bytes.toString(tableName));\n     fs.mkdirs(tableDir);\n \n     // Move the old region directory under the table directory\n", "projectName": "apache.hbase", "bugLineNum": 345, "bugNodeStartChar": 10886, "bugNodeLength": 20, "fixLineNum": 345, "fixNodeStartChar": 10886, "fixNodeLength": 25, "sourceBeforeFix": "tableName.toString()", "sourceAfterFix": "Bytes.toString(tableName)"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "ad743978ed62cdf18bb3f8d580deb27b9b2195a4", "fixCommitParentSHA1": "d8f4792f8e20bf7c0c0ca7a057245c3fd1e2a75d", "bugFilePath": "src/java/org/apache/hadoop/hbase/HMaster.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/HMaster.java b/src/java/org/apache/hadoop/hbase/HMaster.java\nindex 9163eea..877379a 100644\n--- a/src/java/org/apache/hadoop/hbase/HMaster.java\n+++ b/src/java/org/apache/hadoop/hbase/HMaster.java\n@@ -2087,7 +2087,7 @@\n           if (closed.get()) {\n             return true;\n           }\n-          if (!rootScanned ||\n+          if (!rootRescanned ||\n               numberOfMetaRegions.get() != onlineMetaRegions.size()) {\n             // We can't proceed because not all of the meta regions are online.\n             // We can't block either because that would prevent the meta region\n@@ -2096,7 +2096,7 @@\n             \n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"Requeuing shutdown because rootScanned: \" +\n-                  rootScanned + \", numberOfMetaRegions: \" +\n+                  rootRescanned + \", numberOfMetaRegions: \" +\n                   numberOfMetaRegions.get() + \", onlineMetaRegions.size(): \" +\n                   onlineMetaRegions.size());\n             }\n", "projectName": "apache.hbase", "bugLineNum": 2090, "bugNodeStartChar": 72502, "bugNodeLength": 12, "fixLineNum": 2090, "fixNodeStartChar": 72502, "fixNodeLength": 14, "sourceBeforeFix": "!rootScanned", "sourceAfterFix": "!rootRescanned"}, {"bugType": "CHANGE_OPERAND", "fixCommitSHA1": "ad743978ed62cdf18bb3f8d580deb27b9b2195a4", "fixCommitParentSHA1": "d8f4792f8e20bf7c0c0ca7a057245c3fd1e2a75d", "bugFilePath": "src/java/org/apache/hadoop/hbase/HMaster.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/HMaster.java b/src/java/org/apache/hadoop/hbase/HMaster.java\nindex 9163eea..877379a 100644\n--- a/src/java/org/apache/hadoop/hbase/HMaster.java\n+++ b/src/java/org/apache/hadoop/hbase/HMaster.java\n@@ -2087,7 +2087,7 @@\n           if (closed.get()) {\n             return true;\n           }\n-          if (!rootScanned ||\n+          if (!rootRescanned ||\n               numberOfMetaRegions.get() != onlineMetaRegions.size()) {\n             // We can't proceed because not all of the meta regions are online.\n             // We can't block either because that would prevent the meta region\n@@ -2096,7 +2096,7 @@\n             \n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"Requeuing shutdown because rootScanned: \" +\n-                  rootScanned + \", numberOfMetaRegions: \" +\n+                  rootRescanned + \", numberOfMetaRegions: \" +\n                   numberOfMetaRegions.get() + \", onlineMetaRegions.size(): \" +\n                   onlineMetaRegions.size());\n             }\n", "projectName": "apache.hbase", "bugLineNum": 2098, "bugNodeStartChar": 72942, "bugNodeLength": 226, "fixLineNum": 2098, "fixNodeStartChar": 72942, "fixNodeLength": 228, "sourceBeforeFix": "\"Requeuing shutdown because rootScanned: \" + rootScanned + \", numberOfMetaRegions: \"+ numberOfMetaRegions.get()+ \", onlineMetaRegions.size(): \"+ onlineMetaRegions.size()", "sourceAfterFix": "\"Requeuing shutdown because rootScanned: \" + rootRescanned + \", numberOfMetaRegions: \"+ numberOfMetaRegions.get()+ \", onlineMetaRegions.size(): \"+ onlineMetaRegions.size()"}, {"bugType": "CHANGE_IDENTIFIER", "fixCommitSHA1": "ad743978ed62cdf18bb3f8d580deb27b9b2195a4", "fixCommitParentSHA1": "d8f4792f8e20bf7c0c0ca7a057245c3fd1e2a75d", "bugFilePath": "src/java/org/apache/hadoop/hbase/HMaster.java", "fixPatch": "diff --git a/src/java/org/apache/hadoop/hbase/HMaster.java b/src/java/org/apache/hadoop/hbase/HMaster.java\nindex 9163eea..877379a 100644\n--- a/src/java/org/apache/hadoop/hbase/HMaster.java\n+++ b/src/java/org/apache/hadoop/hbase/HMaster.java\n@@ -2087,7 +2087,7 @@\n           if (closed.get()) {\n             return true;\n           }\n-          if (!rootScanned ||\n+          if (!rootRescanned ||\n               numberOfMetaRegions.get() != onlineMetaRegions.size()) {\n             // We can't proceed because not all of the meta regions are online.\n             // We can't block either because that would prevent the meta region\n@@ -2096,7 +2096,7 @@\n             \n             if (LOG.isDebugEnabled()) {\n               LOG.debug(\"Requeuing shutdown because rootScanned: \" +\n-                  rootScanned + \", numberOfMetaRegions: \" +\n+                  rootRescanned + \", numberOfMetaRegions: \" +\n                   numberOfMetaRegions.get() + \", onlineMetaRegions.size(): \" +\n                   onlineMetaRegions.size());\n             }\n", "projectName": "apache.hbase", "bugLineNum": 2098, "bugNodeStartChar": 72942, "bugNodeLength": 226, "fixLineNum": 2098, "fixNodeStartChar": 72942, "fixNodeLength": 228, "sourceBeforeFix": "\"Requeuing shutdown because rootScanned: \" + rootScanned + \", numberOfMetaRegions: \"+ numberOfMetaRegions.get()+ \", onlineMetaRegions.size(): \"+ onlineMetaRegions.size()", "sourceAfterFix": "\"Requeuing shutdown because rootScanned: \" + rootRescanned + \", numberOfMetaRegions: \"+ numberOfMetaRegions.get()+ \", onlineMetaRegions.size(): \"+ onlineMetaRegions.size()"}]